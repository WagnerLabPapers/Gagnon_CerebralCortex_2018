---
title: "AP_results"
output: 
  html_document: 
    highlight: pygments
    theme: flatly
    toc: yes
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Set up environment
```{r}
source('~/Experiments/AP/stats/init_renv.R')

# plotting stuff
theme_set(theme_classic(base_size = 22))
library(gridExtra)
library(RColorBrewer)

library(boot)
zscore <- function(vec){(vec-mean(vec))/sd(vec)}

# run trial-wise mediation? (takes a long time - only do first time)
run_mediation = FALSE
```

# 0) Manipulation checks

## 00) Compare CTRU vs. Salimetrics assay on independent set of 49 samples (Salimetrics ran these using data from other lab)
```{r}
dcort_salcompare = read.csv('/Volumes/group/awagner/sgagnon/AP/data/cortisol/salimetrics_comparison_n49samples.csv')
dim(dcort_salcompare)

# correlation between assays
res_cor = cor.test(dcort_salcompare$lnSal_CORt_Mean, 
         y = dcort_salcompare$lnSAL_IBL_mean)
res_cor
cat('R^2: ', (res_cor$estimate)^2)

# mean of assays
dcort_salcompare %>% summarise_all(funs(mean, sd))

# compare means
bartlett.test(value ~ key, dcort_salcompare %>% gather())
t.test(dcort_salcompare$lnSal_CORt_Mean,
       dcort_salcompare$lnSAL_IBL_mean, 
       var.equal=TRUE, paired = TRUE)
t.test(value ~ key, dcort_salcompare %>% gather(), 
       var.equal=TRUE, paired = TRUE)
```



## 0a) Cortisol
```{r}
dcort = read.csv('/Volumes/group/awagner/sgagnon/AP/data/cortisol/combined_cort_results.csv')
head(dcort)

dcort %>% filter(log.ug.dL. > 0) # all neg

# calculate %change relative to baselines
dcort_change = dcort %>% 
  dplyr::select(subid, group, Sample, log.ug.dL., assay) %>% 
  spread(key = Sample, value=log.ug.dL.) %>%
  mutate(day1_change = (S2 - S1)/abs(S1) * 100,
         day2_change1 = (T2 - T1)/abs(T1) * 100,
         day2_change2 = (T3 - T1)/abs(T1) * 100,
         day2_avgchange = (day2_change1 + day2_change2)/2)
dcort_change

contrasts(dcort_change$group) = c(-1,1); contrasts(dcort_change$group)
contrasts(dcort_change$assay) = c(-1,1); contrasts(dcort_change$assay) 

dcort_change %>% group_by(subid, group) %>% summarise(n())%>% group_by(group) %>% summarise(n())

# day 1
summary(lm(day1_change ~ group + assay, data=dcort_change))

# day 2
summary(lm(day2_avgchange ~ group + assay, data=dcort_change))
summary(lm(day2_change1 ~ group + assay, data=dcort_change))
summary(lm(day2_change2 ~ group + assay, data=dcort_change))

# day 2: time * group interaction
dcort_combined = dcort_change %>% 
  dplyr::select(subid, group, assay, day2_change1, day2_change2) %>%
  gather(time, cort, day2_change1:day2_change2) %>%
  mutate(time = factor(time))
contrasts(dcort_combined$time) = c(-1,1); contrasts(dcort_combined$time)
summary(lmer(cort ~ time * group + assay + (1|subid), data=dcort_combined))

# day * group interaction
dcort_combined = dcort_change %>% 
  dplyr::select(subid, group, assay, day1_change, day2_avgchange) %>%
  gather(day, cort, day1_change:day2_avgchange) %>%
  mutate(day = factor(day))

contrasts(dcort_combined$day) = c(-1,1)
contrasts(dcort_combined$group)
summary(lmer(cort ~ day * group + assay + (1|subid), data=dcort_combined))

contrasts(dcort_combined$day) = c(0,1); contrasts(dcort_combined$day)
summary(lmer(cort ~ day * group + assay+ (1|subid), data=dcort_combined))

contrasts(dcort_combined$day) = c(1,0); contrasts(dcort_combined$day)
summary(lmer(cort ~ day * group + assay + (1|subid), data=dcort_combined))
```

### Plot
```{r}
d_cort = read.csv('/Volumes/group/awagner/sgagnon/AP/data/cortisol/cort_percentchange_t1-2_testbaseline.csv')
str(d_cort)

dfwc = d_cort %>% group_by(group, Sample) %>%
  summarise(value = mean(log.ug.dL.),
            se = std.error(log.ug.dL.),
            n()) 
dfwc

# dfwc
p3 = ggplot(dfwc, aes(x=Sample, y=value, group=group, color=group)) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=value-se, ymax=value+se), 
                  size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('% Change in cortisol\n(relative to T1)')+
  scale_color_manual(values=c('dodgerblue', 'orange')) +
  xlab('Sample') +
  theme(legend.title=element_blank())

ggsave('~/Experiments/AP/figs/AP_behav_cort.jpeg', p3, dpi=300, width=5, height=4)
p3


# b&w
p3 = ggplot(dfwc, aes(x=Sample, y=value, group=group)) +
    geom_line(position=pos_dodge, size=1.5, aes(linetype=group)) +
    geom_errorbar(width=0, aes(ymin=value-se, ymax=value+se), 
                  size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge, aes(shape=group, fill=group)) + 
  scale_shape_manual(values=c(19,23)) +
  scale_fill_manual(values=c('white', 'white'))+
  ylab('% Change in cortisol\n(relative to T1)')+
  xlab('Sample') +
  theme(legend.title=element_blank())

ggsave('~/Experiments/AP/figs/AP_behav_cort_bw.tiff', p3, dpi=600, width=5, height=4)
p3

```

### Raw cortisol

```{r}
# check out raw levels at T2 and T3
hist(dcort_change$T3)
summary(lm(T2 ~ group + assay, data=dcort_change))
summary(lm(T3 ~ group + assay, data=dcort_change))

# double check on T1
summary(lm(T1 ~ group + assay, data=dcort_change))
boxplot(T1 ~ group + assay, data=dcort_change)

dcort_change %>% group_by(group) %>% summarise(mean(T1), n())

with(dcort_change, table(group, assay))
```
```{r}
dcort_long = dcort_change %>% 
  dplyr::select(subid, group, assay, T1, T2, T3) %>%
  gather(time, value, T1:T3) %>%
  mutate(time=as.integer(substr(time, 2,3)))
dcort_long
contrasts(dcort_long$group)
res = lmer(value ~ scale(time) * group +assay + (1 + scale(time) | subid),
           data=dcort_long)

# is quad effect better? since T1 should be similar, and T2 and 3 elevated under stress
res1 = lmer(value ~ scale(time) * group +assay + (1| subid),
           data=dcort_long)

res2 = lmer(value ~ poly(time, 2) * group + assay +
              (1 | subid),
           data=dcort_long) # cant include random slopes
anova(res1, res2)
anova(res, res2)

# look at full model
summary(res)

# try excluding ap170
summary(lmer(value ~ scale(time) * group +assay + (1 + scale(time) | subid),
           data=dcort_long %>% filter(subid != 'ap170')))

summary(lmer(value ~ scale(time) * group +assay + (1 + scale(time) | subid),
           data=dcort_long %>% filter(subid != 'ap170',
                                      subid != 'ap154')))


# look at simple effects by group
contrasts(dcort_long$group) = c(0,1); contrasts(dcort_long$group)
summary(lmer(value ~ scale(time) * group+ assay  + 
               (1 + scale(time) | subid),
           data=dcort_long))

contrasts(dcort_long$group) = c(1,0); contrasts(dcort_long$group)
summary(lmer(value ~ scale(time) * group+ assay  + 
               (1 + scale(time) | subid),
           data=dcort_long))

contrasts(dcort_long$group) = c(-1,1); contrasts(dcort_long$group)
```

```{r}
dfwc = dcort_long %>% 
  mutate(time = paste0('T', time)) %>%
  group_by(group, time) %>%
  summarise(se = std.error(value),
            value = mean(value),
            n()) 
dfwc

# dfwc
p3 = ggplot(dfwc, aes(x=time, y=value, group=group, 
                      fill=group, color=group)) +
    geom_line(position=pos_dodge, size=1.5, 
              aes(linetype = group)) +
    geom_errorbar(width=0, aes(ymin=value-se, ymax=value+se), 
                  size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge, aes(shape = group)) + 
  ylab('Cortisol (log(ug/dL))')+
  scale_color_manual(values=c('black', 'black')) +
  scale_shape_manual(values=c(21, 17))+
  scale_fill_manual(values=c('white', 'black'))+
  xlab('Sample') +
  theme(legend.title=element_blank())

ggsave('~/Experiments/AP/figs/AP_behav_cort_raw.tiff', p3, dpi=600, width=6, height=4)

ggsave('~/Experiments/AP/figs/AP_behav_cort_raw_150dpi.tiff', p3, dpi=150, width=6, height=4)

p3
```

#### Raw cort by subj
```{r}
p3 = ggplot(dcort_long %>% 
  mutate(time = paste0('T', time)), 
  aes(x=time, y=value, group=subid, 
      color=group)) +
    geom_line(position=pos_dodge, size=1, 
              aes(linetype = assay), alpha=.4)+
  ylab('Cortisol (log(ug/dL))')+
  scale_color_manual(values=c('dodgerblue', 'orange')) +
  xlab('Sample') +
  theme(legend.title=element_blank())

ggsave('~/Experiments/AP/figs/AP_behav_cort_raw_bysubj_150dpi.png', p3, dpi=150, width=8, height=4)

p3
```

#### Raw cort by time of day
```{r}
ibl_assay = read.csv('/Users/sgagnon/Dropbox/AP/SNI/data/cortisol/CTRUAnalysis_apr17.csv')

sal_assay = read.csv('/Users/sgagnon/Dropbox/AP/SNI/data/cortisol/salimetrics_data_tod.csv')

dcort_tod = dcort_change %>% 
  dplyr::select(subid, group, assay, T1, T2, T3) %>%
  gather(Sample, value, T1:T3) %>% 
  left_join(ibl_assay %>% 
              dplyr::select(subid, Sample, Time) %>%
               mutate(Time = as.character(Time)),
            by=c("subid", "Sample")) %>%
  left_join(sal_assay %>% 
              separate(sample_id, c('subid', 'Sample')) %>% 
              dplyr::select(subid, Sample, Time) %>%
              mutate(Time = as.character(Time)),
            by=c("subid", "Sample")) %>%
  mutate(Time = ifelse(is.na(Time.x), Time.y, Time.x)) %>%
  dplyr::select(-Time.x, -Time.y) %>%
  arrange(subid, Sample)

# convert times to datetime var -- use arbitrary date
dcort_tod = dcort_tod %>% 
  mutate(date_time = paste0("01-01-2016 ", Time)) %>%
  mutate(date_time = lubridate::mdy_hm(date_time))
dcort_tod

dcort_tod %>% dplyr::select(subid, Sample, date_time) %>% 
  spread(key = Sample, value = date_time) %>%
  mutate(T2-T1, T3-T2, T3-T1)

p3 = ggplot(dcort_tod, aes(x=date_time, y=value, group=subid, 
      color=group)) +
    geom_point(data=dcort_tod %>% filter(Sample == 'T1'), alpha=.4) + 
    geom_line(position=pos_dodge, size=1, 
              aes(linetype = assay), alpha=.4)+
  ylab(expression(paste("Cortisol (log(",mu,"g/dL))", sep="")))+
  scale_color_manual(values=c('dodgerblue', 'orange')) +
  xlab('Time of day') +
  theme(legend.title=element_blank())

dcort_tod %>% group_by(subid, group) %>% summarise(n()) %>% group_by(group) %>% summarise(n())

ggsave('~/Experiments/AP/figs/AP_behav_cort_raw_bysubj_tod_150dpi.png', p3, dpi=150, width=8, height=4)
ggsave('/Users/sgagnon/Dropbox/Stanford/Papers/AP/Figures/AP_supp_figure1.tiff', p3, dpi=600, width=8, height=4)
ggsave('/Users/sgagnon/Dropbox/Stanford/Papers/AP/Figures/AP_supp_figure1_150dpi.png', p3, dpi=150, width=8, height=4)
p3
```

```{r}
dcort_tod = dcort_tod %>%
  mutate(Sample_int=as.integer(substr(Sample, 2,3)))
glimpse(dcort_tod)

write.csv(dcort_tod, '~/Dropbox/AP/SNI/data/cortisol/dcort_tod.csv', row.names = FALSE)


time_diffs = dcort_tod %>% 
  dplyr::select(subid, group, Sample, date_time) %>% 
  spread(Sample, date_time) %>% mutate(t1_to_t2 = T2 - T1,
                                                                                                      t2_to_t3 = T3 - T2,
                    t1_to_t3 = T3 - T1)
time_diffs
mean(time_diffs$t1_to_t2)
mean(time_diffs$t2_to_t3)
mean(time_diffs$t1_to_t3)


dcort_starttime = dcort_tod %>% 
  filter(Sample == 'T1') %>% 
  mutate(date_time_sec = as.numeric(date_time)) %>%
  dplyr::select(subid, date_time_sec)

summary(lmer(value ~ scale(Sample_int) * group + 
               assay + scale(date_time_sec) + 
       (1 + scale(Sample_int)| subid),
           data=dcort_tod %>% left_join(dcort_starttime, by=c('subid'))))
```


## 0b) Questionnaires: 

#### Do ratings on in-scanner valence questionnaires differ between groups?
```{r echo=FALSE, cache=TRUE}
d_q  = read.csv('/Volumes/group/awagner/sgagnon/AP/data/behav/behav_quest.csv')
head(d_q)
d_val = d_q %>%
  filter(subScaleName %in% c('Negative', 'Positive'))
d_val
hist(d_val$adjustedRating)

d_val %>% group_by(subid, group) %>% summarise(n()) %>% group_by(group) %>% summarise(n())
d_val$subScaleName = factor(d_val$subScaleName)
contrasts(d_val$subScaleName) = c(-1,1)
contrasts(d_val$group) = c(-1,1)
contrasts(d_val$shockCond) = c(-1,1)
res = lmer(adjustedRating ~ subScaleName * group * shockCond + 
             (1 + subScaleName*shockCond |subid), data=d_val,
           control=lmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)), REML=TRUE)
summary(res)
```

# how do first 3 stress / 5 control subjs compare
Believe these got phrasing prompting to rate how they feel right now in scanner; directions outside of scanner (pre-task) were to rate how they were feeling during the run; updated for remaining subjs
```{r}
d_val
early_subs = c('ap150', 'ap151', 'ap152', 'ap100', 'ap101', 'ap102', 'ap103', 'ap104')
d_val_early = d_val %>% group_by(subid, group, shockCond, subScaleName) %>% 
  summarise(adjustedRating = mean(adjustedRating)) %>%
  ungroup() %>%
  mutate(sub_timing = ifelse(subid %in% early_subs, 'early', 'late'))

d_val_early %>% filter(group == 'stress-fmri')
ggplot(d_val_early %>% filter(group == 'stress-fmri'), 
       aes(y=adjustedRating, x=shockCond, color=sub_timing)) + 
  geom_point()+
  geom_line(aes(group=subid)) +
  facet_grid(.~subScaleName) +
  ylab('Rating') +
  xlab('Run type')

ggplot(d_val_early %>% filter(group == 'control-fmri'), 
       aes(y=adjustedRating, x=shockCond, color=sub_timing)) + 
  geom_point()+
  geom_line(aes(group=subid)) +
  facet_grid(.~subScaleName) +
  ylab('Rating') +
  xlab('Run type')
```



```{r echo=FALSE, cache=TRUE}
d = d_q %>%
  group_by(group, subScaleName, shockCond, subid) %>%
  summarise(adjustedRating = mean_(adjustedRating))%>% 
  separate(group, c('group', 'study')) %>%
  mutate(group = revalue(group, replace = c('control' = 'Control',
                                            'stress' = 'Stress')))
d
dfwc = d %>% group_by(group, subScaleName, shockCond) %>%
  summarise_each(funs(n(), mean, sd, se=std.error), adjustedRating)
dfwc

p2 = ggplot(dfwc, aes(x=shockCond, y=mean, group=group, fill=group)) +
    geom_bar(position=position_dodge(), stat="identity") +
    geom_errorbar(width=0, aes(ymin=mean-se, ymax=mean+se), 
                  size=1.5, position=position_dodge(.9)) +
  ylab('Rating') +
  xlab('Run type') +
  facet_grid(.~subScaleName)+
  scale_fill_manual(values=palette) +
  theme(legend.title=element_blank())

ggsave('~/Experiments/AP/figs/AP_inscanner_emo.jpeg', dpi=300, width=8, height=4)
p2

## plot all participants too
p2 = ggplot(dfwc, aes(x=subScaleName, y=mean, 
                      group=shockCond, fill=shockCond)) +
    geom_bar(position=position_dodge(), stat="identity") +
    geom_errorbar(width=0, aes(ymin=mean-se, ymax=mean+se), 
                  size=1.5, position=position_dodge(.9)) +
  ylab('Rating') +
  facet_grid(.~group)+
  scale_fill_manual(values=c('mediumpurple', 'darkorange')) +
  theme(legend.title=element_blank())
p2

p = ggplot(d, 
       aes(x=subScaleName, y=adjustedRating, 
           group=shockCond, color=shockCond)) + 
   facet_grid(.~group) +
  geom_point(pch = 19, position = position_jitterdodge(), 
             alpha=.2, size=1.5)+
  scale_x_discrete(name = "") +
  geom_point(data = dfwc, aes(y=mean), position=position_dodge(.9), 
             alpha=1, size = 2.5, shape=19) +
  geom_errorbar(data = dfwc, width=0,
                aes(y=mean, ymin=mean-se, ymax=mean+se),
                size=1.5, position=position_dodge(.9), alpha=1) +
  scale_color_manual(values=c('#0072b2', '#d55e00')) +
  ylab('Rating')+
  theme(legend.title=element_blank(), 
        legend.position='none',
        strip.text = element_text(size=20),
        strip.background = element_rect(colour="white", fill="white"))
p
ggsave('~/Dropbox/Stanford/Papers/AP/Figures/AP_supp_figure1b.tiff', dpi=600, width=8, height=4)
p


p = ggplot(d, 
       aes(x=subScaleName, y=adjustedRating, 
           group=shockCond, fill=shockCond)) + 
   facet_grid(.~group) +
  geom_point(position = position_jitterdodge(), aes(shape=shockCond),
             alpha=.2, size=1.5)+
  scale_x_discrete(name = "") +
  geom_errorbar(data = dfwc, width=0,
                aes(y=mean, ymin=mean-se, ymax=mean+se),
                size=1.5, position=position_dodge(.9), alpha=1) +
  geom_point(data = dfwc, aes(y=mean, shape=shockCond), position=position_dodge(.9), 
             alpha=1, size = 2.5) +
  scale_fill_manual(values=c('black', 'white')) +
  scale_shape_manual(values=c(15, 23))+
  ylab('Rating')+
  theme(legend.title=element_blank(),
        strip.text = element_text(size=20),
        strip.background = element_rect(colour="white", fill="white"))
p
ggsave('~/Dropbox/Stanford/Papers/AP/Figures/AP_figure1c.tiff', dpi=600, width=9, height=4)
p
```

```{r cache=TRUE}
head(d_val)
data = d_val %>% group_by(subid, group, subScaleName, shockCond) %>%
  summarise(adjustedRating = mean(adjustedRating))

# control diff?
bartlett.test(adjustedRating ~ shockCond, data=data[(data$subScaleName == 'Negative') &
                                                    (data$group == 'control-fmri'),])
t.test(adjustedRating ~ shockCond, data=data[(data$subScaleName == 'Negative') &
                                               (data$group == 'control-fmri'),], 
       paired=T, var.equal=TRUE)
bartlett.test(adjustedRating ~ shockCond, data=data[(data$subScaleName == 'Positive') &
                                                    (data$group == 'control-fmri'),])
t.test(adjustedRating ~ shockCond, data=data[(data$subScaleName == 'Positive') &
                                               (data$group == 'control-fmri'),], 
       paired=T, var.equal=TRUE)

# stress diff?
bartlett.test(adjustedRating ~ shockCond, data=data[(data$subScaleName == 'Negative') &
                                                    (data$group == 'stress-fmri'),])
t.test(adjustedRating ~ shockCond, data=data[(data$subScaleName == 'Negative') &
                                               (data$group == 'stress-fmri'),], 
       paired=T, var.equal=TRUE)
bartlett.test(adjustedRating ~ shockCond, data=data[(data$subScaleName == 'Positive') &
                                                    (data$group == 'stress-fmri'),])
t.test(adjustedRating ~ shockCond, data=data[(data$subScaleName == 'Positive') &
                                               (data$group == 'stress-fmri'),], 
       paired=T, var.equal=TRUE)

# other
bartlett.test(adjustedRating ~ group, data=data[(data$subScaleName == 'Negative') & 
                                            (data$shockCond == 'threat'),])
t.test(adjustedRating ~ group, data=data[(data$subScaleName == 'Negative') & 
                                            (data$shockCond == 'threat'),], var.equal=TRUE)
t.test(adjustedRating ~ group, data=data[(data$subScaleName == 'Negative') & 
                                            (data$shockCond == 'safe'),], var.equal=TRUE)
t.test(adjustedRating ~ group, data=data[(data$subScaleName == 'Positive') & 
                                            (data$shockCond == 'threat'),], var.equal=TRUE)
t.test(adjustedRating ~ group, data=data[(data$subScaleName == 'Positive') & 
                                            (data$shockCond == 'safe'),], var.equal=TRUE)
```


#### Do ratings on in-scanner arousal questionnaires differ between groups?
```{r echo=FALSE, cache=TRUE}
d_aro = d_q %>%
  filter(subScaleName %in% c('Arousal'))
hist(d_aro$adjustedRating)

contrasts(d_aro$group) = c(-1,1)
contrasts(d_aro$shockCond) = c(-1,1)
res = lmer(adjustedRating ~ group * shockCond + (1 + shockCond|subid), data=d_aro, REML=TRUE)
summary(res)

data = d_aro %>% group_by(subid, group, shockCond) %>%
  summarise(adjustedRating = mean(adjustedRating))

bartlett.test(adjustedRating ~ group, data=data[(data$shockCond == 'threat'),])
t.test(adjustedRating ~ group, data=data[(data$shockCond == 'threat'),], var.equal=TRUE)
bartlett.test(adjustedRating ~ group, data=data[(data$shockCond == 'safe'),])
t.test(adjustedRating ~ group, data=data[(data$shockCond == 'safe'),], var.equal=TRUE)

bartlett.test(adjustedRating ~ shockCond, data=data[(data$group == 'control-fmri'),])
t.test(adjustedRating ~ shockCond, data=data[(data$group == 'control-fmri'),], paired=T, var.equal=TRUE)
bartlett.test(adjustedRating ~ shockCond, data=data[(data$group == 'stress-fmri'),])
t.test(adjustedRating ~ shockCond, data=data[(data$group == 'stress-fmri'),], paired=T, var.equal=TRUE)
```


#### Do ratings on post-test valence questionnaires differ between groups?
```{r echo=FALSE, cache=TRUE}
d_ratings = read.csv('/Volumes/group/awagner/sgagnon/AP/data/behav/group_info.csv')
head(d_ratings)
# ratings for each variable
# bartlett.test(safe ~ group, data=d_ratings)
# t.test(safe ~ group, data=d_ratings, var.equal=TRUE)
# t.test(happy ~ group, data=d_ratings, var.equal=TRUE)
# t.test(anxious ~ group, data=d_ratings, var.equal=TRUE)
# t.test(stressed ~ group, data=d_ratings, var.equal=TRUE)

# str(d_ratings)
d_ratings_long = d_ratings %>%
  gather("scale", "emo_rating", negative:positive)
dim(d_ratings_long)
d_ratings_long$scale = factor(d_ratings_long$scale)
contrasts(d_ratings_long$scale) = c(-1,1)
contrasts(d_ratings_long$group) = c(-1,1)
res = lmer(emo_rating ~ scale * group + (1 |subid), data=d_ratings_long, REML=TRUE) #can't include scale RE, not enough terms
summary(res)

bartlett.test(negative ~ group, data=d_ratings)
t.test(negative ~ group, data=d_ratings, var.equal=TRUE)

bartlett.test(positive ~ group, data=d_ratings)
t.test(positive ~ group, data=d_ratings, var.equal=TRUE)

d_ratings %>%
  summarise(mean(safe))

ggplot(d_ratings, aes(x=safe, fill=group)) + 
  geom_histogram()
```

Post-test affective ratings, we observed an interaction between group and valence, F(1,90)=12.4948, p < 0.001, such that participants rated feeling significantly more negative (stressed, anxious), t(45) = 3.2618, p < 0.01. Positive ratings (safe, happy) did not significantly differ between groups (p > 0.1). 

```{r, echo=FALSE, cache=TRUE}
d = d_ratings_long %>%
  group_by(subid, group, scale) %>%
  summarise(avg=mean(emo_rating))

g = ggplot(data=d, aes(x=scale, y=avg, fill=group, color=group)) +
  geom_boxplot(alpha=.3) +
  geom_jitter(size=3, alpha=.7, position=position_jitterdodge()) +
  scale_fill_manual(values=palette, guide = guide_legend(title = NULL)) +
  scale_color_manual(values=palette, guide = guide_legend(title = NULL)) +
  ggtitle('') +
  # guides(fill=FALSE, color=FALSE)+
  ylab('Rating') +
  xlab('Valence')
g
```

# 1) Stress effects on memory

## Load in data
```{r}
# note that shock and post trials are filtered out
dtest = read.csv('/Volumes/group/awagner/sgagnon/AP/data/behav/df_test.csv')
with(dtest %>% filter(acc =='H', conf == 'Hi'), table(subid))
with(dtest, table(acc, conf))
head(dtest)
with(dtest, table(acc, cond, resp))

# Some processing to label HC associative hits, and objectively old/new status
dtest = dtest %>%
  mutate(group = stress_group) %>%
  dplyr::select(subid, group, run, trial, cond, 
                shockCond, resp, acc, respRT, reps, conf) %>%
  mutate(subj_status = ifelse(resp == 'foil', 
                              'new', 
                              ifelse(resp %in% c('indoor', 'outdoor'),
                                     'old', 
                                     'no response')),
         acc_num = ifelse(acc %in% c('H', 'CR'), 1, 0),
         acc_SH_num = ifelse(acc %in% c('H', 'CR'), 1, 0),
         acc_SH_num = replace(acc_SH_num, conf=='Lo', 0),
         obj_status = ifelse(cond == 'foil', 'new', 'old'))
# str(dtest)
head(dtest)
dtest %>% filter(subid == 'ap160', run == 5, trial == 13) # make sure tossed (2 shocks in a row, so shock_and_post == 2)

with(dtest, table(acc_num, conf))
with(dtest, table(acc_SH_num, conf, acc))
str(dtest)
```

## 1a) Recognition: dprime

### Calculate dprime
```{r}
# get obj counts
obj_counts = dtest %>% group_by(subid, group, reps, shockCond, obj_status) %>%
  summarise(count = n()) %>%
  rename(trial_type = obj_status) %>%
  ungroup()
unique(dtest$acc)

# get counts by bin
coded_counts = dtest %>% 
  filter(acc %in% c('H', 'SM', 'FA')) %>%
  mutate(acc = ifelse(acc == 'FA', 'fa', 'hit')) %>%
  group_by(subid, group, reps, shockCond, acc) %>%
  summarise(count = n()) %>% 
  ungroup() %>%
  complete(nesting(subid, group), shockCond, nesting(reps, acc), 
           fill = list(count = 0))

# combine hits and olds
d_old = coded_counts %>% filter(acc == 'hit') %>%
  dplyr::select(-acc) %>%
  rename(hits = count) %>%
  right_join(obj_counts %>% 
              filter(trial_type == 'old') %>%
              dplyr::select(-trial_type) %>% 
              rename(olds = count))

# combine fas and news
d_new= coded_counts %>% filter(acc == 'fa') %>%
  dplyr::select(-acc) %>%
  rename(fas = count) %>%
  right_join(obj_counts %>% 
              filter(trial_type == 'new') %>%
              dplyr::select(-trial_type) %>% 
              rename(news = count)) %>%
  dplyr::select(-reps)

# compute hit/fa rates, and other
dmerge = d_old %>% left_join(d_new) %>%
  mutate(hitRate = hits/olds,
         faRate = fas/news,
         halfHit = 0.5/olds,
         halfFA = 0.5/news,
         crRate = 1-faRate,
         reps = factor(reps))

# get summary stats, before adjusting for 0s/1s
dmerge %>% 
  group_by(subid, group) %>%
  summarise(hitRate = mean(hitRate), 
            faRate = mean(faRate), 
            crRate = mean(crRate)) %>%
  group_by(group) %>%
  summarise_each(funs(mean, std.error, length))

dmerge %>% 
  group_by(subid, group, shockCond) %>%
  summarise(hitRate = mean(hitRate), 
            faRate = mean(faRate), 
            crRate = mean(crRate)) %>%
  group_by(group, shockCond) %>%
  summarise_each(funs(mean, std.error, length))

# replace 0 and 1s
dmerge = dmerge %>% mutate(faRate=ifelse(faRate==0, halfFA, faRate),
                  faRate=ifelse(faRate==1, 1-halfFA, faRate),
                  hitRate=ifelse(hitRate==0, halfHit, hitRate),
                  hitRate=ifelse(hitRate==1, 1-halfHit, hitRate))

# calc SDT measures
dmerge = dmerge %>% mutate(dprime = qnorm(hitRate) - qnorm(faRate),
                  c = -(qnorm(hitRate) + qnorm(faRate))/2) %>%
  mutate(reps = factor(reps))

dmerge %>%
  group_by(subid, group) %>%
  summarise(n()) %>%
  group_by(group) %>%
  summarise(n())

dmerge %>%
  group_by(subid, group) %>%
  summarise(dprime = mean(dprime),
            c = mean(c)) %>%
  group_by(group) %>%
  summarise_each(funs(mean, std.error, length))

dmerge %>%
  group_by(subid, group, shockCond) %>%
  summarise(dprime = mean(dprime),
            c = mean(c)) %>%
  group_by(group, shockCond) %>%
  summarise_each(funs(mean, std.error, length))

item_d = dmerge
```

### Dprime stats
```{r}
dmerge %>%
  group_by(subid, group) %>%
  summarise(n()) %>%
  group_by(group) %>%
  summarise(n())

contrasts(dmerge$group) = c(1,-1)
contrasts(dmerge$shockCond) = c(1,-1)
contrasts(dmerge$reps) = c(-1,1)
summary(lmer(dprime ~ group * shockCond * reps + 
               (1 + shockCond + reps| subid), data=dmerge)) #not enough obs for interaction RE

# effect of shockCond within stress:
summary(lmer(dprime ~ shockCond * reps + 
               (1 + shockCond + reps| subid), data=dmerge %>% filter(group == 'stress')))

# stress means by run type
dmerge %>% filter(group == 'stress') %>%
  group_by(shockCond) %>%
  summarise(dprime = mean(dprime)) 

# effect of group just within safe?
summary(lmer(dprime ~ group * reps + 
               (1| subid), data=dmerge %>% filter(shockCond == 'safe')))
```

### Criterion stats
```{r}
summary(lmer(c ~ group * shockCond * reps + 
               (1 + shockCond + reps| subid), data=dmerge)) #not enough obs for interaction RE
```


### Does cortisol affect dprime?
```{r}
d_cort = read.csv('/Volumes/group/awagner/sgagnon/AP/data/cortisol/cort_percentchange_testbaseline.csv')

dprime_cort = dmerge %>% left_join(d_cort)
str(dprime_cort)

contrasts(dprime_cort$assay) = c(1,-1)
contrasts(dprime_cort$shockCond) = c(1,-1)
contrasts(dprime_cort$reps) = c(-1,1)
fit = lmer(dprime ~ scale(log.ug.dL.) * shockCond * reps + assay +
               (1 + shockCond + reps| subid), data=dprime_cort)
fit2 = lmer(dprime ~ poly(log.ug.dL.,2) * shockCond * reps + assay +
               (1 + shockCond + reps| subid), data=dprime_cort)
anova(fit, fit2)
summary(fit)
```


### Just to check, break down dprime also by indoor/outdoor associate
(doesn't make as much sense here, since collapsing across associates in saying)
```{r}
# get obj counts
obj_counts = dtest %>% group_by(subid, group, cond, reps, shockCond, obj_status) %>%
  summarise(count = n()) %>%
  rename(trial_type = obj_status) %>%
  ungroup()

# get counts by bin
coded_counts = dtest %>% 
  filter(acc %in% c('H', 'SM', 'FA')) %>%
  mutate(acc = ifelse(acc == 'FA', 'fa', 'hit')) %>%
  group_by(subid, group, cond, reps, shockCond, acc) %>%
  summarise(count = n()) %>% 
  ungroup() %>%
  complete(nesting(subid, group), shockCond, nesting(cond, reps, acc), 
           fill = list(count = 0))

# combine hits and olds
d_old = coded_counts %>% filter(acc == 'hit') %>%
  dplyr::select(-acc) %>%
  rename(hits = count) %>%
  right_join(obj_counts %>% 
              filter(trial_type == 'old') %>%
              dplyr::select(-trial_type) %>% 
              rename(olds = count))

# combine fas and news
d_new= coded_counts %>% filter(acc == 'fa') %>%
  dplyr::select(-acc) %>%
  rename(fas = count) %>%
  right_join(obj_counts %>% 
              filter(trial_type == 'new') %>%
              dplyr::select(-trial_type) %>% 
              rename(news = count)) %>%
  dplyr::select(-reps, -cond)

# compute hit/fa rates, and other
dmerge = d_old %>% left_join(d_new) %>%
  mutate(hitRate = hits/olds,
         faRate = fas/news,
         halfHit = 0.5/olds,
         halfFA = 0.5/news)

dmerge %>% group_by(subid, group, cond) %>%
  summarise(hitRate = mean(hitRate), faRate = mean(faRate)) %>%
  group_by(group, cond) %>%
  summarise_each(funs(mean)) %>%
  mutate(crRate = 1-faRate)

# replace 0 and 1s
dmerge = dmerge %>% mutate(faRate=ifelse(faRate==0, halfFA, faRate),
                  faRate=ifelse(faRate==1, 1-halfFA, faRate),
                  hitRate=ifelse(hitRate==0, halfHit, hitRate),
                  hitRate=ifelse(hitRate==1, 1-halfHit, hitRate))

# calc SDT measures
dmerge = dmerge %>% mutate(dprime = qnorm(hitRate) - qnorm(faRate),
                  c = -(qnorm(hitRate) + qnorm(faRate))/2) %>%
  mutate(reps = factor(reps), 
         cond = factor(cond))

dmerge

contrasts(dmerge$group) = c(1,-1)
contrasts(dmerge$shockCond) = c(1,-1)
contrasts(dmerge$reps) = c(-1,1)
contrasts(dmerge$cond) = c(-1,1)
summary(lmer(dprime ~ group * shockCond * reps + cond + 
               (1 + shockCond + reps + cond| subid), data=dmerge),
        control=lmerControl(optimizer="bobyqa",optCtrl=list(maxfun=5e5))) # failed to converge w/diff optimizers/increasing iters

# double check that no group:cond interaction
summary(lmer(dprime ~ group * shockCond * reps + cond + group:cond + 
               (1 + shockCond + reps + cond| subid), data=dmerge),
        control=lmerControl(optimizer="bobyqa",optCtrl=list(maxfun=5e5))) # failed to converge w/diff optimizers/increasing iters
```


## 1b) HC associative dprime

### Calculate HC associative dprimes/criterion
```{r}
# get obj counts
obj_counts = dtest %>% filter(cond %in% c('indoor',
                                          'outdoor')) %>%
  group_by(subid, group, reps, 
           cond, shockCond, obj_status) %>%
  summarise(count = n()) %>%
  rename(trial_type = obj_status) %>%
  ungroup() %>%
  complete(nesting(subid, group), shockCond, nesting(reps, cond, trial_type), 
           fill = list(count = 0))
obj_counts
# write.csv(obj_counts, '~/Desktop/obj_counts.csv')

# get counts for hi conf assoc hits and misses
coded_counts = dtest %>% 
  filter(acc %in% c('H', 'SM'),
         conf == 'Hi') %>%
  group_by(subid, group, reps, shockCond, resp, cond, acc) %>%
  summarise(count = n()) %>% 
  ungroup() %>%
  complete(nesting(subid, group), shockCond, nesting(reps, acc, cond, resp), 
           fill = list(count = 0))
coded_counts
# write.csv(coded_counts, '~/Desktop/coded_counts.csv')

# combine hits and olds (on condition)
hit_rates = coded_counts %>%
  filter(acc == 'H') %>%
  rename(resp_rate = count) %>%
  right_join(obj_counts %>% 
              filter(trial_type == 'old') %>%
              dplyr::select(-trial_type) %>% 
              rename(olds = count)) %>%
     mutate(H = resp_rate/olds, half_rate = 0.5/olds,
         H=ifelse(H==0, half_rate, H),
         H=ifelse(H==1, 1-half_rate, H)) %>%
  dplyr::select(-resp_rate, -olds, -half_rate, -cond, -acc)
hit_rates

# combine SHs (response) and olds (condition)
sm_rates = coded_counts %>%
  filter(acc == 'SM') %>%
  rename(resp_rate = count) %>%
  right_join(obj_counts %>% 
              filter(trial_type == 'old') %>%
              dplyr::select(-trial_type) %>% 
              rename(olds = count)) %>%
     mutate(SM = resp_rate/olds, half_rate = 0.5/olds,
         SM=ifelse(SM==0, half_rate, SM),
         SM=ifelse(SM==1, 1-half_rate, SM)) %>%
  dplyr::select(-resp_rate, -olds, -half_rate, -cond, -acc)
sm_rates

# join on response (e.g., "indoor" hit to indoor - fa "indoor"" to outdoor)
dmerge = hit_rates %>% left_join(sm_rates)
dmerge


# calc SDT measures
dmerge = dmerge %>% mutate(dprime = qnorm(H) - qnorm(SM),
                           c = -(qnorm(H) + qnorm(SM))/2) %>%
  mutate(reps = factor(reps),
         resp = factor(resp))
dmerge

dmerge %>% group_by(subid, group) %>%
  summarise(hitRate=mean(H), 
            smRate=mean(SM), 
            dprime=mean(dprime),
            c = mean(c)) %>%
  group_by(group) %>%
  summarise_each(funs(mean))

assoc_d = dmerge

assoc_d
```

### HC assoc dprime stats
```{r}
contrasts(dmerge$group) = c(1,-1)
contrasts(dmerge$shockCond) = c(1,-1)
contrasts(dmerge$reps) = c(-1,1)
contrasts(dmerge$resp) = c(-1,1); contrasts(dmerge$resp)
# hist(dmerge$dprime)
# dmerge

dmerge %>% group_by(subid, group) %>% summarise(n()) %>% group_by(group) %>% summarise(n())

# include group interactions by resp, shockcond, reps
summary(lmer(dprime ~ group * (shockCond * reps + resp) + 
               (1 + reps + shockCond + resp| subid), data=dmerge,
             control=lmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e5))))

# does effect hold looking at safe block?
summary(lmer(dprime ~ group * (reps + resp) + 
               (1 + reps + resp| subid), data=dmerge %>% filter(shockCond == 'safe'),
             control=lmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e5))))

# is effect of group diff for 2 vs 4 reps?
summary(lmer(dprime ~ group * (shockCond + resp) + 
               (1 + shockCond + resp| subid), data=dmerge %>% filter(reps == 2),
             control=lmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e5))))
summary(lmer(dprime ~ group * (shockCond + resp) + 
               (1 + shockCond + resp| subid), data=dmerge %>% filter(reps == 4),
             control=lmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e5))))

# check out group x reps interaction + shockCond just within stress group
summary(lmer(dprime ~ shockCond * reps + resp + 
               (1 + reps * shockCond + resp| subid), 
             data=dmerge %>% filter(group == 'stress'),
             control=lmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e5))))

# simple effects to double check:
# control
contrasts(dmerge$group) = c(0,1); contrasts(dmerge$group)
summary(lmer(dprime ~ group * (shockCond * reps + resp) + 
               (1 + reps + shockCond + resp| subid), data=dmerge,
             control=lmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e5))))
# stress
contrasts(dmerge$group) = c(1,0); contrasts(dmerge$group)
summary(lmer(dprime ~ group * (shockCond * reps + resp) + 
               (1 + reps + shockCond + resp| subid), data=dmerge,
             control=lmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e5))))
contrasts(dmerge$group) = c(1,-1)


# stress means by run type
dmerge %>% filter(group == 'stress') %>%
  group_by(subid, shockCond) %>%
  summarise(dprime = mean(dprime)) %>%
  group_by(shockCond) %>%
  summarise(dprime = mean(dprime)) 
```

### What about high confidence FA rates?
```{r}
# Calculate high confidence FA rate
dat_fa = dtest %>%
  filter(cond %in% c('foil'),
         acc == 'FA') %>%
  group_by(subid, group, shockCond, conf) %>%
  summarise(count=n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), shockCond, conf, 
           fill = list(count = 0)) %>%
  filter(conf == 'Hi')
head(dat_fa)

new_counts = dtest %>%
  filter(cond %in% c('foil')) %>%
  mutate(cond = factor(cond),
         acc = factor(acc)) %>%
  group_by(subid, group, shockCond) %>%
  summarise(count=n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), shockCond, fill = list(count = 0))
min(new_counts$count)
head(new_counts)

dat_fa = dat_fa %>% 
  left_join(new_counts %>% rename(new_count = count)) %>%
  mutate(fa_rate = count/new_count)

head(dat_fa)
dat_fa %>% group_by(subid, group, shockCond) %>% 
  summarise(fa_rate = mean(fa_rate)) %>%
  group_by(group, shockCond) %>% 
  summarise(mean_fa = mean(fa_rate), se=std.error(fa_rate), n())

dat_fa %>% group_by(subid, group) %>% 
  summarise(fa_rate = mean(fa_rate)) %>%
  group_by(group) %>%
  summarise(mean_fa = mean(fa_rate), se=std.error(fa_rate), n())
```

```{r}
hist(dat_fa$fa_rate)
hist(logit(dat_fa$fa_rate))

dat_fa = dat_fa %>% mutate(fa_rate_log = car::logit(fa_rate))

contrasts(dat_fa$group) = c(1,-1); contrasts(dat_fa$group)
contrasts(dat_fa$shockCond) = c(1,-1); contrasts(dat_fa$shockCond)

summary(lmer(fa_rate_log ~  group*shockCond + 
               (1 | subid), data=dat_fa,
             control=lmerControl(optimizer="bobyqa",optCtrl=list(maxfun=5e5))))
```

### All assoc FA rates:
```{r}
# Calculate high confidence FA rate
dat_fa = dtest %>%
  filter(cond %in% c('foil'),
         acc == 'FA') %>%
  group_by(subid, group, shockCond, conf) %>%
  summarise(count=n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), shockCond, conf, 
           fill = list(count = 0))
head(dat_fa)

new_counts = dtest %>%
  filter(cond %in% c('foil')) %>%
  mutate(cond = factor(cond),
         acc = factor(acc)) %>%
  group_by(subid, group, shockCond) %>%
  summarise(count=n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), shockCond, 
           fill = list(count = 0))

dat_fa = dat_fa %>% 
  left_join(new_counts %>% rename(new_count = count)) %>%
  mutate(fa_rate = count/new_count)

dat_fa %>% group_by(subid, group, conf) %>% 
  summarise(fa_rate = mean(fa_rate)) %>%
  group_by(group, conf) %>%
  summarise(mean_fa = mean(fa_rate), se=std.error(fa_rate), n())

dat_fa %>% group_by(subid, group, shockCond, conf) %>% 
  summarise(fa_rate = mean(fa_rate)) %>%
  group_by(group, conf, shockCond) %>%
  summarise(mean_fa = mean(fa_rate), se=std.error(fa_rate), n())

```

### All assoc H rates:
```{r}
# Calculate high confidence H rates
dat_fa = dtest %>%
  filter(cond %in% c('indoor', 'outdoor'),
         acc == 'H') %>%
  mutate(cond = factor(cond),
         acc = factor(acc)) %>%
  group_by(subid, group, shockCond, conf, cond) %>%
  summarise(count=n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), shockCond, conf, cond,
           fill = list(count = 0))
head(dat_fa)

old_counts = dtest %>%
  filter(cond %in% c('indoor', 'outdoor')) %>%
  mutate(cond = factor(cond),
         acc = factor(acc)) %>%
  group_by(subid, group, shockCond, cond) %>%
  summarise(count=n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), shockCond, cond,
           fill = list(count = 0))

dat_fa = dat_fa %>% 
  left_join(old_counts %>% rename(old_count = count)) %>%
  mutate(hit_rate = count/old_count)

dat_fa %>% group_by(subid, group, conf) %>% 
  summarise(hit_rate = mean(hit_rate)) %>%
  group_by(group, conf) %>%
  summarise(mean(hit_rate), std.error(hit_rate), n())

dat_fa %>% filter(group == 'stress') %>%
  group_by(subid, group, conf, shockCond) %>% 
  summarise(hit_rate = mean(hit_rate)) %>%
  group_by(group, conf, shockCond) %>%
  summarise(mean(hit_rate), std.error(hit_rate), n())
```
### All assoc error (miss) rates:
```{r}
# Calculate high confidence H rates
dat_fa = dtest %>%
  filter(cond %in% c('indoor', 'outdoor'),
         acc == 'SM') %>%
  mutate(cond = factor(cond),
         acc = factor(acc)) %>%
  group_by(subid, group, shockCond, conf, cond) %>%
  summarise(count=n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), shockCond, conf, cond,
           fill = list(count = 0))
head(dat_fa)

old_counts = dtest %>%
  filter(cond %in% c('indoor', 'outdoor')) %>%
  mutate(cond = factor(cond),
         acc = factor(acc)) %>%
  group_by(subid, group, shockCond, cond) %>%
  summarise(count=n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), shockCond, cond,
           fill = list(count = 0))

dat_fa = dat_fa %>% 
  left_join(old_counts %>% rename(old_count = count)) %>%
  mutate(hit_rate = count/old_count)

dat_fa %>% group_by(subid, group, conf) %>% 
  summarise(hit_rate = mean(hit_rate)) %>%
  group_by(group, conf) %>%
  summarise(mean(hit_rate), std.error(hit_rate), n())

dat_fa %>% filter(group == 'stress') %>%
  group_by(subid, group, conf, shockCond) %>% 
  summarise(hit_rate = mean(hit_rate)) %>%
  group_by(group, conf, shockCond) %>%
  summarise(mean(hit_rate), std.error(hit_rate), n())
```


### Does cortisol affect assoc dprime?
```{r}
### Does cortisol affect assoc dprime?
d_cort = read.csv('/Volumes/group/awagner/sgagnon/AP/data/cortisol/cort_percentchange_testbaseline.csv')

dprime_cort = dmerge %>% left_join(d_cort)
str(dprime_cort)

contrasts(dprime_cort$shockCond) = c(1,-1)
contrasts(dprime_cort$reps) = c(-1,1)
contrasts(dprime_cort$assay) = c(-1,1)
contrasts(dprime_cort$resp) = c(-1,1); contrasts(dprime_cort$resp)

# include group interactions by resp, shockcond, reps
fit = lmer(dprime ~ scale(log.ug.dL.) * (shockCond * reps + resp) + assay+
               (1 + reps + shockCond + resp| subid), data=dprime_cort,
             control=lmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e5)))
fit2 = lmer(dprime ~ poly(log.ug.dL.,2) * (shockCond * reps + resp) + assay+
               (1 + reps + shockCond + resp| subid), data=dprime_cort,
             control=lmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e5)))
anova(fit, fit2)
summary(fit)
```



## 1c) Plot item and assoc dprimes
```{r}
# merge these 2 measures:
item_d = item_d %>% 
  dplyr::select(subid, group, reps, shockCond, dprime) %>%
  group_by(subid, group, reps, shockCond) %>%
  summarise(item_d = mean(dprime))

assoc_d = assoc_d %>% 
  dplyr::select(subid, group, reps, shockCond, dprime) %>%
  group_by(subid, group, reps, shockCond) %>%
  summarise(assoc_d = mean(dprime))

combined_d = item_d %>% left_join(assoc_d) %>% 
  ungroup() %>%
  gather(key = 'cond', value = 'dprime', item_d:assoc_d) %>%
  mutate(cond = factor(cond), reps=factor(reps))
combined_d

davg = combined_d %>%
  group_by(subid, group, cond, reps) %>%
  summarise(dprime = mean(dprime)) %>% 
  group_by(group, cond, reps) %>%
  summarise(mean = mean(dprime),
            se = std.error(dprime),
            sterr = sd(dprime)/sqrt(n()),
            ci = error <- qt(1-(.05/2),df=n()-1)*sd(dprime)/sqrt(n()),
            sd = sd(dprime),
            n()) %>%
  ungroup() %>%
  mutate(cond = as.character(cond)) %>%
  mutate(cond=replace(cond, cond=='assoc_d', 'Associative'),
         cond=replace(cond, cond=='item_d', 'Item')) %>%
  mutate(cond = factor(cond, levels=c('Item', 'Associative'))) %>%
  mutate(reps = as.character(reps)) %>%
  mutate(reps=replace(reps, reps=='2', 'weak'),
         reps=replace(reps, reps=='4', 'strong')) %>%
  mutate(reps = factor(reps, levels=c('weak', 'strong')))

davg

p = ggplot(davg, 
       aes(x=reps, y=mean, group=group, fill=group)) + 
   facet_grid(.~cond, scales = "free_x", space = "free_x") +
    geom_bar(position=position_dodge(), stat="identity") + 
    geom_errorbar(width=0, aes(ymin=mean-se, 
                               ymax=mean+se), size=1.5, position=position_dodge(.9)) +
    scale_fill_manual(values=c('dodgerblue', 'orange')) +
  ylab(expression(paste('Discriminability (',italic("d'"),')')))+
  xlab('Encoding strength') +
    theme(legend.title=element_blank(), axis.title.y=element_text(face="italic"))

ggsave('~/Experiments/AP/figs/AP_behav_dprimes_bystrength.jpeg', dpi=150, width=8, height=4)
p


dcomb = combined_d %>%
  group_by(subid, group, cond, reps) %>%
  summarise(dprime = mean(dprime)) %>% 
  ungroup() %>%
  mutate(cond = as.character(cond)) %>%
  mutate(cond=replace(cond, cond=='assoc_d', 'Associative'),
         cond=replace(cond, cond=='item_d', 'Item')) %>%
  mutate(cond = factor(cond, levels=c('Item', 'Associative'))) %>%
  mutate(reps = as.character(reps)) %>%
  mutate(reps=replace(reps, reps=='2', 'weak'),
         reps=replace(reps, reps=='4', 'strong')) %>%
  mutate(reps = factor(reps, levels=c('weak', 'strong'))) %>%
  ungroup()
dcomb
p = ggplot(dcomb, 
       aes(x=reps, y=dprime, color=group)) + 
   facet_grid(.~cond) +
   geom_boxplot(position = position_dodge(width = .85),
                outlier.shape = NA) +
  scale_x_discrete(name = "Encoding strength") +
  geom_point(pch = 21, position = position_jitterdodge())+
  scale_color_manual(values=c('dodgerblue', 'orange')) +
  ylab(expression(paste('Discriminability (',italic("d'"),')')))+
  theme(legend.title=element_blank(), axis.title.y=element_text(face="italic"))

ggsave('~/Experiments/AP/figs/AP_behav_dprimes_bystrength_boxplot.jpeg', dpi=150, width=8, height=4)
p


p = ggplot(dcomb, 
       aes(x=reps, y=dprime, color=group)) + 
   facet_grid(.~cond) +
   stat_summary(fun.y = "mean", size = 9, shape=18, alpha=.7,
                geom = "point", position=position_dodge(.9)) +
  scale_x_discrete(name = "Encoding strength") +
  geom_point(pch = 21, position = position_jitterdodge(), alpha=1, size=3)+
  scale_color_manual(values=c('dodgerblue', 'orange')) +
  ylab(expression(paste('Discriminability (',italic("d'"),')')))+
  theme(legend.title=element_blank(), axis.title.y=element_text(face="italic"))
p
ggsave('~/Experiments/AP/figs/AP_behav_dprimes_bystrength_stripplot.jpeg', dpi=150, width=8, height=4)
p

# point plot with points
p = ggplot(dcomb, 
       aes(x=reps, y=dprime, color=group)) + 
   facet_grid(.~cond) +
   # stat_summary(fun.y = "mean", size = 9, shape=18, alpha=.7,
   #              geom = "point", position=position_dodge(.9)) +
  geom_point(pch = 21, position = position_jitterdodge(), 
             alpha=1, size=3)+
  scale_x_discrete(name = "Encoding strength") +
  geom_point(data = davg, aes(y=mean), position=position_dodge(.9), 
             alpha=.7, size = 3, shape=18) +
  geom_errorbar(data = davg, width=0,
                aes(y=mean, ymin=mean-se, ymax=mean+se),
                size=2, position=position_dodge(.9), alpha=.7) +
  scale_color_manual(values=c('dodgerblue', 'orange')) +
  ylab(expression(paste('Discriminability (',italic("d'"),')')))+
  theme(legend.title=element_blank(), axis.title.y=element_text(face="italic"))
p

p = ggplot(dcomb, 
       aes(x=reps, y=dprime, color=group)) + 
   facet_grid(.~cond) +
  geom_point(pch = 21, position = position_jitterdodge(), 
             alpha=.5, size=2)+
  scale_x_discrete(name = "Encoding strength") +
  geom_point(data = davg, aes(y=mean), position=position_dodge(.9), 
             alpha=.8, size = 2.5, shape=19) +
  geom_errorbar(data = davg, width=0,
                aes(y=mean, ymin=mean-se, ymax=mean+se),
                size=1.5, position=position_dodge(.9), alpha=.8) +
  scale_color_manual(values=c('dodgerblue', 'orange')) +
  ylab(expression(paste('Discriminability (',italic("d'"),')')))+
  theme(legend.title=element_blank(), axis.title.y=element_text(face="italic"))

ggsave('~/Experiments/AP/figs/AP_behav_dprimes_bystrength_stripplot_se.jpeg', dpi=600, width=8, height=4)
p


p = ggplot(dcomb, 
       aes(x=reps, y=dprime, color=group)) + 
   facet_grid(.~cond) +
  geom_point(pch = 19, position = position_jitterdodge(), 
             alpha=.2, size=1.5)+
  scale_x_discrete(name = "Encoding strength") +
  geom_point(data = davg, aes(y=mean), position=position_dodge(.9), 
             alpha=1, size = 2.5, shape=19) +
  geom_errorbar(data = davg, width=0,
                aes(y=mean, ymin=mean-se, ymax=mean+se),
                size=1.5, position=position_dodge(.9), alpha=1) +
  scale_color_manual(values=c('dodgerblue', 'orange')) +
  ylab(expression(paste('Discriminability (',italic("d'"),')')))+
  theme_classic(base_size = 14)+
  theme(legend.title=element_blank(), 
        strip.text = element_text(size=14),
        strip.background = element_rect(colour="white", fill="white"),
        axis.title.y=element_text(face="italic"))

ggsave('~/Experiments/AP/figs/AP_behav_dprimes_bystrength_stripplot_se_v2.jpeg', dpi=600, width=6.69, height=3)
ggsave('~/Dropbox/Stanford/Papers/AP/Figures/AP_figure2_color.tiff', dpi=600, width=6.69, height=3)
p

dcomb
p = ggplot(dcomb, aes(x=reps, y=dprime, group=group, fill=group)) + 
   facet_grid(.~cond) +
  geom_errorbar(data = davg, width=0,
                aes(y=mean, ymin=mean-se, ymax=mean+se),
                size=1.5, position=position_dodge(.9), alpha=1) +
  geom_point(aes(shape=group), position = position_jitterdodge(), 
             alpha=.2, size=1.5)+
  scale_x_discrete(name = "Encoding strength") +
  geom_point(data = davg, aes(y=mean, shape=group), 
             position=position_dodge(.9), 
             alpha=1, size = 2.5) +
  scale_shape_manual(values=c(19,23)) +
  scale_fill_manual(values=c('white', 'white'))+
  ylab(expression(paste('Discriminability (',italic("d'"),')')))+
  theme_classic(base_size = 14)+
  theme(legend.title=element_blank(), 
        strip.text = element_text(size=14),
        strip.background = element_rect(colour="white", fill="white"),
        axis.title.y=element_text(face="italic"))
ggsave('~/Dropbox/Stanford/Papers/AP/Figures/AP_figure2_bw.tiff', 
       dpi=600, width=6.69, height=3)
ggsave('~/Dropbox/Stanford/Papers/AP/Figures/AP_figure2_bw_dpi150.tiff', 
       dpi=150, width=6.69, height=3)
p


### COLOR CODE 2 SUBJS
dcomb = dcomb %>% mutate(subj_med = 
                           ifelse(subid %in% c('ap170'), 'GC+b2-agonist', 
                                  ifelse(subid == 'ap154', 'b2-agonist',
                                         'none')))
dcomb
p = ggplot(dcomb, aes(x=reps, y=dprime, group=group, 
                      fill=group)) + 
   facet_grid(.~cond) +
  geom_errorbar(data = davg, width=0,
                aes(y=mean, ymin=mean-se, ymax=mean+se),
                size=1.5, position=position_dodge(.9), alpha=1) +
  scale_x_discrete(name = "Encoding strength") +
  geom_point(data = davg, aes(y=mean, shape=group), 
             position=position_dodge(.9), 
             alpha=1, size = 3) +
    geom_point(aes(shape=group,                   
                 color=subj_med), 
               position = position_jitterdodge(), 
             alpha=1, size=1.5)+
  scale_shape_manual(values=c(19,23)) +
  scale_fill_manual(values=c('white', 'white'))+
  scale_color_manual(values=c('red', 'blue', 'gray'))+
  ylab(expression(paste('Discriminability (',italic("d'"),')')))+
  theme_classic(base_size = 14)+
  theme(legend.title=element_blank(), 
        strip.text = element_text(size=14),
        strip.background = element_rect(colour="white", fill="white"),
        axis.title.y=element_text(face="italic"))
ggsave('~/Dropbox/Stanford/Papers/AP/Figures/AP_figure2_codedbymed_dpi150.tiff', 
       dpi=150, width=6.69, height=3)
p



ann_text <- data.frame(reps = c(.75, 1.25), dprime = c(4, 3.5),
                       group=c('control', 'stress'),
                        lab=c("control", "stress"),
                        cond = factor(c('Item'), levels = c("Item", "Associative")))
# 95% CI
p = ggplot(dcomb, 
       aes(x=reps, y=dprime, color=group)) + 
   facet_grid(.~cond) +
  geom_point(pch = 19, position = position_jitterdodge(), 
             alpha=.2, size=1.5)+
  scale_x_discrete(name = "Encoding strength") +
  geom_errorbar(data = davg, width=0,
                aes(y=mean, ymin=mean-ci, ymax=mean+ci),
                size=1.5, position=position_dodge(.9), alpha=1) +
  geom_point(data = davg, aes(y=mean), position=position_dodge(.9),
             alpha=1, size = 4, shape=1) +
  scale_color_manual(values=c('dodgerblue', 'orange')) +
  ylab(expression(paste('Discriminability (',italic("d'"),')')))+
  geom_text(data = ann_text,aes(label =lab)) +
  theme_classic(base_size = 14)+
  theme(legend.title=element_blank(), 
        strip.background = element_rect(colour="white", fill="white"),
        legend.position="none",
        axis.title.y=element_text(face="italic"))

ggsave('~/Experiments/AP/figs/AP_behav_dprimes_bystrength_stripplot_95ci_v2.jpeg', dpi=600, width=6.69, height=3)
ggsave('~/Dropbox/Stanford/Papers/AP/Figures/AP_figure2_95ci.jpg', dpi=600, width=6.69, height=3)
p
```

Just assoc plot
```{r}
# p = ggplot(davg %>% filter(cond == 'associative'), 
#        aes(x=reps, y=mean, group=group, fill=group)) + 
#     geom_bar(position=position_dodge(), stat="identity") + 
#     geom_errorbar(width=0, aes(ymin=mean-se, 
#                                ymax=mean+se), size=1.5, position=position_dodge(.9)) +
#     scale_fill_manual(values=c('dodgerblue', 'orange')) +
#   ylab(expression(paste('Associative ',italic("d'"))))+
#   xlab('Encoding strength') +
#   ylim(0, 1.9) +
#     theme(legend.title=element_blank(), axis.title.y=element_text(face="italic"))
# 
# ggsave('~/Dropbox/Stanford/Papers/Dissertation/Figures_defense/AP_behav_assocdprime_bystrength.jpeg', 
#        dpi=300, width=6, height=4)
# p
```


```{r}
davg = combined_d %>%
  filter(group == 'stress') %>%
  group_by(subid, group, cond, reps, shockCond) %>%
  summarise(dprime = mean(dprime)) %>% 
  group_by(group, cond, reps, shockCond) %>%
  summarise(mean = mean(dprime),
            se = std.error(dprime),
            sterr = sd(dprime)/sqrt(n()),
            n()) %>%
  ungroup() %>%
  mutate(cond = as.character(cond)) %>%
  mutate(cond=replace(cond, cond=='assoc_d', 'associative'),
         cond=replace(cond, cond=='item_d', 'item')) %>%
  mutate(cond = factor(cond, levels=c('item', 'associative'))) %>%
  mutate(reps = as.character(reps)) %>%
  mutate(reps=replace(reps, reps=='2', 'weak'),
         reps=replace(reps, reps=='4', 'strong')) %>%
  mutate(reps = factor(reps, levels=c('weak', 'strong')))

davg

p=ggplot(davg, 
       aes(x=reps, y=mean, group=shockCond, fill=shockCond)) + 
   facet_grid(.~cond, scales = "free_x", space = "free_x") +
    geom_bar(position=position_dodge(), stat="identity") + 
    geom_errorbar(width=0, aes(ymin=mean-se, 
                               ymax=mean+se), size=1.5, position=position_dodge(.9)) +
    scale_fill_manual(values=c('mediumpurple', 'darkorange')) +
  ylab(expression(paste('Discriminability (',italic("d'"),')')))+
  xlab('Encoding strength') +
    theme(legend.title=element_blank(), axis.title.y=element_text(face="italic"))

ggsave('~/Experiments/AP/figs/AP_behav_dprimes_stress_byshockCond.jpeg', dpi=150, width=8, height=4)
p
```

### Stress: within-participant standard error/95% CI (if all subjs)
```{r}
davg = combined_d %>%
  filter(group == 'stress') %>%
  group_by(subid, group, cond, reps, shockCond) %>%
  summarise(dprime = mean(dprime)) 
davg

dfwc = summarySEwithin(davg, measurevar="dprime", withinvars=c("cond", "reps", "shockCond"),
                       idvar="subid", na.rm=TRUE, conf.interval=.95) %>%
  ungroup() %>%
  mutate(cond = as.character(cond)) %>%
  mutate(cond=replace(cond, cond=='assoc_d', 'Associative'),
         cond=replace(cond, cond=='item_d', 'Item')) %>%
  mutate(cond = factor(cond, levels=c('Item', 'Associative'))) %>%
  mutate(reps = as.character(reps)) %>%
  mutate(reps=replace(reps, reps=='2', 'weak'),
         reps=replace(reps, reps=='4', 'strong')) %>%
  mutate(reps = factor(reps, levels=c('weak', 'strong')))

dfwc

p=ggplot(dfwc, 
       aes(x=reps, y=dprime, group=shockCond, fill=shockCond)) + 
   facet_grid(.~cond, scales = "free_x", space = "free_x") +
    geom_bar(position=position_dodge(), stat="identity") + 
    geom_errorbar(width=0, aes(ymin=dprime-se, 
                               ymax=dprime+se), size=1.5, position=position_dodge(.9)) +
    scale_fill_manual(values=c('mediumpurple', 'darkorange')) +
  ylab(expression(paste('Discriminability (',italic("d'"),')')))+
  xlab('Encoding strength') +
    theme(legend.title=element_blank(), axis.title.y=element_text(face="italic"))

ggsave('~/Experiments/AP/figs/AP_behav_dprimes_stress_byshockCond_withinsubjerrorbars.jpeg', dpi=300, width=8, height=4)
p


### include points for each subj
dcomb = combined_d %>%
  filter(group == 'stress') %>%
  group_by(subid, group, shockCond, cond, reps) %>%
  summarise(dprime = mean(dprime)) %>% 
  ungroup() %>%
  mutate(cond = as.character(cond)) %>%
  mutate(cond=replace(cond, cond=='assoc_d', 'Associative'),
         cond=replace(cond, cond=='item_d', 'Item')) %>%
  mutate(cond = factor(cond, levels=c('Item', 'Associative'))) %>%
  mutate(reps = as.character(reps)) %>%
  mutate(reps=replace(reps, reps=='2', 'weak'),
         reps=replace(reps, reps=='4', 'strong')) %>%
  mutate(reps = factor(reps, levels=c('weak', 'strong'))) %>%
  ungroup()
dcomb

p = ggplot(dcomb, 
       aes(x=reps, y=dprime, color=shockCond)) + 
   facet_grid(.~cond) +
  geom_point(pch = 19, position = position_jitterdodge(), 
             alpha=.2, size=1.5)+
  scale_x_discrete(name = "Encoding strength") +
  geom_point(data = dfwc, aes(y=dprime), position=position_dodge(.9), 
             alpha=1, size = 2.5, shape=19) +
  geom_errorbar(data = dfwc, width=0,
                aes(y=dprime, ymin=dprime-ci, ymax=dprime+ci),
                size=1.5, position=position_dodge(.9), alpha=1) +
  scale_color_manual(values=c('#0072b2', '#d55e00')) +
  ylab(expression(paste('Discriminability (',italic("d'"),')')))+
  theme_classic(base_size = 14)+
  theme(legend.title=element_blank(), 
        strip.text = element_text(size=14),
        strip.background = element_rect(colour="white", fill="white"),
        axis.title.y=element_text(face="italic"))
p
ggsave('~/Dropbox/Stanford/Papers/AP/Figures/AP_supp_figure2.tiff', dpi=600, width=6.69, height=3)
ggsave('~/Dropbox/Stanford/Papers/AP/Figures/AP_supp_figure2_dpi150.tiff', dpi=150, width=6.69, height=3)
```

## 1d) RT

### HC hit, LC hit, CR
```{r}
dt = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/mvpa/notebooks/ap_behav.csv')
with(dt, table(shockTrial, mem_conditions, group))

# Get mean of median RT by condition, only include subjs w/more than 5 trials/cond
drt = dt %>%
  filter(mem_conditions %in% c("sourcehit", 'CR', 'itemhit_lo')) %>%
  group_by(group, subid, mem_conditions) %>%
  summarise(rt=median(respRT), rt_sd = sd(respRT), n=n()) %>%
  filter(n > 5) %>% 
  group_by(group, mem_conditions) %>%
  summarise(mean=mean(rt), se=std.error(rt), n()) %>%
  ungroup() %>%
  mutate(group = as.character(group),
         group = replace(group, group == 'control-fmri', 'control'),
         group = replace(group, group == 'stress-fmri', 'stress'),
         mem_conditions = as.character(mem_conditions),
         mem_conditions = replace(mem_conditions, mem_conditions=='sourcehit', 'HC\nassoc hit'),
         mem_conditions = replace(mem_conditions, mem_conditions=='itemhit_lo', 'LC\nitem hit'),
         mem_conditions = factor(mem_conditions, levels=c('HC\nassoc hit',
                                                          'LC\nitem hit', 
                                                          'CR')))
drt

p1=ggplot(drt, 
       aes(x=mem_conditions, y=mean, group=group, color=group)) + 
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=mean-se, 
                               ymax=mean+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
    scale_color_manual(values=c('dodgerblue', 'orange')) +
  ylab('Median RT (s)')+
  xlab('') +
  theme(legend.title = element_blank(),
        legend.position = c(0.9, 0.8))
p1
ggsave('~/Experiments/AP/figs/AP_behav_rt_groupXcond.jpeg', dpi=150, width=6, height=4)
p1
```

### HC assoc hit RT - all trials
```{r}
drt = dt %>%
  filter(mem_conditions %in% c("sourcehit")) %>% # need at least 6 trials/bin
  group_by(group, subid, mem_conditions) %>%
  summarise(n=n()) %>%
  ungroup() %>%
  mutate(mem_conditions = factor(mem_conditions)) %>%
  complete(nesting(group, subid), mem_conditions, fill=list(n=0))
sub_list = drt %>% filter(n < 6) %>% ungroup %>% pull(subid) %>% unique()
sub_list

# look at mean trial counts/cond/group
drt %>%
  filter(!subid %in% sub_list) %>% # need at least 6 trials/bin
  group_by(group, mem_conditions) %>%
  summarise(mean=mean(n), sd=sd(n), n=n())

# get medians/sds
head(dt)
drt = dt %>%
  filter(mem_conditions %in% c("sourcehit"),
         !subid %in% sub_list) %>%
  group_by(group, subid, mem_conditions) %>%
  summarise(rt=median(respRT), rt_sd = sd(respRT), n=n())
min(drt$n)

drt %>% group_by(mem_conditions, group) %>% summarise(mean(rt), sd(rt), mean(rt_sd), n())
```
```{r}
# median
bartlett.test(rt ~ group, data=drt %>% filter(mem_conditions == 'sourcehit'))
t.test(rt ~ group, data=drt %>% filter(mem_conditions == 'sourcehit'), var.equal=TRUE)

# sd
bartlett.test(rt_sd ~ group, data=drt %>% filter(mem_conditions == 'sourcehit'))
t.test(rt_sd ~ group, data=drt %>% filter(mem_conditions == 'sourcehit'), var.equal=TRUE)
```

### RT: HC assoc hits vs. CRs

#### Calculate median/SDs:
```{r echo=FALSE, cache=TRUE}
# Determine subs to toss due to low trial counts
drt = dt %>%
  filter(mem_conditions %in% c("sourcehit", 'CR')) %>% # need at least 6 trials/bin
  group_by(group, subid, mem_conditions) %>%
  summarise(n=n()) %>%
  ungroup() %>%
  mutate(mem_conditions = factor(mem_conditions)) %>%
  complete(nesting(group, subid), mem_conditions, fill=list(n=0))
sub_list = drt %>% filter(n < 6) %>% ungroup %>% pull(subid) %>% unique()
sub_list
# look at mean trial counts/cond/group
drt %>%
  filter(!subid %in% sub_list) %>% # need at least 6 trials/bin
  group_by(group, mem_conditions) %>%
  summarise(mean=mean(n), sd=sd(n), n=n())

# get medians/sds
head(dt)
drt = dt %>%
  filter(mem_conditions %in% c("sourcehit", 'CR'),
         !subid %in% sub_list) %>%
  group_by(group, subid, mem_conditions) %>%
  summarise(rt=median(respRT), rt_sd = sd(respRT), n=n()) %>%
  mutate(mem_conditions = factor(mem_conditions))

```

#### Median RT: SH vs. CR
```{r}
contrasts(drt$group) = c(1,-1); contrasts(drt$group)
contrasts(drt$mem_conditions) = c(-1,1); contrasts(drt$mem_conditions)

fit = lmer(rt ~ group * mem_conditions + (1|subid), data=drt, REML=TRUE) # not enough obs for RE
# plot(fit) # these look fine, not log transforming rt
# hist(resid(fit))
summary(fit)

drt %>% group_by(mem_conditions, group) %>% summarise(mean(rt), sd(rt), n())

drt %>% group_by(mem_conditions) %>% summarise(mean(rt), sd(rt), n())
```

```{r}
bartlett.test(rt ~ group, data=drt %>% filter(mem_conditions == 'sourcehit'))
t.test(rt ~ group, data=drt %>% filter(mem_conditions == 'sourcehit'), var.equal=TRUE)

bartlett.test(rt ~ group, data=drt %>% filter(mem_conditions == 'CR'))
t.test(rt ~ group, data=drt %>% filter(mem_conditions == 'CR'), var.equal=TRUE)

t.test(rt ~ mem_conditions, data=drt %>% filter(group == 'control-fmri'), 
       var.equal=TRUE, paired=TRUE)

t.test(rt ~ mem_conditions, data=drt %>% filter(group == 'stress-fmri'), 
       var.equal=TRUE, paired=TRUE)
```

#### SD RT: SH vs. CR
```{r}
contrasts(drt$group) = c(1,-1); contrasts(drt$group)
contrasts(drt$mem_conditions) = c(-1,1); contrasts(drt$mem_conditions)
head(drt)
# hist(d$rt_sd)
fit = lmer(rt_sd ~ group * mem_conditions + (1|subid), data=drt, REML=TRUE) # not enough obs for RE
# plot(fit)
# hist(resid(fit))
summary(fit)

drt %>% group_by(mem_conditions, group) %>% summarise(mean(rt_sd), sd(rt_sd), n())
bartlett.test(rt_sd ~ group, data=drt %>% filter(mem_conditions == 'sourcehit'))
t.test(rt ~ group, data=drt %>% filter(mem_conditions == 'sourcehit'), var.equal=TRUE)
```

### RT: HC assoc hit vs. item hits

#### Calculate median/SDs:
```{r echo=FALSE, cache=TRUE}
# Determine subs to toss due to low trial counts
d = dt %>%
  filter(mem_conditions %in% c("sourcehit", 'itemhit_lo')) %>% # need at least 6 trials/bin
  group_by(group, subid, mem_conditions) %>%
  summarise(n=n())%>%
  ungroup() %>%
  mutate(mem_conditions = factor(mem_conditions)) %>%
  complete(nesting(group, subid), mem_conditions, fill=list(n=0))
sub_list = d %>% filter(n < 6) %>% ungroup %>% pull(subid) %>% unique()
sub_list
# look at mean trial counts/cond/group
d %>%
  filter(!subid %in% sub_list) %>% # need at least 6 trials/bin
  group_by(group, mem_conditions) %>%
  summarise(mean=mean(n), sd=sd(n), n=n())

# get medians/sds
d = dt %>%
  filter(mem_conditions %in% c("sourcehit", 'itemhit_lo'),
         !subid %in% sub_list) %>%
  group_by(group, subid, mem_conditions) %>%
  summarise(rt=median(respRT), rt_sd = sd(respRT), n=n()) %>%
  mutate(mem_conditions = factor(mem_conditions))
min(d$n)
```

#### Median RT: SH vs. IH
```{r}
contrasts(d$group) = c(1,-1); contrasts(d$group)
contrasts(d$mem_conditions) = c(1,-1); contrasts(d$mem_conditions)

fit = lmer(rt ~ group * mem_conditions + (1|subid), data=d, REML=TRUE) # not enough obs for RE
summary(fit)

d %>% group_by(group, mem_conditions) %>% summarise(mean(rt), sd(rt), n())
d %>% group_by(mem_conditions) %>% summarise(mean(rt), sd(rt), n())
```

#### SD RT: SH vs. CR
```{r}
contrasts(d$mem_conditions)
fit = lmer(rt_sd ~ group * mem_conditions + (1|subid), data=d, REML=TRUE) # not enough obs for RE
summary(fit)
# anova(fit)
```

### RT: HC assoc hits by encoding strength

#### Calculate median/SDs:
```{r echo=FALSE, cache=TRUE}
# Determine subs to toss due to low trial counts
d = dt %>%
  filter(mem_conditions %in% c("sourcehit")) %>%
  group_by(group, subid, reps) %>%
  summarise(n=n())%>%
  ungroup() %>%
  complete(nesting(group, subid), reps, fill=list(n=0))

sub_list = d %>% filter(n < 6) %>% ungroup %>% pull(subid) %>% unique()
sub_list
# look at mean trial counts/cond/group
d %>%
  filter(!subid %in% sub_list) %>% # need at least 6 trials/bin
  group_by(group, reps) %>%
  summarise(mean=mean(n), sd=sd(n), n=n())

# get medians/sds
head(dt)
d = dt %>%
  filter(mem_conditions %in% c("sourcehit"),
         !subid %in% sub_list) %>%
  group_by(group, subid, reps) %>%
  summarise(rt=median(respRT), rt_sd = sd(respRT), n=n()) %>%
  ungroup() %>%
  mutate(reps = factor(reps))
min(d$n)
```
#### Median RT
```{r}
contrasts(d$group) = c(1,-1); contrasts(d$group)
contrasts(d$reps) = c(1,-1); contrasts(d$reps)

fit = lmer(rt ~ group * reps + (1|subid), data=d, REML=TRUE) # not enough obs for RE
summary(fit)

d %>% group_by(reps) %>% summarise(mean(rt), sd(rt), n())
```

#### SD RT
```{r}
fit = lmer(rt_sd ~ group * reps + (1|subid), data=d, REML=TRUE) # not enough obs for RE
summary(fit)
# anova(fit)
```


### RT: HC assoc hit - by run type
```{r}
# Determine subs to toss due to low trial counts
drt = dt %>%
  filter(mem_conditions %in% c("sourcehit")) %>%
  group_by(group, subid, shockCond) %>%
  summarise(n=n())%>%
  ungroup() %>%
  complete(nesting(group, subid), shockCond, fill=list(n=0))

sub_list = drt %>% filter(n < 6) %>% ungroup %>% pull(subid) %>% unique()
sub_list
# look at mean trial counts/cond/group
drt %>%
  filter(!subid %in% sub_list) %>% # need at least 6 trials/bin
  group_by(group, shockCond) %>%
  summarise(mean=mean(n), sd=sd(n), n=n())

# get medians/sds
head(dt)
drt = dt %>%
  filter(mem_conditions %in% c("sourcehit"),
         !subid %in% sub_list) %>%
  group_by(group, subid, shockCond) %>%
  summarise(rt=median(respRT), rt_sd = sd(respRT), n=n()) %>%
  ungroup() %>%
  mutate(shockCond = factor(shockCond))
drt
min(drt$n)

contrasts(drt$group) = c(1,-1); contrasts(drt$group)
contrasts(drt$shockCond) = c(1,-1); contrasts(drt$shockCond)

bartlett.test(rt ~ shockCond, data=drt %>% filter(group == 'stress-fmri'))
t.test(rt ~ shockCond, data=drt %>% filter(group == 'stress-fmri'), 
       paired=TRUE, var.equal=TRUE)

drt %>% group_by(group, shockCond) %>% summarise(n())

bartlett.test(rt ~ group, data=drt %>% filter(shockCond == 'threat'))
t.test(rt ~ group, data=drt %>% filter(shockCond == 'threat'), 
       paired=FALSE, var.equal=TRUE)

summary(lmer(rt ~ group * shockCond + (1  | subid), data=drt))
```

```{r}
bartlett.test(rt_sd ~ shockCond, data=drt %>% filter(group == 'stress-fmri'))
t.test(rt_sd ~ shockCond, data=drt %>% filter(group == 'stress-fmri'), 
       paired=TRUE, var.equal=TRUE)

bartlett.test(rt_sd ~ group, data=drt %>% filter(shockCond == 'threat'))
t.test(rt_sd ~ group, data=drt %>% filter(shockCond == 'threat'), 
       paired=FALSE, var.equal=TRUE)

summary(lmer(rt_sd ~ group * shockCond + (1  | subid), data=drt))
```


# 2) Trial-wise analyses

Note that all these analyses exclude the 2 participants with poor VTC localizer classification:

## Localizer classification:

### VTC F1 score
```{r}
d = read.csv('/Users/sgagnon/Dropbox/Stanford/Presentations/AP/mvpa_f1_localizer_group_scalewithinrun.csv')
str(d)

# mean +/- SD
d %>% 
  group_by(subid, category) %>%
  summarise(mean = mean(mean)) %>%
  group_by(category) %>% 
  summarise(sd=sd(mean), f1 = mean(mean), n=n())

# how are individ subjs doing? look for outliers
d_avg = d %>% 
          group_by(subid, group) %>%
          summarise(f1 = mean(mean))
head(d_avg)

boxplot(d_avg$f1)
boxplot.stats(d_avg$f1)
outlier_values <- boxplot.stats(d_avg$f1)$out

d_avg %>% filter(f1 %in% outlier_values)
subids_rm = d_avg %>% filter(f1 %in% outlier_values) %>% collect %>% .[["subid"]]
subids_rm # ap168 ap174
dim(d)
d = d %>% filter(!subid %in% subids_rm)
dim(d)

ggplot(d %>% 
         group_by(subid, group, category) %>%
         summarise(f1 = mean(mean)), aes(x=category, y=f1, color=group)) +
  geom_boxplot()+
  geom_point(alpha=.7, size=3, position=position_jitterdodge()) +
  ylab('F1 score')+
  scale_color_manual(values=c('dodgerblue', 'orange')) +
  xlab('') + ylim(.5, 1)

contrasts(d$group) = c(1,-1); contrasts(d$group)
contrasts(d$category) = cbind(objVother=c(1,-2,1),
                              faceVplace=c(1,0,-1)); contrasts(d$category)
fit = lmer(mean ~ group*category + (1|subid), data=d, REML=TRUE)
anova(fit)
summary(fit)
```

### Inferior parietal F1 score
```{r}
d = read.csv('/Users/sgagnon/Dropbox/Stanford/Presentations/AP/mvpa_f1_localizer_inferiorparietal_group_scalewithinrun.csv')
str(d)

# mean +/- SD
d %>% 
  group_by(subid, category) %>%
  summarise(mean = mean(mean)) %>%
  group_by(category) %>% 
  summarise(sd=sd(mean), f1 = mean(mean), n=n())

# how are individ subjs doing? look for outliers
d_avg = d %>% 
          group_by(subid, group) %>%
          summarise(f1 = mean(mean))
head(d_avg)

boxplot(d_avg$f1)
boxplot.stats(d_avg$f1)
outlier_values <- boxplot.stats(d_avg$f1)$out

d_avg %>% filter(f1 %in% outlier_values)
subids_rm = d_avg %>% filter(f1 %in% outlier_values) %>% collect %>% .[["subid"]]
subids_rm # ap168
dim(d)
d = d %>% filter(!subid %in% subids_rm)
dim(d)

ggplot(d %>% 
         group_by(subid, group, category) %>%
         summarise(f1 = mean(mean)), aes(x=category, y=f1, color=group)) +
  geom_boxplot()+
  geom_point(alpha=.7, size=3, position=position_jitterdodge()) +
  ylab('F1 score')+
  scale_color_manual(values=c('dodgerblue', 'orange')) +
  xlab('') + ylim(.5, 1)

contrasts(d$group) = c(1,-1); contrasts(d$group)
contrasts(d$category) = cbind(objVother=c(1,-2,1),
                              faceVplace=c(1,0,-1)); contrasts(d$category)
fit = lmer(mean ~ group*category + (1|subid), data=d, REML=TRUE)
anova(fit)
summary(fit)
```


## Load in data
```{r}
d = read.csv('/Users/sgagnon/Dropbox/Stanford/Presentations/AP/mvpa_logit_place_byreps_avg_46810_filtartloc_scalewithinrun.csv')
table(d$subid)
table(d$cond)

subids_rm = c('ap168', 'ap174') # bad VTC localizer classification

# filter d to just good subjs, and only OLD items
d = d %>%
  filter(!subid %in% subids_rm) %>%
  filter(cond %in% c('sourcemiss_hi', 'sourcehit', 'M', 'itemhit_lo')) %>%
  mutate(pcorr = factor(ifelse(cond == "sourcehit", 1, 0)),
         vtc_logit = avg_logit)

dt %>% filter(shock_and_post == 2) # one subj w/consecutive shocks - trial needs to be removed (though mem_condition == 'nuisance', so doesn't matter)

# Merge w/other behavioral info
d = dt %>%
  mutate(onset=onset_adj, img_type=cond) %>% 
  dplyr::select(-group, -reps, -cond) %>%
  right_join(d, by=c('subid', 'run', 'onset')) %>%
  mutate(subid = factor(subid), imgType = factor(img_type))
dim(d)
d = d %>% filter(shock_and_post == 0)
dim(d)

# Read in hipp BOLD
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-hippocampus.csv')
roi_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-hippocampus.csv')
# dim(roi_lh); dim(roi_rh)

# Take timepoints of interest for old trials, and collapse across hemispheres
roi_f = bind_rows("lh" = roi_lh, "rh" = roi_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, hemi, run, onset) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset) %>%
  summarise(hipp_sig = mean_(mean_activity)) %>% ungroup()

# Read in hipp tail BOLD (as potential secondary analysis)
roi_tail_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-hippocampus-tail.csv')
roi_tail_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-hippocampus-tail.csv')

# Take timepoints of interest for old trials, and collapse across hemispheres
roi_tail_f = bind_rows("lh" = roi_tail_lh, "rh" = roi_tail_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, hemi, run, onset) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset) %>%
  summarise(hipp_tail_sig = mean_(mean_activity)) %>% ungroup()

# Read in hipp head BOLD (reviewer followup)
roi_head_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-hippocampus-head.csv')
roi_head_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-hippocampus-head.csv')

# Take timepoints of interest for old trials, and collapse across hemispheres
roi_head_f = bind_rows("lh" = roi_head_lh, "rh" = roi_head_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, hemi, run, onset) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset) %>%
  summarise(hipp_head_sig = mean_(mean_activity)) %>% ungroup()


# Read in angular BOLD
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-DefaultA_IPL.csv')
angular_lh_f = roi_lh %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, run, onset) %>%
  summarise(angular_lh_sig = mean_(mean_activity)) %>% ungroup()

# Read in RSP BOLD
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-DefaultC_Rsp.csv')
roi_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-DefaultC_Rsp.csv')

# Take timepoints of interest for old trials, and collapse across hemispheres
rsp_f = bind_rows("lh" = roi_lh, "rh" = roi_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, hemi, run, onset) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset) %>%
  summarise(rsp_sig = mean_(mean_activity)) %>% ungroup()

# Read in CCN BOLD
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-frontoparietal.csv')
roi_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-frontoparietal.csv')
# dim(roi_lh); dim(roi_rh)

# Take timepoints of interest for old trials, and collapse across hemispheres
CCN_f = bind_rows("lh" = roi_lh, "rh" = roi_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, hemi, run, onset) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset) %>%
  summarise(CCN_sig = mean_(mean_activity)) %>% ungroup()

# also, just for LH
CCN_lh_f = roi_lh %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, run, onset) %>%
  summarise(CCN_lh_sig = mean_(mean_activity)) %>% ungroup()

# Read in DAN BOLD
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-dorsalattn.csv')
roi_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-dorsalattn.csv')
# dim(roi_lh); dim(roi_rh)

# Take timepoints of interest for old trials, and collapse across hemispheres
DAN_f = bind_rows("lh" = roi_lh, "rh" = roi_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, hemi, run, onset) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset) %>%
  summarise(DAN_sig = mean_(mean_activity)) %>% ungroup()

# also, just for LH
DAN_lh_f = roi_lh %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, run, onset) %>%
  summarise(DAN_lh_sig = mean_(mean_activity)) %>% ungroup()

# Other reinstatement
d_infpar = read.csv('/Users/sgagnon/Dropbox/Stanford/Presentations/AP/mvpa_logit_inferiorparietal_place_byreps_avg_46810_filtartloc_scalewithinrun.csv') %>%
  filter(!subid %in% subids_rm) %>%
  filter(cond %in% c('sourcemiss_hi', 'sourcehit', 'M', 'itemhit_lo')) %>%
  mutate(ang_logit = avg_logit) %>%
  dplyr::select(subid, run, onset, ang_logit)

d_hipp = read.csv('/Users/sgagnon/Dropbox/Stanford/Presentations/AP/mvpa_logit_bilat-hippocampus_place_byreps_avg_46810_filtartloc_scalewithinrun.csv') %>%
  filter(!subid %in% subids_rm) %>%
  filter(cond %in% c('sourcemiss_hi', 'sourcehit', 'M', 'itemhit_lo')) %>%
  mutate(pcorr = factor(ifelse(cond == "sourcehit", 1, 0)),
         hipp_logit = avg_logit) %>%
  dplyr::select(subid, run, onset, hipp_logit)

# to see if need phc (maybe includes "general memory" response?)
d_vtc_nophc = read.csv('/Users/sgagnon/Dropbox/Stanford/Presentations/AP/mvpa_logit_bilat-fusi_inftemp_place_byreps_avg_46810_filtartloc_scalewithinrun.csv') %>%
  filter(!subid %in% subids_rm) %>%
  filter(cond %in% c('sourcemiss_hi', 'sourcehit', 'M', 'itemhit_lo')) %>%
  mutate(pcorr = factor(ifelse(cond == "sourcehit", 1, 0)),
         vtc_nophc_logit = avg_logit) %>%
  dplyr::select(subid, run, onset, vtc_nophc_logit)

# Merge w/VTC classifier evidence
dm = d %>%
  left_join(roi_f, by=c('subid', 'run', 'onset')) %>%
  left_join(roi_tail_f, by=c('subid', 'run', 'onset')) %>%
  left_join(roi_head_f, by=c('subid', 'run', 'onset')) %>%
  left_join(DAN_f, by=c('subid', 'run', 'onset')) %>%
  left_join(CCN_f, by=c('subid', 'run', 'onset')) %>%
  left_join(rsp_f, by=c('subid', 'run', 'onset')) %>%
  left_join(angular_lh_f, by=c('subid', 'run', 'onset')) %>%
  left_join(DAN_lh_f, by=c('subid', 'run', 'onset')) %>%
  left_join(CCN_lh_f, by=c('subid', 'run', 'onset')) %>%
  left_join(d_infpar, by=c('subid', 'run', 'onset')) %>%
  left_join(d_hipp, by=c('subid', 'run', 'onset')) %>%
  left_join(d_vtc_nophc, by=c('subid', 'run', 'onset')) %>%
  group_by(subid) %>%
  mutate(ang_logit_z = zscore(ang_logit),
         vtc_logit_z = zscore(vtc_logit),
         hipp_logit_z = zscore(hipp_logit),
         CCN_sig_z = zscore(CCN_sig),
         rsp_sig_z = zscore(rsp_sig),
         DAN_sig_z = zscore(DAN_sig),
         angular_lh_sig_z = zscore(angular_lh_sig),
         CCN_lh_sig_z = zscore(CCN_lh_sig),
         DAN_lh_sig_z = zscore(DAN_lh_sig),
         hipp_sig_z = zscore(hipp_sig),
         hipp_tail_sig_z = zscore(hipp_tail_sig),
         hipp_head_sig_z = zscore(hipp_head_sig),
         reps = factor(reps),
         hipp_quintile = ntile(hipp_sig, 5),
         rsp_quintile = ntile(rsp_sig, 5),
         CCN_quintile = ntile(CCN_sig, 5),
         DAN_quintile = ntile(DAN_sig, 5),
         angular_lh_sig_quintile = ntile(angular_lh_sig, 5),
         CCN_lh_quintile = ntile(CCN_lh_sig, 5),
         DAN_lh_quintile = ntile(DAN_lh_sig, 5),
         hipp_tail_quintile = ntile(hipp_tail_sig, 5),
         hipp_head_quintile = ntile(hipp_head_sig, 5),
         vtc_quintile = ntile(vtc_logit, 5),
         hipp_logit_quintile = ntile(hipp_logit, 5),
         ang_quintile = ntile(ang_logit, 5)) %>%
  ungroup() %>%
  mutate(subid = factor(subid),
         cond = factor(cond),
         condition = factor(condition))
dim(dm) #just hipp: 6623  
with(dm, table(subid, reps))

str(dm)

# set up contrasts
contrasts(dm$pcorr) = c(-1,1); contrasts(dm$pcorr)
contrasts(dm$reps) = c(-1,1); contrasts(dm$reps)
contrasts(dm$group) = c(1,-1); contrasts(dm$group)
contrasts(dm$shockCond) = c(1,-1); contrasts(dm$shockCond)
```

Trial-wise analysis counts/group:
```{r}
dm %>% group_by(subid, group) %>% summarise(n()) %>% group_by(group) %>% summarise(n())
```

```{r}
dm %>% mutate(avg = (X4+X6+X8+X10)/4) %>%
  filter(round(vtc_logit,3) != round(avg,3)) %>%
  dplyr::select(vtc_logit, avg)
```


### Trial counts/cond
```{r}
# all subjs must have at least 6 trials of each type for sh vs cr analyses
dt %>% filter(mem_conditions %in% c('sourcehit', 'CR'))%>% 
  mutate(mem_conditions = factor(mem_conditions)) %>%
  group_by(subid, mem_conditions) %>% summarise(n()) %>% 
  ungroup() %>%
  complete(nesting(subid), mem_conditions, fill = list(`n()` = 0)) %>%
  filter(`n()` < 6)
# must exclude: ap151, ap156

# need at least 2 runs with BOTH 1 SH and 1 CR
dt %>% filter(mem_conditions %in% c('sourcehit', 'CR'))%>% 
  mutate(mem_conditions = factor(mem_conditions)) %>%
  group_by(subid, run, mem_conditions) %>% 
  summarise(count = n()) %>%
  ungroup() %>%
  complete(nesting(subid, run), mem_conditions, fill = list(count = 0)) %>%
  spread(key=mem_conditions, value=count, fill = 0) %>%
  filter(CR == 0 | sourcehit == 0)
# remaining subjs have a min of 3 runs with both

# this leaves this many subjs/group for analyses collapsing across shockCond:
dt %>% filter(!subid %in% c('ap151', 'ap156')) %>% 
  group_by(subid, group) %>% summarise(n()) %>%
  group_by(group) %>% summarise(n())
# 22 controls/22 stress
# minus 1 control for too much movement! (T1 is even blurry...)

# Now, for shockCond analyses:

# all subjs must have at least 6 trials of each type
dt %>% filter(mem_conditions %in% c('sourcehit', 'CR'))%>% 
  mutate(mem_conditions = factor(mem_conditions),
         shockCond = factor(shockCond)) %>%
  group_by(subid, group, mem_conditions, shockCond) %>% summarise(n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), mem_conditions, shockCond, fill = list(`n()` = 0)) %>%
filter(`n()` < 6)
# ap121 (control): 1 threat CR
# ap158 (control): 5 safe SH
# ap164 (stress) 5 safe CR
# ap173 (stress) 1 threat SH

# 6 runs for everyone by ap155 (had to leave early on day1)
dt %>% group_by(subid, run) %>% summarise(n()) %>% group_by(subid) %>% summarise(n())

(47 - 6) * 6 * 2 - 2 #490 rows
# need at least 2 runs with BOTH 1 SH and 1 CR
dt %>% filter(!subid %in% c('ap151', 'ap156', 'ap121', 'ap158', 'ap164', 'ap173')) %>%
  filter(mem_conditions %in% c('sourcehit', 'CR'))%>% 
  mutate(mem_conditions = factor(mem_conditions)) %>%
  group_by(subid, group, run, mem_conditions, shockCond) %>% 
  summarise(count = n()) %>%
  ungroup() %>%
  complete(nesting(subid, group, run, shockCond), mem_conditions, fill = list(count = 0)) %>%
  filter(count == 0)
#2 subjs are missing 1 cond for 1 run; that means they have 2 good runs (at least 1 trial/condition) for each shockC type

# dt %>% filter(subid %in% c('ap110', 'ap172')) %>%
#   filter(mem_conditions %in% c('sourcehit', 'CR'))%>% 
#   mutate(mem_conditions = factor(mem_conditions)) %>%
#   group_by(subid, group, run, mem_conditions, shockCond) %>% 
#   summarise(count = n()) %>%
#   ungroup() %>%
#   complete(nesting(subid, group, run, shockCond), mem_conditions, fill = list(count = 0))
```


## Are hipp quintiles matched across groups?

No significant differences in hipp BOLD between groups at each quintile:
```{r}
dm %>% filter(hipp_quintile == 4) %>% group_by(group, subid) %>% summarise(n()) %>% 
  group_by(group) %>% summarise(n())

summary(lmer(hipp_sig ~ group + (1|subid), data=dm %>% filter(hipp_quintile == 1)))
summary(lmer(hipp_sig ~ group + (1|subid), data=dm %>% filter(hipp_quintile == 2)))
summary(lmer(hipp_sig ~ group + (1|subid), data=dm %>% filter(hipp_quintile == 3)))
summary(lmer(hipp_sig ~ group + (1|subid), data=dm %>% filter(hipp_quintile == 4)))
summary(lmer(hipp_sig ~ group + (1|subid), data=dm %>% filter(hipp_quintile == 5)))
```

## Are VTC quintiles matched across groups?

vtc logit is greater for controls at quintiles 3 and 4
```{r}
head(dm)
summary(lmer(vtc_logit ~ group + (1|subid), data=dm %>% filter(vtc_quintile == 1)))
summary(lmer(vtc_logit ~ group + (1|subid), data=dm %>% filter(vtc_quintile == 2)))
summary(lmer(vtc_logit ~ group + (1|subid), data=dm %>% filter(vtc_quintile == 3)))
summary(lmer(vtc_logit ~ group + (1|subid), data=dm %>% filter(vtc_quintile == 4)))
summary(lmer(vtc_logit ~ group + (1|subid), data=dm %>% filter(vtc_quintile == 5)))
```


## VTC Mediation: Indirect effect of hipp -> VTC -> pcorr
Template borrowed from Alan Gordon (https://github.com/amgordon/Gordon_CerCor_2014)

### Overall effect of hipp -> pcorr
```{r}
mean(dm$hipp_sig_z)
sd(dm$hipp_sig_z)
mean(dm$vtc_logit_z)
sd(dm$vtc_logit_z)

# standardize continuous vars
dCleanStandardized = dm
dCleanStandardized$rGenHipp<-scale(dCleanStandardized$hipp_sig_z)
dCleanStandardized$ERActUnsigned<-scale(dCleanStandardized$vtc_logit_z)
dCleanStandardized$ERActUnsigned_infpar<-scale(dCleanStandardized$ang_logit_z)
dCleanStandardized$rGenANG<-scale(dCleanStandardized$angular_lh_sig_z)
dCleanStandardized$rGenRSP<-scale(dCleanStandardized$rsp_sig_z)

# also include hipp head/tail separately to address reviewer question
dCleanStandardized$rGenHipp_tail<-scale(dCleanStandardized$hipp_tail_sig_z)
dCleanStandardized$rGenHipp_head<-scale(dCleanStandardized$hipp_head_sig_z)
```

```{r}
# overall effect
deq.0<-glmer(pcorr ~ group*(rGenHipp) + reps + shockCond +
               (-1 + rGenHipp|subid) + 
               (1|subid), 
             data=dCleanStandardized, family = "binomial")
# coef(deq.0)
summary(deq.0)
fixef(deq.0)
fixef(deq.0)[3] # overall effect of hipp
fixef(deq.0)[6] # overall effect of hipp:group

# look at interaction of hipp * group
summary(glmer(pcorr ~ (rGenHipp) + reps + shockCond +
               (-1 + rGenHipp|subid) + 
               (1|subid), 
             data=dCleanStandardized %>% filter(group == 'control'), 
      family = "binomial"))

summary(glmer(pcorr ~ (rGenHipp) + reps + shockCond +
               (-1 + rGenHipp|subid) + 
               (1|subid), 
             data=dCleanStandardized %>% filter(group == 'stress'), 
      family = "binomial"))

# polynomial interaction?
deq.0b<-glmer(pcorr ~ group*(poly(hipp_sig_z, 2)) + reps + shockCond +
               (-1 + poly(hipp_sig_z, 2)|subid) + 
               (1|subid), 
             data=dCleanStandardized, family = "binomial")
coef(deq.0b)
summary(deq.0b)

summary(glmer(pcorr ~ (poly(hipp_sig_z, 2)) + reps + shockCond +
               (-1 + poly(hipp_sig_z, 2)|subid) + 
               (1|subid), 
             data=dCleanStandardized %>% filter(group == 'control'), 
             family = "binomial"))

summary(glmer(pcorr ~ (poly(hipp_sig_z, 2)) + reps + shockCond +
               (-1 + poly(hipp_sig_z, 2)|subid) + 
               (1|subid), 
             data=dCleanStandardized %>% filter(group == 'stress'), 
             family = "binomial"))

# exploratory check: is there an interaction between reps and hipp?
summary(glmer(pcorr ~ group*(rGenHipp) + reps + shockCond + rGenHipp:reps +
               (-1 + rGenHipp|subid) + 
               # (-1 + rGenHipp:reps|subid) + # remove to converge
               (1|subid), 
             data=dCleanStandardized, family = "binomial",
             control=glmerControl(optimizer='Nelder_Mead')))
```


### Full model, controlling for VTC reinstatement
```{r}
# triple check zstats are same
# summary(glmer(pcorr ~ group*(hipp_sig_z + vtc_logit_z) + reps + shockCond +
#                (-1 + hipp_sig_z|subid) + 
#                (-1 + vtc_logit_z|subid) + 
#                (1|subid), 
#              data=dCleanStandardized, family = "binomial"))

# effect of things on subsequent memory
deq.1<-glmer(pcorr ~ group*(rGenHipp + ERActUnsigned) + reps + shockCond +
               (-1 + rGenHipp|subid) + 
               (-1 + ERActUnsigned|subid) + 
               (1|subid), 
             data=dCleanStandardized, family = "binomial")
# uncorrelate random slopes and intercepts
summary(deq.1)
fixef(deq.1)
fixef(deq.1)[4] # subs ~ VTC direct effect 
fixef(deq.1)[3] # subs ~ hipp direct effect 
fixef(deq.1)[7] # hipp:group interaction on pcorr direct
summary(deq.1)

# quick: what about "b" -- effect of VTC on pcorr
summary(glmer(pcorr ~ group*(ERActUnsigned) + reps + shockCond +
               (-1 + ERActUnsigned|subid) + 
               (1|subid), 
             data=dCleanStandardized, family = "binomial"))

# quadratic effect?
summary(glmer(pcorr ~ group*(poly(vtc_logit_z, 2)) + reps + shockCond +
               (-1 + poly(vtc_logit_z, 2)|subid) + 
               (1|subid), 
             data=dCleanStandardized, family = "binomial",
             control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e5))))

# interrogate interaction
summary(glmer(pcorr ~ (rGenHipp + ERActUnsigned) + reps + shockCond +
               (-1 + rGenHipp|subid) + 
               (-1 + ERActUnsigned|subid) + 
               (1|subid), 
             data=dCleanStandardized %>% filter(group == 'control'), 
             family = "binomial"))
summary(glmer(pcorr ~ (rGenHipp + ERActUnsigned) + reps + shockCond +
               (-1 + rGenHipp|subid) + 
               (-1 + ERActUnsigned|subid) + 
               (1|subid), 
             data=dCleanStandardized %>% filter(group == 'stress'), 
             family = "binomial"))

# poly?
# both linear and quadratic interactions
summary(glmer(pcorr ~ group*(poly(hipp_sig_z, 2) + ERActUnsigned) +
                reps + shockCond +
               (-1 + poly(hipp_sig_z, 2)|subid) +
               (-1 + ERActUnsigned|subid) +
               (1|subid),
             data=dCleanStandardized, family = "binomial",
             control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e5))))
# Fixed effects:
#                             Estimate Std. Error z value Pr(>|z|)    
# (Intercept)                 -0.43867    0.16078  -2.728  0.00636 ** 
# group1                       0.45414    0.16077   2.825  0.00473 ** 
# poly(hipp_sig_z, 2)1        22.17829    4.20261   5.277 1.31e-07 ***
# poly(hipp_sig_z, 2)2         2.33975    2.70260   0.866  0.38663    
# ERActUnsigned                0.26556    0.04602   5.771 7.89e-09 ***
# reps1                        0.38623    0.02921  13.221  < 2e-16 ***
# shockCond1                   0.02184    0.02879   0.758  0.44823    
# group1:poly(hipp_sig_z, 2)1  9.96197    4.20164   2.371  0.01774 *  
# group1:poly(hipp_sig_z, 2)2  6.74722    2.64882   2.547  0.01086 *  
# group1:ERActUnsigned        -0.03230    0.04596  -0.703  0.48219    
# ---
# Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1



# holds w/simple effects?
#controls:
contrasts(dCleanStandardized$group) = c(0,1); contrasts(dCleanStandardized$group)
summary(glmer(pcorr ~ group*(rGenHipp + ERActUnsigned) + reps + shockCond +
               (-1 + rGenHipp|subid) + 
               (-1 + ERActUnsigned|subid) + 
               (1|subid), 
             data=dCleanStandardized, family = "binomial",
             control=glmerControl(optimizer="bobyqa",
                                  optCtrl=list(maxfun=2e5))))

#stress:
contrasts(dCleanStandardized$group) = c(1,0); contrasts(dCleanStandardized$group)
summary(glmer(pcorr ~ group*(rGenHipp + ERActUnsigned) + reps + shockCond +
               (-1 + rGenHipp|subid) + 
               (-1 + ERActUnsigned|subid) + 
               (1|subid), 
             data=dCleanStandardized, family = "binomial",
             control=glmerControl(optimizer="bobyqa",
                                  optCtrl=list(maxfun=2e5))))

contrasts(dCleanStandardized$group) = c(1,-1); contrasts(dCleanStandardized$group)

# what about if we model random slope for rep?
# need to add more iterations to converge
summary(glmer(pcorr ~ group*(rGenHipp + ERActUnsigned) + reps + shockCond +
               (-1 + rGenHipp|subid) + 
               (-1 + ERActUnsigned|subid) + 
               (-1 + reps|subid) + 
               (1|subid), 
             control=glmerControl(optimizer="bobyqa",
                                  optCtrl=list(maxfun=2e5)), 
             data=dCleanStandardized, family = "binomial"))

# interactions of reps * group/neural measures?
summary(glmer(pcorr ~ group*(rGenHipp + ERActUnsigned + reps) +
                reps:rGenHipp + reps:ERActUnsigned + shockCond +
               (-1 + rGenHipp|subid) + 
               (-1 + ERActUnsigned|subid) + 
               (1|subid), 
             control=glmerControl(optimizer="bobyqa",
                                  optCtrl=list(maxfun=2e5)), 
             data=dCleanStandardized, family = "binomial"))
# removed Rslope of hipp/vtc to converge
```

### Full model, also controlling for inferior parietal reinstatment
```{r}
# effect of more things on subsequent memory
deq.1b<-glmer(pcorr ~ group*(rGenHipp + ERActUnsigned + ERActUnsigned_infpar) +
                reps + shockCond +
               (-1 + rGenHipp|subid) + 
               (-1 + ERActUnsigned|subid) + 
               (-1 + ERActUnsigned_infpar|subid) + 
               (1|subid), 
             data=dCleanStandardized, family = "binomial",
             control=glmerControl(optimizer="bobyqa",
                                  optCtrl=list(maxfun=2e5))
             )
summary(deq.1b)
```

### Follow up -- does hipp effect vary as a function of encoding strength?
```{r}
# with(dCleanStandardized, table(subid, pcorr, reps))
subids_lowtrials_HChreps = dm %>% 
  filter(cond == 'sourcehit') %>%
  group_by(group, subid, reps) %>% 
  summarise(count = n()) %>% 
  ungroup() %>%
  complete(nesting(subid, group), reps, fill = list(count= 0)) %>%
  filter(count < 6) %>% pull(subid) %>% unique()
subids_lowtrials_HChreps

res_reps = glmer(pcorr ~ reps*rGenHipp + group + shockCond +
                (-1 + rGenHipp|subid) + 
                (-1 + reps|subid) + 
                (-1 + reps:rGenHipp|subid) + 
                (1|subid), 
             data=dCleanStandardized %>% 
               filter(!subid %in% subids_lowtrials_HChreps), 
             family = "binomial", 
             glmerControl(optimizer="bobyqa",
                                    optCtrl=list(maxfun=2e5))
             )
summary(res_reps)
```



### Follow up -- does the group x hipp interaction differ as a function of hipp sub-region?
```{r}
d_hipp_long = dCleanStandardized %>% dplyr::select(subid, group, 
                                                   pcorr, trial, run,
                                     reps, shockCond,
                                     ERActUnsigned,
                                     rGenHipp_head, rGenHipp_tail) %>%
  gather('hipp_loc', 'hipp_val', 
         rGenHipp_head, rGenHipp_tail) %>%
  arrange(subid, run, trial) %>%
  mutate(hipp_loc = factor(hipp_loc))

contrasts(d_hipp_long$hipp_loc) = c(-1,1); contrasts(d_hipp_long$hipp_loc)

# does effect differ as function of head/tail?
summary(glmer(pcorr ~ group*(hipp_loc * hipp_val + ERActUnsigned) + 
                reps + shockCond +
               (-1 + hipp_val|subid) + 
               (-1 + hipp_loc|subid) + 
#                (-1 + hipp_loc:hipp_val|subid) + 
               (-1 + ERActUnsigned|subid) + 
               (1|subid), 
             data=d_hipp_long, family = "binomial"))
#when including random slope for interaction: Model failed to converge with max|grad| = 0.00166645 (tol = 0.001, component 1)

# Fixed effects:
#                             Estimate Std. Error z value Pr(>|z|)    
# (Intercept)               -0.4475550  0.1606885  -2.785  0.00535 ** 
# group1                     0.4453580  0.1606868   2.772  0.00558 ** 
# hipp_loc1                 -0.0003536  0.0205482  -0.017  0.98627    
# hipp_val                   0.1923756  0.0452421   4.252 2.12e-05 ***
# ERActUnsigned              0.2864644  0.0462469   6.194 5.86e-10 ***
# reps1                      0.3916379  0.0206696  18.947  < 2e-16 ***
# shockCond1                 0.0208784  0.0203538   1.026  0.30500    
# hipp_loc1:hipp_val        -0.0413424  0.0208610  -1.982  0.04750 *  
# group1:hipp_loc1          -0.0016695  0.0204051  -0.082  0.93479    
# group1:hipp_val            0.1008079  0.0452409   2.228  0.02586 *  
# group1:ERActUnsigned      -0.0302857  0.0462395  -0.655  0.51248    
# group1:hipp_loc1:hipp_val -0.0156174  0.0208157  -0.750  0.45309  

# what about quadratic interaction?
summary(glmer(pcorr ~ group*(hipp_loc * poly(hipp_val,2) + ERActUnsigned) + 
                reps + shockCond +
               (-1 + poly(hipp_val,2)|subid) + 
               (-1 + ERActUnsigned|subid) + 
               (1|subid), 
             data=d_hipp_long, family = "binomial", 
             control = glmerControl(optimizer="bobyqa",
                                    optCtrl=list(maxfun=2e5))))
# with hipp_loc random slope, model failed to converge...
# convergence code: 0
# Model failed to converge with max|grad| = 0.00697401 (tol = 0.001, component 1)
# failure to converge in 10000 evaluations

# Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [
# glmerMod]
#  Family: binomial  ( logit )
# Formula: pcorr ~ group * (hipp_loc * poly(hipp_val, 2) + ERActUnsigned) +  
#     reps + shockCond + (-1 + poly(hipp_val, 2) | subid) + (-1 +  
#     ERActUnsigned | subid) + (1 | subid)
#    Data: d_hipp_long
# Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e+05))
# 
#      AIC      BIC   logLik deviance df.resid 
#  14689.2  14846.5  -7323.6  14647.2    13225 
# 
# Scaled residuals: 
#     Min      1Q  Median      3Q     Max 
# -4.4298 -0.6753 -0.3368  0.7512  5.6247 
# 
# Random effects:
#  Groups  Name               Variance  Std.Dev. Corr
#  subid   poly(hipp_val, 2)1 899.60289 29.9934      
#          poly(hipp_val, 2)2 203.80104 14.2759  0.17
#  subid.1 ERActUnsigned        0.06932  0.2633      
#  subid.2 (Intercept)          1.07279  1.0358      
# Number of obs: 13246, groups:  subid, 42
# 
# Fixed effects:
#                                      Estimate Std. Error z value Pr(>|z|)    
# (Intercept)                         -0.446718   0.161497  -2.766  0.00567 ** 
# group1                               0.451578   0.161495   2.796  0.00517 ** 
# hipp_loc1                           -0.001778   0.020393  -0.087  0.93053    
# poly(hipp_val, 2)1                  23.863134   4.806530   4.965 6.88e-07 ***
# poly(hipp_val, 2)2                   2.378950   3.250073   0.732  0.46419    
# ERActUnsigned                        0.291749   0.046598   6.261 3.83e-10 ***
# reps1                                0.392907   0.020734  18.950  < 2e-16 ***
# shockCond1                           0.023208   0.020425   1.136  0.25584    
# hipp_loc1:poly(hipp_val, 2)1        -3.997673   2.338457  -1.710  0.08735 .  
# hipp_loc1:poly(hipp_val, 2)2        -0.668557   2.413193  -0.277  0.78175    
# group1:hipp_loc1                    -0.001122   0.020394  -0.055  0.95611    
# group1:poly(hipp_val, 2)1           11.697236   4.818808   2.427  0.01521 *  
# group1:poly(hipp_val, 2)2           10.308573   3.240900   3.181  0.00147 ** 
# group1:ERActUnsigned                -0.029853   0.046580  -0.641  0.52159    
# group1:hipp_loc1:poly(hipp_val, 2)1 -1.526027   2.336503  -0.653  0.51368    
# group1:hipp_loc1:poly(hipp_val, 2)2  2.092032   2.413863   0.867  0.38612    
# ---
# Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1
# 
# Correlation matrix not shown by default, as p = 16 > 12.
# Use print(x, correlation=TRUE)  or
# 	 vcov(x)	 if you need it


# Does the effect hold when just looking at hipp head?
summary(glmer(pcorr ~ group*(rGenHipp_head + ERActUnsigned) + reps + shockCond +
               (-1 + rGenHipp_head|subid) + 
               (-1 + ERActUnsigned|subid) + 
               (1|subid), 
             data=dCleanStandardized, family = "binomial"))
# rGenHipp_head         0.23621    0.05140   4.596 4.32e-06 ***
# group1:rGenHipp_head  0.11593    0.05139   2.256  0.02407 * 

# check that also holds in the tail
summary(glmer(pcorr ~ group*(rGenHipp_tail + ERActUnsigned) + reps + shockCond +
               (-1 + rGenHipp_tail|subid) + 
               (-1 + ERActUnsigned|subid) + 
               (1|subid), 
             data=dCleanStandardized, family = "binomial"))
# group1:rGenHipp_tail  0.08876    0.04403   2.016 0.043823 *  
```



### Full model, also controlling for angular bold
```{r}
# effect of more things on subsequent memory
deq.1c<-glmer(pcorr ~ group*(rGenHipp + ERActUnsigned + 
                               ERActUnsigned_infpar + rGenANG) +
                reps + shockCond +
               (-1 + rGenHipp|subid) + 
               (-1 + ERActUnsigned|subid) + 
               (-1 + ERActUnsigned_infpar|subid) + 
                (-1 + rGenANG|subid) + 
               (1|subid), 
             data=dCleanStandardized, family = "binomial",
             control=glmerControl(optimizer="bobyqa",
                                  optCtrl=list(maxfun=2e5))
             )
summary(deq.1c)
```
### Full model, also controlling for rsp
```{r}
# effect of more things on subsequent memory
deq.1d<-glmer(pcorr ~ group*(rGenHipp + ERActUnsigned + 
                               ERActUnsigned_infpar +
                               rGenANG + rGenRSP) +
                reps + shockCond +
               (-1 + rGenHipp|subid) + 
               (-1 + ERActUnsigned|subid) + 
               (-1 + ERActUnsigned_infpar|subid) + 
                (-1 + rGenANG|subid) + 
                (-1 + rGenRSP|subid) + 
               (1|subid), 
             data=dCleanStandardized, family = "binomial",
             control=glmerControl(optimizer="bobyqa",
                                  optCtrl=list(maxfun=2e5))
             )
summary(deq.1d)
```

### VTC reinstatement ~ hipp
```{r}
deq.2<-lmer(ERActUnsigned ~ group*(rGenHipp) + reps + shockCond + pcorr + 
              (-1 + rGenHipp|subid)+
              (1|subid), 
            data=dCleanStandardized)
# uncorrelate random slopes and intercepts
summary(deq.2)
fixef(deq.2)
fixef(deq.2)[3] # VTC ~ hipp direct effect 
fixef(deq.2)[7] # VTC ~ group:hipp


# interaction
summary(lmer(ERActUnsigned ~ rGenHipp + reps + shockCond + pcorr + 
              (-1 + rGenHipp|subid)+
              (1|subid), 
            data=dCleanStandardized %>% filter(group == 'control')))

summary(lmer(ERActUnsigned ~ rGenHipp + reps + shockCond + pcorr + 
              (-1 + rGenHipp|subid)+
              (1|subid), 
            data=dCleanStandardized %>% filter(group == 'stress')))

## double check with simple effects
# controls:
contrasts(dCleanStandardized$group) = c(0,1); contrasts(dCleanStandardized$group)
summary(lmer(ERActUnsigned ~ group*(rGenHipp) + reps + shockCond + pcorr + 
              (-1 + rGenHipp|subid)+
              (1|subid), 
            data=dCleanStandardized))

# stress:
contrasts(dCleanStandardized$group) = c(1,0); contrasts(dCleanStandardized$group)
summary(lmer(ERActUnsigned ~ group*(rGenHipp) + reps + shockCond + pcorr + 
              (-1 + rGenHipp|subid)+
              (1|subid), 
            data=dCleanStandardized))

contrasts(dCleanStandardized$group) = c(1,-1); contrasts(dCleanStandardized$group)

# look at raw reinstatement by median split of hipp signal
dat = dCleanStandardized %>%
  group_by(subid, group) %>%
  mutate(hipp_med = ntile(hipp_sig, 2)) %>%
  ungroup()

summary(lmer(vtc_logit ~ group + reps + shockCond + pcorr +
              (1|subid), 
            data=dat %>% filter(hipp_med == 1)))

summary(lmer(vtc_logit ~ group + reps + shockCond + pcorr + 
              (1|subid), 
            data=dat %>% filter(hipp_med == 2)))

# what about rep effect?
summary(lmer(ERActUnsigned ~ group*(rGenHipp) + reps + shockCond + pcorr + 
              (-1 + rGenHipp|subid)+
              (-1 + reps|subid)+
              (1|subid), 
            data=dCleanStandardized))
```

#### Double check: does it matter if pcorr is included?
```{r}
summary(lmer(ERActUnsigned ~ group*(rGenHipp) + reps + shockCond + pcorr +
              (-1 + rGenHipp|subid)+
              (1|subid), 
            data=dCleanStandardized))

summary(lmer(ERActUnsigned ~ group*(rGenHipp) + reps + shockCond +
              (-1 + rGenHipp|subid)+
              (1|subid), 
            data=dCleanStandardized))

summary(lmer(ERActUnsigned ~ group*(rGenHipp*pcorr) + reps + shockCond +
              (-1 + rGenHipp|subid)+
               (-1 + pcorr|subid)+
               (-1 + rGenHipp:pcorr|subid)+
              (1|subid), 
            data=dCleanStandardized))
```





### Mediation of hipp -> pcorr by VTC reinstatement
```{r}
# run mediation if requested, otherwise just read in data already generated
if (run_mediation == TRUE){
  
  ## bootstrapping approach
  bootDist_0_hipp<-NULL
  bootDist_0_hippxgroup<-NULL
  bootDist_1_vtc<-NULL
  bootDist_1_vtcxgroup<-NULL
  bootDist_1_hipp<-NULL
  bootDist_1_hippxgroup<-NULL
  bootDist_2_hipp<-NULL
  bootDist_2_hippxgroup<-NULL
  min_persub <- NULL
  
  for (i in 1:5000) {
    print(i)
    # randomly sample from data, with replacement
    o1<-dCleanStandardized[sample(1:dim(dCleanStandardized)[1],
                                  size=dim(dCleanStandardized)[1],
                                  replace=T),]
    
    min_persub[i] = min(with(o1, table(subid))) # make sure sampling roughly equally across subs
    # all trials
    
    beq.0<-glmer(pcorr ~ group*(rGenHipp) + reps + shockCond +
                   (-1 + rGenHipp|subid) + 
                   (1|subid), 
                 data=o1, family = "binomial")
    
    bootDist_0_hipp[i]<-fixef(beq.0)[3] # overall effect of hipp
    bootDist_0_hippxgroup[i]<-fixef(beq.0)[6] # overall effect of hipp:group
    
    
    beq.1<-glmer(pcorr ~ group*(rGenHipp + ERActUnsigned) + reps + shockCond +
                   (-1 + rGenHipp|subid) + 
                   (-1 + ERActUnsigned|subid) + 
                   (1|subid), 
                 data=o1, family = "binomial")
    
    bootDist_1_vtc[i]<-fixef(beq.1)[4]
    bootDist_1_hipp[i]<-fixef(beq.1)[3]
    bootDist_1_hippxgroup[i]<-fixef(beq.1)[7]
    bootDist_1_vtcxgroup[i]<-fixef(beq.1)[8]
    
    beq.2<-lmer(ERActUnsigned ~ group*(rGenHipp) + reps + shockCond +  pcorr + 
                  (-1 + rGenHipp|subid)+
                  (1|subid), 
                data=o1)
    
    bootDist_2_hipp[i]<-fixef(beq.2)[3]
    bootDist_2_hippxgroup[i]<-fixef(beq.2)[7]
    
  }
  
  # Save out estimates
  boot_est = 
    data.frame(bootDist_0_hipp,
               bootDist_0_hippxgroup,
               bootDist_1_vtc,
               bootDist_1_vtcxgroup,
               bootDist_1_hipp,
               bootDist_1_hippxgroup,
               bootDist_2_hipp,
               bootDist_2_hippxgroup,
               min_persub)
  
  head(boot_est)
  dim(boot_est) # 5000x9
  # write.csv(boot_est, '~/Experiments/AP/stats/pcorr_hippxvtc_bootest.csv')
}

# read in estimates
boot_est = read.csv('~/Experiments/AP/stats/pcorr_hippxvtc_bootest.csv')
head(boot_est)
dim(boot_est) # 5000x10


# overall effect
mean(boot_est$bootDist_0_hipp)
quantile(boot_est$bootDist_0_hipp, c(.025, 0.975))
mean(boot_est$bootDist_0_hippxgroup)
quantile(boot_est$bootDist_0_hippxgroup, c(.025, 0.975))

# direct effect
mean(boot_est$bootDist_1_hipp)
quantile(boot_est$bootDist_1_hipp, c(.025, 0.975))

mean(boot_est$bootDist_1_hippxgroup)
quantile(boot_est$bootDist_1_hippxgroup, c(.025, 0.975))

# a
mean(boot_est$bootDist_2_hipp)
quantile(boot_est$bootDist_2_hipp,c(.025, 0.975))

mean(boot_est$bootDist_2_hippxgroup)
quantile(boot_est$bootDist_2_hippxgroup,c(.025, 0.975))

# b
mean(boot_est$bootDist_1_vtc)
quantile(boot_est$bootDist_1_vtc, c(.025, 0.975))

mean(boot_est$bootDist_1_vtcxgroup)
quantile(boot_est$bootDist_1_vtcxgroup, c(.025, 0.975))

# mediation
IE_hippVIAvtc = boot_est$bootDist_1_vtc * boot_est$bootDist_2_hipp
hist(IE_hippVIAvtc)

mean(IE_hippVIAvtc)
quantile(IE_hippVIAvtc,c(.025, 0.975))
```

## Plots:

### pSourcehit ~ hipp BOLD
```{r echo=FALSE, cache=TRUE} 
d_avg = dm %>% 
  mutate(pcorr = as.numeric(pcorr)-1) %>%
  group_by(subid, group, hipp_quintile, reps) %>%
  summarise(pcorr = mean_(pcorr))

dfwc = summarySEwithin(d_avg, measurevar="pcorr", 
                       withinvars=c("hipp_quintile", "reps"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc = dfwc%>% 
  mutate(reps=ifelse(reps == "4", "strong", "weak"),
         reps=factor(reps, levels=c('weak', 'strong')))
dfwc

p2 = ggplot(dfwc, aes(x=hipp_quintile, y=pcorr, group=group, color=group)) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=pcorr-se, 
                               ymax=pcorr+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  facet_grid(. ~ reps) +
  xlab('Hippocampal activity (quintiles)')+
  ylab('p HC recollection')+
  scale_color_manual(values=palette, guide = guide_legend(title = NULL))
p2

ggsave(p2, 
       filename ='~/Experiments/AP/figs/pcorrXhippxreps_quintile_allOLD_wholehipp.jpg', 
       dpi=150, width = 8, height=4.4)

### Now collapse across reps for main plot
d_avg = dm %>% 
  mutate(pcorr = as.numeric(pcorr)-1) %>%
  group_by(subid, group, hipp_quintile, reps) %>%
  summarise(pcorr = mean_(pcorr)) %>%
  group_by(subid, group, hipp_quintile) %>%
  summarise(pcorr = mean_(pcorr))

dfwc = summarySEwithin(d_avg, measurevar="pcorr", withinvars=c("hipp_quintile"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc


ann_text <- data.frame(hipp_quintile = c(2, 4), 
                       pcorr = c(.55, .28),
                       group=c('control', 'stress'),
                       lab=c("control", "stress"))

p2 = ggplot(dfwc, aes(x=hipp_quintile, y=pcorr, group=group, color=group)) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=pcorr-se, 
                               ymax=pcorr+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  xlab('Hippocampal activity (quintiles)')+
  ylab('p HC recollection')+
  scale_color_manual(values=palette, 
                     guide = guide_legend(title = NULL)) +
  geom_text(data = ann_text, aes(label=lab), size=7) +
  theme_classic(base_size = 20)+
  theme(legend.title=element_blank(), 
        legend.position="none",
        strip.background = element_rect(colour="white", fill="white"))
p2

ggsave(p2, 
       filename ='~/Experiments/AP/figs/pcorrXhipp_quintile_allOLD_wholehipp.jpg', 
       dpi=600, width = 4.65, height=4)
```


### Plot prop trials/cond by hipp quintile
```{r}
old_counts = dm %>% 
  group_by(subid, group, hipp_quintile) %>%
  summarise(old_count = n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), hipp_quintile, fill = list(old_count=0))

d_counts = dm %>% 
  group_by(subid, group, cond, hipp_quintile) %>%
  summarise(count = n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), cond, hipp_quintile, fill = list(count=0))

d_avg = d_counts %>% left_join(old_counts) %>% 
  mutate(prop = count/old_count)
d_avg


dfwc = summarySEwithin(d_avg, measurevar="prop", withinvars=c("hipp_quintile",
                                                              "cond"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

p2 = ggplot(dfwc, aes(x=hipp_quintile, y=prop, group=cond, color=cond)) +
    facet_grid(.~group)+
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=prop-se, 
                               ymax=prop+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  xlab('Hippocampal activity (quintiles)')+
  ylab('p Old trials')+
  scale_color_brewer(palette = 'Set1', guide = guide_legend(title = NULL))

ggsave(p2, 
       filename ='~/Experiments/AP/figs/pOLDXhippxreps_quintile_allOLD_wholehipp.jpg', 
       dpi=150, width = 8, height=4.4)
p2
```

### Plot prop trials/cond by VTC quintile
```{r}
old_counts = dm %>% 
  group_by(subid, group, vtc_quintile) %>%
  summarise(old_count = n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), vtc_quintile, fill = list(old_count=0))

d_counts = dm %>% 
  group_by(subid, group, cond, vtc_quintile) %>%
  summarise(count = n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), cond, vtc_quintile, fill = list(count=0))

d_avg = d_counts %>% left_join(old_counts) %>% 
  mutate(prop = count/old_count)
d_avg


dfwc = summarySEwithin(d_avg, measurevar="prop", withinvars=c("vtc_quintile",
                                                              "cond"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

p2 = ggplot(dfwc, aes(x=vtc_quintile, y=prop, group=cond, color=cond)) +
    facet_grid(.~group)+
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=prop-se, 
                               ymax=prop+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  xlab('Reinstatement strength (quintiles)')+
  ylab('p Old trials')+
  scale_color_brewer(palette = 'Set1', guide = guide_legend(title = NULL))

ggsave(p2, 
       filename ='~/Experiments/AP/figs/pOLDXvtc_quintile_allOLD_wholehipp.jpg', 
       dpi=150, width = 8, height=4.4)
p2
```


### z-scored hipp by condition
```{r}
d_avg = dm %>% 
  group_by(subid, group, cond) %>%
  summarise(hipp_sig_z = mean(hipp_sig_z))
d_avg

dfwc = summarySEwithin(d_avg, measurevar="hipp_sig_z", withinvars=c("cond"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

p2 = ggplot(dfwc, aes(x=cond, y=hipp_sig_z, group=group, color=group)) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=hipp_sig_z-se, 
                               ymax=hipp_sig_z+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  xlab('condition')+
  ylab('Hippocampal signal\n(z-scored)')+
  scale_color_manual(values = palette, guide = guide_legend(title = NULL))
p2

ggsave(p2,
       filename ='~/Experiments/AP/figs/hippsigzxcond_allOLD_wholehipp.jpg',
       dpi=150, width = 8, height=4.4)
p2
```

### pSourcehit ~ VTC
```{r echo=FALSE, cache=TRUE} 
d_avg = dm %>% 
  mutate(pcorr = as.numeric(pcorr)-1) %>%
  group_by(subid, group, vtc_quintile, reps) %>%
  summarise(pcorr = mean_(pcorr))

dfwc = summarySEwithin(d_avg, measurevar="pcorr", withinvars=c("vtc_quintile", "reps"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc = dfwc%>% 
  mutate(reps=ifelse(reps == "4", "strong", "weak"),
         reps=factor(reps, levels=c('weak', 'strong')))
dfwc

p2 = ggplot(dfwc, aes(x=vtc_quintile, y=pcorr, group=group, color=group)) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=pcorr-se, 
                               ymax=pcorr+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  facet_grid(. ~ reps) +
  xlab('Reinstatement strength (quintiles)')+
  ylab('p HC recollection')+
  scale_color_manual(values=palette, guide = guide_legend(title = NULL))
p2

ggsave(p2, 
       filename ='~/Experiments/AP/figs/pcorrXvtcxreps_quintile_allOLD_wholehipp.jpg', 
       dpi=150, width = 8, height=4.4)

### Now collapse across reps for main plot
d_avg = dm %>% 
  mutate(pcorr = as.numeric(pcorr)-1) %>%
  group_by(subid, group, vtc_quintile, reps) %>%
  summarise(pcorr = mean_(pcorr)) %>%
  group_by(subid, group, vtc_quintile) %>%
  summarise(pcorr = mean_(pcorr))

dfwc = summarySEwithin(d_avg, measurevar="pcorr", withinvars=c("vtc_quintile"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

p2 = ggplot(dfwc, aes(x=vtc_quintile, y=pcorr, group=group, color=group)) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=pcorr-se, 
                               ymax=pcorr+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  xlab('Reinstatement strength (quintiles)')+
  ylab('p HC recollection')+
  scale_color_manual(values=palette, guide = guide_legend(title = NULL))
p2

ggsave(p2, 
       filename ='~/Experiments/AP/figs/pcorrXvtc_quintile_allOLD_wholehipp.jpg', 
       dpi=150, width = 5.5, height=4)
ggsave(p2, 
       filename ='~/Dropbox/Stanford/Papers/Dissertation/Figures_defense/AP_pcorrXvtc_quintile_allOLD_wholehipp.jpg', 
       dpi=300, width = 5.5, height=4)
p2
```

### VTC ~ hipp BOLD
```{r}
dm_avg = dm %>%
  group_by(subid, group, hipp_quintile, reps) %>%
  summarise(vtc_logit = mean_(vtc_logit), count = n()) 

dim(dm_avg)
dfwc = summarySEwithin(dm_avg, measurevar="vtc_logit", 
                       withinvars=c("hipp_quintile", "reps"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95) %>% 
  mutate(reps=ifelse(reps == "4", "strong", "weak"),
         reps=factor(reps, levels=c('weak', 'strong')))
dfwc

p2 = ggplot(dfwc, aes(x=hipp_quintile, y=vtc_logit, group=group, color=group)) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=vtc_logit-se, 
                               ymax=vtc_logit+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  facet_grid(. ~ reps) +
  ylab('Reinstatement strength (logits)')+
  xlab('Hippocampal activity (quintiles)')+
  scale_color_manual(values=palette, guide = guide_legend(title = NULL))
p2

ggsave(p2, 
       filename ='~/Experiments/AP/figs/logitXhippxreps_quintile_allOLD_wholehipp.jpg', 
       dpi=150, width = 8, height=4.4)
p2


## collapse across rep
dm_avg = dm %>%
  group_by(subid, group, hipp_quintile, reps) %>%
  summarise(vtc_logit = mean_(vtc_logit), count = n()) %>%
  group_by(subid, group, hipp_quintile) %>%
  summarise(vtc_logit = mean_(vtc_logit), count = n()) 

dfwc = summarySEwithin(dm_avg, measurevar="vtc_logit", 
                       withinvars=c("hipp_quintile"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

p2 = ggplot(dfwc, aes(x=hipp_quintile, y=vtc_logit, group=group, color=group)) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=vtc_logit-se, 
                               ymax=vtc_logit+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('Reinstatement strength')+
  xlab('Hippocampal activity (quintiles)')+
  scale_color_manual(values=palette, 
                     guide = guide_legend(title = NULL))+
  theme_classic(base_size = 20)+
  theme(legend.title=element_blank(), 
        legend.position="none",
        strip.background = element_rect(colour="white", fill="white"))
p2

ggsave(p2, 
       filename ='~/Experiments/AP/figs/logitXhipp_quintile_allOLD_wholehipp.jpg', 
       dpi=600, width = 4.65, height=4)
p2

```



```{r}
## logits (z-scored within subj)
dm_avg = dm %>%
  group_by(subid, group, hipp_quintile, reps) %>%
  summarise(vtc_logit = mean_(vtc_logit_z), count = n()) %>%
  group_by(subid, group, hipp_quintile) %>%
  summarise(vtc_logit = mean_(vtc_logit), count = n()) 

dfwc = summarySEwithin(dm_avg, measurevar="vtc_logit", withinvars=c("hipp_quintile"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

p2 = ggplot(dfwc, aes(x=hipp_quintile, y=vtc_logit, group=group, color=group)) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=vtc_logit-se, 
                               ymax=vtc_logit+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('Reinstatement strength\n(z-scored logits)')+
  xlab('Hippocampal activity (quintiles)')+
  scale_color_manual(values=palette, guide = guide_legend(title = NULL))
p2

ggsave(p2, 
       filename ='~/Experiments/AP/figs/zscoredlogitXhipp_quintile_allOLD_wholehipp.jpg', 
       dpi=150, width = 6, height=4)
p2

```


### Look at hipp raw timecourse across all old trials

```{r}
# Read in hipp BOLD
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-hippocampus.csv')
roi_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-hippocampus.csv')

# Take timepoints of interest for old trials, and collapse across hemispheres
roi_f = bind_rows("lh" = roi_lh, "rh" = roi_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M')) %>%
  group_by(subid, hemi, run, onset, time) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset, time) %>%
  summarise(hipp_sig = mean_(mean_activity)) %>% ungroup()

roi_f = roi_f %>% inner_join(d, by=c('subid', 'run', 'onset')) %>%
   mutate(subid = factor(subid),
         cond = factor(cond)) %>%
  left_join(dm %>% dplyr::select(subid, run, onset, hipp_quintile))

roi_f %>% group_by(group, subid) %>% summarise(n()) %>% group_by(group) %>% summarise(n())
head(roi_f)

with(roi_f, table(cond, condition))

ggplot(roi_f %>% group_by(subid, cond, time) %>% 
         summarise(hipp_sig = mean(hipp_sig)) %>% 
         group_by(time, cond) %>% 
         summarise(mean(hipp_sig)), 
       aes(x=time, y=`mean(hipp_sig)`, color=cond, group=cond)) +
  geom_line()
```

##### Break down by quintile (from above plotting)
```{r}
hipp_avg = roi_f %>% 
  group_by(subid, group, hipp_quintile, time) %>% 
  summarise(hipp_sig = mean(hipp_sig)) %>%
  group_by(group, hipp_quintile, time) %>%
  summarise(mean = mean(hipp_sig), se = std.error(hipp_sig), n())
hipp_avg  

blues <- brewer.pal(6, "Blues")[2:6]
p2 = ggplot(hipp_avg, aes(x=factor(time), y=mean, group=factor(hipp_quintile), color=factor(hipp_quintile))) +
    facet_grid(.~group) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=mean-se, 
                               ymax=mean+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('% signal change') +
  xlab('Time post-stimulus onset (s)') +
  guides(color=guide_legend(title="Quintile")) +
  scale_color_manual(values=blues)
ggsave(p2,
       filename ='~/Experiments/AP/figs/hipp_bytimeXhippQuintile.jpg',
       dpi=300, width = 8, height=4)
p2

p2 = ggplot(hipp_avg %>% filter(hipp_quintile == 5), 
            aes(x=factor(time), y=mean, group=group, color=group)) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=mean-se, 
                               ymax=mean+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('% signal change') +
  xlab('Time post-stimulus onset (s)') +
  guides(color=FALSE) +
  scale_color_manual(values=palette)
p2
ggsave(p2,
       filename ='~/Experiments/AP/figs/hipp_bytimeX5thquintile.jpg',
       dpi=300, width = 5, height=4)
p2
```


# 2b) Signal variation for HC associative hits

```{r}
# standardize continuous vars
dCleanStandardized_HC = dm %>% filter(pcorr == 1)
dCleanStandardized_HC = dCleanStandardized_HC %>% 
  group_by(subid) %>%
   mutate(ang_logit_z = zscore(ang_logit),
         vtc_logit_z = zscore(vtc_logit),
         hipp_logit_z = zscore(hipp_logit),
         CCN_sig_z = zscore(CCN_sig),
         DAN_sig_z = zscore(DAN_sig),
         CCN_lh_sig_z = zscore(CCN_lh_sig),
         DAN_lh_sig_z = zscore(DAN_lh_sig),
         hipp_sig_z = zscore(hipp_sig),
         hipp_tail_sig_z = zscore(hipp_tail_sig),
         reps = factor(reps),
         hipp_quintile = ntile(hipp_sig, 5),
         CCN_quintile = ntile(CCN_sig, 5),
         DAN_quintile = ntile(DAN_sig, 5),
         CCN_lh_quintile = ntile(CCN_lh_sig, 5),
         DAN_lh_quintile = ntile(DAN_lh_sig, 5),
         hipp_tail_quintile = ntile(hipp_tail_sig, 5),
         vtc_quintile = ntile(vtc_logit, 5),
         hipp_logit_quintile = ntile(hipp_logit, 5),
         ang_quintile = ntile(ang_logit, 5),
         rt_z = zscore(respRT))

dCleanStandardized_HC$rGenHipp<-scale(dCleanStandardized_HC$hipp_sig_z)
dCleanStandardized_HC$ERActUnsigned<-scale(dCleanStandardized_HC$vtc_logit_z)
dCleanStandardized_HC$ERActUnsigned_infpar<-scale(dCleanStandardized_HC$ang_logit_z)
dCleanStandardized_HC$RT_z<-scale(dCleanStandardized_HC$rt_z)

contrasts(dCleanStandardized_HC$group) 
contrasts(dCleanStandardized_HC$reps)  = c(-1,1); contrasts(dCleanStandardized_HC$reps)
contrasts(dCleanStandardized_HC$shockCond) 


# look at trial counts/subj
trial_counts = data.frame(with(dCleanStandardized_HC, table(subid)))
trial_counts %>% summarise(min(Freq), max(Freq), mean(Freq), sd(Freq))
```

#### Subj level effects

```{r}
datalist = list()
i = 1
for (subject in unique(dCleanStandardized_HC$subid)){
  print(subject)
  fit = lm(vtc_logit_z ~ hipp_sig_z + reps + shockCond + pcorr,
            data=dCleanStandardized %>% filter(subid == subject))
  print(fit$coefficients['hipp_sig_z'])
  dat = data.frame(subid=subject,
                   coef = fit$coefficients['hipp_sig_z'])
  datalist[[i]] <- dat 
  i = 1+i
}

slopes_vtcXhipp <- dplyr::bind_rows(datalist) %>% 
  left_join(dCleanStandardized %>% 
                                group_by(subid, group) %>% 
                                summarise(n()))
with(slopes_vtcXhipp , boxplot(coef ~ group))
bartlett.test(coef ~ group, data=slopes_vtcXhipp)
t.test(coef ~ group, data=slopes_vtcXhipp, var.equal=TRUE)

ggplot(slopes_vtcXhipp, aes(x=group, y=coef)) + 
  geom_boxplot(outlier.alpha = 0)+
  geom_point(position = position_jitter(width=.1)) +
  xlab('') + ylab('Slope (vtc ~ hipp)')

# ## now dont control for pcorr
# datalist = list()
# i = 1
# for (subject in unique(dCleanStandardized_HC$subid)){
#   print(subject)
#   fit = lm(vtc_logit_z ~ hipp_sig_z + reps + shockCond ,
#             data=dCleanStandardized %>% filter(subid == subject))
#   print(fit$coefficients['hipp_sig_z'])
#   dat = data.frame(subid=subject,
#                    coef = fit$coefficients['hipp_sig_z'])
#   datalist[[i]] <- dat 
#   i = 1+i
# }
# 
# slopes_vtcXhipp <- dplyr::bind_rows(datalist) %>% 
#   left_join(dCleanStandardized %>% 
#                                 group_by(subid, group) %>% 
#                                 summarise(n()))
# with(slopes_vtcXhipp , boxplot(coef ~ group))
# bartlett.test(coef ~ group, data=slopes_vtcXhipp)
# t.test(coef ~ group, data=slopes_vtcXhipp, var.equal=TRUE)
```
```{r}
with(slopes_vtcXhipp %>% left_join(assoc_d %>% 
                                group_by(subid, group) %>% 
                                summarise(assoc_d = mean(assoc_d))),
     summary(lm(coef ~ assoc_d)))

```

```{r}
summary(lmer(CCN_lh_sig ~ group + (1|subid), 
             data=dCleanStandardized_HC %>% filter(CCN_lh_quintile == 1)))
summary(lmer(CCN_lh_sig ~ group + (1|subid), 
             data=dCleanStandardized_HC %>% filter(CCN_lh_quintile == 2)))
summary(lmer(CCN_lh_sig ~ group + (1|subid), 
             data=dCleanStandardized_HC %>% filter(CCN_lh_quintile == 3)))
summary(lmer(CCN_lh_sig ~ group + (1|subid), 
             data=dCleanStandardized_HC %>% filter(CCN_lh_quintile == 4)))
summary(lmer(CCN_lh_sig ~ group + (1|subid), 
             data=dCleanStandardized_HC %>% filter(CCN_lh_quintile == 5)))
```


## 2b (i): Does hipp still track VTC for HC recollection?
```{r}
deq.2b<-lmer(ERActUnsigned ~ group*(rGenHipp) + reps + shockCond +
              (-1 + rGenHipp|subid)+
              (1|subid), 
            data=dCleanStandardized_HC)
# uncorrelate random slopes and intercepts
summary(deq.2b)

# look at raw reinstatement by median split of hipp (un-zscored)
dat = dCleanStandardized_HC %>%
  filter(pcorr == 1) %>%
  group_by(subid, group) %>%
  mutate(hipp_med = ntile(hipp_sig, 2)) %>%
  ungroup()

summary(lmer(vtc_logit ~ group + reps + shockCond + 
              (1|subid), 
            data=dat %>% filter(hipp_med == 1)))

summary(lmer(vtc_logit ~ group + reps + shockCond + 
              (1|subid), 
            data=dat %>% filter(hipp_med == 2)))

# what about rep effect?
summary(lmer(ERActUnsigned ~ group*(rGenHipp) + reps + shockCond + 
              (-1 + rGenHipp|subid)+
              (-1 + reps|subid)+
              (1|subid), 
            data=dCleanStandardized_HC))
```
Hippocampal activity does scale with VTC reinstatement strength across HC recollection; there's no effect of encoding strength on VTC reinstatement strength when controlling for hippocampal activity. There's a marginal group interaction, similar to that seen across all old items.

### Plot
```{r}
## collapse across rep
dm_avg = dm %>% filter(pcorr == 1) %>%
  group_by(subid) %>%
  mutate(hipp_quintile = ntile(hipp_sig, 5)) %>%
  group_by(subid, group, hipp_quintile, reps) %>%
  summarise(vtc_logit = mean_(vtc_logit), count = n()) %>%
  group_by(subid, group, hipp_quintile) %>%
  summarise(vtc_logit = mean_(vtc_logit), count = n()) 

dfwc = summarySEwithin(dm_avg, measurevar="vtc_logit", withinvars=c("hipp_quintile"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

p2 = ggplot(dfwc, aes(x=hipp_quintile, y=vtc_logit, group=group, color=group)) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=vtc_logit-se, 
                               ymax=vtc_logit+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('Reinstatement strength\n(logits)')+
  xlab('Hippocampal activity (quintiles)')+
  scale_color_manual(values=palette, guide = guide_legend(title = NULL))
p2

ggsave(p2, 
       filename ='~/Experiments/AP/figs/logitXhipp_quintile_HCrecollection_wholehipp.jpg', 
       dpi=150, width = 6, height=4)
p2
```


## 2b (ii): Is frontoparietal activity modulated by RT/difficulty of HC decisions? 

Predict that more uncertain HC recollection decisions should scale with RT + frontoparietal bold (particularly in LH). We'll test lh first, then look to see if holds in bilateral network.

Since encoding strength tracks RT for HC decisions (faster RTs for stronger encoding items), these might require less FP activity to recall. 

Would hipp be the reverse? Greater activity for more vivid/confident/faster memories? Or, would hipp be greater for slower HC recollection of associate, where potentially have retrieved more things/activated more neurons in hipp before settling on correct response?

### Include all subjects included in fMRI analyses:
```{r}
d = read.csv('/Users/sgagnon/Dropbox/Stanford/Presentations/AP/mvpa_logit_place_byreps_avg_46810_filtartloc_scalewithinrun.csv')

# filter d to just good subjs, and only OLD items
d = d %>%
  filter(cond %in% c('sourcemiss_hi', 'sourcehit', 'M', 'itemhit_lo')) %>%
  mutate(pcorr = factor(ifelse(cond == "sourcehit", 1, 0)),
         vtc_logit = avg_logit)

dt %>% filter(shock_and_post == 2) # one subj w/consecutive shocks - trial needs to be removed (though mem_condition == 'nuisance')

# Merge w/other behavioral info
d = dt %>%
  mutate(onset=onset_adj, img_type=cond) %>% 
  dplyr::select(-group, -reps, -cond) %>%
  right_join(d, by=c('subid', 'run', 'onset')) %>%
  mutate(subid = factor(subid), imgType = factor(img_type))
dim(d)
d = d %>% filter(shock_and_post == 0)
dim(d)

# Read in hipp BOLD
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-hippocampus.csv')
roi_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-hippocampus.csv')
# dim(roi_lh); dim(roi_rh)

# Take timepoints of interest for old trials, and collapse across hemispheres
roi_f = bind_rows("lh" = roi_lh, "rh" = roi_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, hemi, run, onset) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset) %>%
  summarise(hipp_sig = mean_(mean_activity)) %>% ungroup()

# Read in hipp tail BOLD
roi_tail_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-hippocampus-tail.csv')
roi_tail_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-hippocampus-tail.csv')

# Take timepoints of interest for old trials, and collapse across hemispheres
roi_tail_f = bind_rows("lh" = roi_tail_lh, "rh" = roi_tail_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, hemi, run, onset) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset) %>%
  summarise(hipp_tail_sig = mean_(mean_activity)) %>% ungroup()

# Read in angular BOLD
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-DefaultA_IPL.csv')
angular_lh_f = roi_lh %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, run, onset) %>%
  summarise(angular_lh_sig = mean_(mean_activity)) %>% ungroup()

# Read in RSP BOLD
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-DefaultC_Rsp.csv')
roi_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-DefaultC_Rsp.csv')

# Take timepoints of interest for old trials, and collapse across hemispheres
rsp_f = bind_rows("lh" = roi_lh, "rh" = roi_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, hemi, run, onset) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset) %>%
  summarise(rsp_sig = mean_(mean_activity)) %>% ungroup()

# Read in CCN BOLD
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-frontoparietal.csv')
roi_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-frontoparietal.csv')
# dim(roi_lh); dim(roi_rh)

# Take timepoints of interest for old trials, and collapse across hemispheres
CCN_f = bind_rows("lh" = roi_lh, "rh" = roi_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, hemi, run, onset) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset) %>%
  summarise(CCN_sig = mean_(mean_activity)) %>% ungroup()

# also, just for LH
CCN_lh_f = roi_lh %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, run, onset) %>%
  summarise(CCN_lh_sig = mean_(mean_activity)) %>% ungroup()

# Read in DAN BOLD
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-dorsalattn.csv')
roi_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-dorsalattn.csv')
# dim(roi_lh); dim(roi_rh)

# Take timepoints of interest for old trials, and collapse across hemispheres
DAN_f = bind_rows("lh" = roi_lh, "rh" = roi_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, hemi, run, onset) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset) %>%
  summarise(DAN_sig = mean_(mean_activity)) %>% ungroup()

# also, just for LH
DAN_lh_f = roi_lh %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, run, onset) %>%
  summarise(DAN_lh_sig = mean_(mean_activity)) %>% ungroup()

# Other reinstatement
d_infpar = read.csv('/Users/sgagnon/Dropbox/Stanford/Presentations/AP/mvpa_logit_inferiorparietal_place_byreps_avg_46810_filtartloc_scalewithinrun.csv') %>%
  filter(cond %in% c('sourcemiss_hi', 'sourcehit', 'M', 'itemhit_lo')) %>%
  mutate(ang_logit = avg_logit) %>%
  dplyr::select(subid, run, onset, ang_logit)

d_hipp = read.csv('/Users/sgagnon/Dropbox/Stanford/Presentations/AP/mvpa_logit_bilat-hippocampus_place_byreps_avg_46810_filtartloc_scalewithinrun.csv') %>%
  filter(cond %in% c('sourcemiss_hi', 'sourcehit', 'M', 'itemhit_lo')) %>%
  mutate(pcorr = factor(ifelse(cond == "sourcehit", 1, 0)),
         hipp_logit = avg_logit) %>%
  dplyr::select(subid, run, onset, hipp_logit)

# Merge w/VTC classifier evidence
dm_allfmri = d %>%
  left_join(roi_f, by=c('subid', 'run', 'onset')) %>%
  left_join(roi_tail_f, by=c('subid', 'run', 'onset')) %>%
  left_join(DAN_f, by=c('subid', 'run', 'onset')) %>%
  left_join(CCN_f, by=c('subid', 'run', 'onset')) %>%
  left_join(rsp_f, by=c('subid', 'run', 'onset')) %>%
  left_join(angular_lh_f, by=c('subid', 'run', 'onset')) %>%
  left_join(DAN_lh_f, by=c('subid', 'run', 'onset')) %>%
  left_join(CCN_lh_f, by=c('subid', 'run', 'onset')) %>%
  left_join(d_infpar, by=c('subid', 'run', 'onset')) %>%
  left_join(d_hipp, by=c('subid', 'run', 'onset')) %>%
  group_by(subid) %>%
  mutate(ang_logit_z = zscore(ang_logit),
         vtc_logit_z = zscore(vtc_logit),
         hipp_logit_z = zscore(hipp_logit),
         CCN_sig_z = zscore(CCN_sig),
         rsp_sig_z = zscore(rsp_sig),
         DAN_sig_z = zscore(DAN_sig),
         angular_lh_sig_z = zscore(angular_lh_sig),
         CCN_lh_sig_z = zscore(CCN_lh_sig),
         DAN_lh_sig_z = zscore(DAN_lh_sig),
         hipp_sig_z = zscore(hipp_sig),
         hipp_tail_sig_z = zscore(hipp_tail_sig),
         reps = factor(reps),
         hipp_quintile = ntile(hipp_sig, 5),
         rsp_quintile = ntile(rsp_sig, 5),
         CCN_quintile = ntile(CCN_sig, 5),
         DAN_quintile = ntile(DAN_sig, 5),
         angular_lh_sig_quintile = ntile(angular_lh_sig, 5),
         CCN_lh_quintile = ntile(CCN_lh_sig, 5),
         DAN_lh_quintile = ntile(DAN_lh_sig, 5),
         hipp_tail_quintile = ntile(hipp_tail_sig, 5),
         vtc_quintile = ntile(vtc_logit, 5),
         hipp_logit_quintile = ntile(hipp_logit, 5),
         ang_quintile = ntile(ang_logit, 5)) %>%
  ungroup() %>%
  mutate(subid = factor(subid),
         cond = factor(cond),
         condition = factor(condition))
dim(dm_allfmri)
with(dm_allfmri, table(subid, reps))

str(dm_allfmri)

# set up contrasts
contrasts(dm_allfmri$pcorr) = c(-1,1); contrasts(dm_allfmri$pcorr)
contrasts(dm_allfmri$reps) = c(-1,1); contrasts(dm_allfmri$reps)
contrasts(dm_allfmri$group) = c(1,-1); contrasts(dm_allfmri$group)
contrasts(dm_allfmri$shockCond) = c(1,-1); contrasts(dm_allfmri$shockCond)

# standardize continuous vars
dCleanStandardized_HC_allfmri = dm_allfmri %>% filter(pcorr == 1)
with(dCleanStandardized_HC_allfmri, table(subid, reps))

dCleanStandardized_HC_allfmri = dCleanStandardized_HC_allfmri %>% 
  group_by(subid) %>%
   mutate(ang_logit_z = zscore(ang_logit),
         vtc_logit_z = zscore(vtc_logit),
         hipp_logit_z = zscore(hipp_logit),
         CCN_sig_z = zscore(CCN_sig),
         DAN_sig_z = zscore(DAN_sig),
         CCN_lh_sig_z = zscore(CCN_lh_sig),
         DAN_lh_sig_z = zscore(DAN_lh_sig),
         hipp_sig_z = zscore(hipp_sig),
         hipp_tail_sig_z = zscore(hipp_tail_sig),
         reps = factor(reps),
         hipp_quintile = ntile(hipp_sig, 5),
         CCN_quintile = ntile(CCN_sig, 5),
         DAN_quintile = ntile(DAN_sig, 5),
         CCN_lh_quintile = ntile(CCN_lh_sig, 5),
         DAN_lh_quintile = ntile(DAN_lh_sig, 5),
         hipp_tail_quintile = ntile(hipp_tail_sig, 5),
         vtc_quintile = ntile(vtc_logit, 5),
         hipp_logit_quintile = ntile(hipp_logit, 5),
         ang_quintile = ntile(ang_logit, 5),
         rt_z = zscore(respRT)) %>%
  ungroup()

dCleanStandardized_HC_allfmri$rGenHipp<-scale(dCleanStandardized_HC_allfmri$hipp_sig_z)
dCleanStandardized_HC_allfmri$ERActUnsigned<-scale(dCleanStandardized_HC_allfmri$vtc_logit_z)
dCleanStandardized_HC_allfmri$ERActUnsigned_infpar<-scale(dCleanStandardized_HC_allfmri$ang_logit_z)
dCleanStandardized_HC_allfmri$RT_z<-scale(dCleanStandardized_HC_allfmri$rt_z)

contrasts(dCleanStandardized_HC_allfmri$group) 
contrasts(dCleanStandardized_HC_allfmri$reps)  = c(-1,1); contrasts(dCleanStandardized_HC_allfmri$reps)
contrasts(dCleanStandardized_HC_allfmri$shockCond) 
```
### Modulation of HC recollection decisions by RT

#### LH CCN
```{r}
mean(dCleanStandardized_HC_allfmri$RT_z)
sd(dCleanStandardized_HC_allfmri$RT_z)
mean(dCleanStandardized_HC_allfmri %>% filter(subid =='ap150') %>% pull(RT_z))
sd(dCleanStandardized_HC_allfmri %>% filter(subid =='ap150') %>% pull(RT_z))

with(dCleanStandardized_HC_allfmri, table(subid))
dCleanStandardized_HC_allfmri %>% group_by(subid, group) %>% summarise(n()) %>%
  group_by(group) %>% summarise(n())
  

# first lh only
fit  = lmer(scale(CCN_lh_sig_z) ~ group * (RT_z + reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri)
summary(fit)

#make sure holds when removing rep effect
# summary(lmer(scale(CCN_lh_sig_z) ~ group * (RT_z + reps)  + shockCond +
#               (-1 + RT_z|subid)+
#               (1 |subid),
#             data=dCleanStandardized_HC_allfmri))

# explore interaction of group * rt
summary(lmer(scale(CCN_lh_sig_z) ~ RT_z + reps  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri%>% filter(group == 'control')))

summary(lmer(scale(CCN_lh_sig_z) ~ RT_z + reps + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri %>% filter(group == 'stress'),
            control=lmerControl(optimizer="Nelder_Mead",
                         optCtrl=list(maxfun=2e5))))

# check to make sure simple effects are same
# contrasts(dCleanStandardized_HC_allfmri$group) = c(0,1)
# summary(lmer(scale(CCN_lh_sig_z) ~ group * (RT_z + reps)  + shockCond +
#               (-1 + reps|subid)+
#               (-1 + RT_z|subid)+
#               (1 |subid),
#             data=dCleanStandardized_HC_allfmri))

# contrasts(dCleanStandardized_HC_allfmri$group) = c(1,0)
# summary(lmer(scale(CCN_lh_sig_z) ~ group * (RT_z + reps)  + shockCond +
#               (-1 + reps|subid)+
#               (-1 + RT_z|subid)+
#               (1 |subid),
#             data=dCleanStandardized_HC_allfmri))
# contrasts(dCleanStandardized_HC_allfmri$group) = c(1,-1)

# interaction between shockcond and RT on CCN? in stress group
# remove subjs w/trial counts/bin < 6
dCleanStandardized_HC_allfmri %>% filter(group == 'stress') %>% 
  group_by(subid, shockCond) %>% 
  summarise(count=n()) %>% 
  ungroup() %>%
  mutate(subid = factor(subid)) %>%
  complete(subid, shockCond, fill = list(count= 0)) %>% filter(count < 6)

summary(lmer(scale(CCN_lh_sig_z) ~ (RT_z + reps) + shockCond +
               shockCond:RT_z +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
               (-1 + shockCond|subid)+
               (-1 + shockCond:RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri %>% 
              filter(group == 'stress', subid != 'ap173')))
dCleanStandardized_HC_allfmri %>% filter(group == 'stress',
                                 subid != 'ap173') %>%
  group_by(subid, group) %>% summarise(n()) %>%
  group_by(group) %>% summarise(n())


# is the RT * rep interaction significant?
dCleanStandardized_HC_allfmri %>% 
  group_by(subid, reps) %>% 
  summarise(count=n()) %>% 
  ungroup() %>%
  mutate(subid = factor(subid)) %>%
  complete(subid, reps, fill = list(count= 0)) %>% filter(count < 6)

summary(lmer(scale(CCN_lh_sig_z) ~ group * (RT_z * reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
               (-1 + RT_z:reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri %>%
              filter(!subid %in% c('ap110', 'ap158', 'ap173'))))

dCleanStandardized_HC_allfmri %>% filter(!subid %in% c('ap110', 'ap158', 'ap173')) %>%
  group_by(subid, group) %>% summarise(n()) %>%
  group_by(group) %>% summarise(n())
```
#### LH DAN
```{r}
### DAN
summary(lmer(scale(DAN_lh_sig_z) ~ group * (RT_z + reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri))

# explore interaction of group * rt
summary(lmer(scale(DAN_lh_sig_z) ~ RT_z + reps  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri%>% filter(group == 'control')))

summary(lmer(scale(DAN_lh_sig_z) ~ RT_z + reps + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri%>% filter(group == 'stress'),
            control=lmerControl(optimizer="Nelder_Mead",
                         optCtrl=list(maxfun=2e5))))

# double check simple effects
# contrasts(dCleanStandardized_HC_allfmri$group) = c(0,1)
# summary(lmer(scale(DAN_lh_sig_z) ~ group * (RT_z + reps)  + shockCond +
#               (-1 + reps|subid)+
#               (-1 + RT_z|subid)+
#               (1 |subid),
#             data=dCleanStandardized_HC_allfmri))
# contrasts(dCleanStandardized_HC_allfmri$group) = c(1,0)
# summary(lmer(scale(DAN_lh_sig_z) ~ group * (RT_z + reps)  + shockCond +
#               (-1 + reps|subid)+
#               (-1 + RT_z|subid)+
#               (1 |subid),
#             data=dCleanStandardized_HC_allfmri))
# contrasts(dCleanStandardized_HC_allfmri$group) = c(1,-1)


# interaction between shockcond and RT on DAN? in stress group
# remove subjs w/trial counts/bin < 6
dCleanStandardized_HC_allfmri %>% filter(group == 'stress') %>% 
  group_by(subid, shockCond) %>% 
  summarise(count=n()) %>% 
  ungroup() %>%
  mutate(subid = factor(subid)) %>%
  complete(subid, shockCond, fill = list(count= 0)) %>% filter(count < 6)

summary(lmer(scale(DAN_lh_sig_z) ~ (RT_z + reps) + shockCond +
               shockCond:RT_z +
              (-1 + RT_z|subid)+
               (-1 + shockCond|subid)+
               (-1 + RT_z:shockCond|subid)+
              (1 |subid), 
              control=lmerControl(optimizer="Nelder_Mead",
                         optCtrl=list(maxfun=2e5)),
            data=dCleanStandardized_HC_allfmri %>% filter(group == 'stress',
                                                  subid != 'ap173')))

dCleanStandardized_HC_allfmri %>% filter(group == 'stress',
                                 subid != 'ap173') %>%
  group_by(subid, group) %>% summarise(n()) %>%
  group_by(group) %>% summarise(n())


# is the RT * rep interaction significant?
dCleanStandardized_HC_allfmri %>% 
  group_by(subid, reps) %>% 
  summarise(count=n()) %>% 
  ungroup() %>%
  mutate(subid = factor(subid)) %>%
  complete(subid, reps, fill = list(count= 0)) %>% filter(count < 6)

summary(lmer(scale(DAN_lh_sig_z) ~ group * (RT_z * reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
               (-1 + RT_z:reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri %>%
              filter(!subid %in% c('ap110', 'ap158', 'ap173'))))
```

#### Plot combined lh networks
```{r}
## collapse
dm_avg = dm_allfmri %>% filter(pcorr == 1) %>%
  group_by(subid) %>%
  mutate(rt_quintile = ntile(respRT, 5)) %>%
  group_by(subid, group, rt_quintile) %>%
  summarise(ccn = mean_(CCN_lh_sig), 
            dan = mean_(DAN_lh_sig), 
            count = n()) %>% 
  gather(key = 'network', value = 'signal', ccn:dan) %>%
  mutate(network = replace(network, network=='ccn', 'CCN'),
         network = replace(network, network=='dan', 'DAN'))
  
dfwc = summarySEwithin(dm_avg, measurevar="signal", 
                       withinvars=c("rt_quintile", "network"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

ann_text <- data.frame(rt_quintile = c(3.2, 1.8), 
                       signal = c(0.08, .18),
                       group=c('control', 'stress'),
                       lab=c("control", "stress"),
                       network = factor(c('CCN', 'CCN'), 
                                      levels = c("CCN", "DAN")))

p2 = ggplot(dfwc, aes(x=rt_quintile, y=signal, group=group, color=group)) +
  facet_grid(.~network)+
    geom_line(position=pos_dodge, size=1) +
    geom_errorbar(width=0, aes(ymin=signal-se, 
                               ymax=signal+se), size=1, position=pos_dodge) +
    geom_point(size=3, position=pos_dodge) + 
  ylab('Percent signal change')+
  xlab('RT (quintiles)')+
  ylim(-.015, .25)+
  scale_color_manual(values=palette, guide = guide_legend(title = NULL)) +
  theme_classic(base_size=14) +
  geom_text(data = ann_text, aes(label=lab)) +
  theme(legend.title=element_blank(), 
        legend.position="none",
        strip.text = element_text(size=14),
        strip.background = element_rect(colour="white", fill="white"))
p2

ggsave(p2,
       filename ='~/Experiments/AP/figs/respRTXfrontoparietalLH_quintile_HCrecollection_allfmri.jpg',
       dpi=600, width = 4.7, height=2.5)
```

#### Plot combined lh networks, full names
```{r}
## collapse
dm_avg = dm_allfmri %>% filter(pcorr == 1) %>%
  group_by(subid) %>%
  mutate(rt_quintile = ntile(respRT, 5)) %>%
  group_by(subid, group, rt_quintile) %>%
  summarise(ccn = mean_(CCN_lh_sig), 
            dan = mean_(DAN_lh_sig), 
            count = n()) %>% 
  gather(key = 'network', value = 'signal', ccn:dan) %>%
  mutate(network = replace(network, network=='ccn', 'Cognitive control'),
         network = replace(network, network=='dan', 'Dorsal attention'))
  
dfwc = summarySEwithin(dm_avg, measurevar="signal", 
                       withinvars=c("rt_quintile", "network"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

p2 = ggplot(dfwc, aes(x=rt_quintile, y=signal, group=group, color=group)) +
  facet_grid(.~network)+
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=signal-se, 
                               ymax=signal+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('Percent signal change')+
  xlab('RT (quintiles)')+
  ylim(-.015, .25)+
  scale_color_manual(values=palette, guide = guide_legend(title = NULL))
p2

ggsave(p2,
       filename ='~/Experiments/AP/figs/respRTXfrontoparietalLH_quintile_HCrecollection_allfmri_fullnames.jpg',
       dpi=300, width = 8, height=4)
p2
```

#### Bilateral networks

##### CCN
```{r}
summary(lmer(scale(CCN_sig_z) ~ group * (RT_z + reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri))

summary(lmer(scale(CCN_sig_z) ~ RT_z + reps  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri%>% filter(group == 'control')))

summary(lmer(scale(CCN_sig_z) ~ RT_z + reps + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri %>% filter(group == 'stress'),
            control=lmerControl(optimizer="Nelder_Mead",
                         optCtrl=list(maxfun=2e5))))

# interaction between shockcond and RT on CCN? in stress group
# remove subjs w/trial counts/bin < 6
dCleanStandardized_HC_allfmri %>% filter(group == 'stress') %>% 
  group_by(subid, shockCond) %>% 
  summarise(count=n()) %>% 
  ungroup() %>%
  mutate(subid = factor(subid)) %>%
  complete(subid, shockCond, fill = list(count= 0)) %>% filter(count < 6)
dCleanStandardized_HC_allfmri %>% filter(group == 'stress') %>% 
  group_by(subid, shockCond) %>% 
  summarise(count=n()) %>% 
  ungroup() %>%
  mutate(subid = factor(subid)) %>%
  complete(subid, shockCond, fill = list(count= 0))

summary(lmer(scale(CCN_sig_z) ~ (RT_z + reps) + shockCond +
               shockCond:RT_z +
              (-1 + RT_z|subid)+ # remove reps random slope to converge
               (-1 + shockCond|subid)+
               (-1 + shockCond:RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri %>% filter(group == 'stress',
                                                  subid != 'ap173'),
            control=lmerControl(optimizer="Nelder_Mead",
                         optCtrl=list(maxfun=2e5))))

dCleanStandardized_HC_allfmri %>% filter(group == 'stress',
                                 subid != 'ap173') %>%
  group_by(subid, group) %>% summarise(n()) %>%
  group_by(group) %>% summarise(n())

# is the RT * rep interaction significant?
dCleanStandardized_HC_allfmri %>% 
  group_by(subid, reps) %>% 
  summarise(count=n()) %>% 
  ungroup() %>%
  mutate(subid = factor(subid)) %>%
  complete(subid, reps, fill = list(count= 0)) %>% filter(count < 6)

summary(lmer(scale(CCN_sig_z) ~ group * (RT_z * reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (-1 + RT_z:reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri %>%
              filter(!subid %in% c('ap110', 'ap158', 'ap173'))))

dCleanStandardized_HC_allfmri %>% filter(!subid %in% c('ap110', 'ap158', 'ap173')) %>%
  group_by(subid, group) %>% summarise(n()) %>%
  group_by(group) %>% summarise(n())
```


##### DAN
```{r}
summary(lmer(scale(DAN_sig_z) ~ group * (RT_z + reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri))

# make sure it holds w/correlated int/slope -- reps RE changes...
fit2 = lmer(scale(DAN_sig_z) ~ group * (RT_z + reps)  + shockCond +
              (1+ reps + RT_z|subid), 
            data=dCleanStandardized_HC_allfmri)
coef(fit2)
summary(fit2)

summary(lmer(scale(DAN_sig_z) ~ RT_z + reps  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri%>% filter(group == 'control')))

summary(lmer(scale(DAN_sig_z) ~ RT_z + reps + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri %>% filter(group == 'stress'),
            control=lmerControl(optimizer="Nelder_Mead",
                         optCtrl=list(maxfun=2e5))))

# interaction between shockcond and RT on DAN? in stress group
# remove subjs w/trial counts/bin < 6
dCleanStandardized_HC_allfmri %>% filter(group == 'stress') %>% 
  group_by(subid, shockCond) %>% 
  summarise(count=n()) %>% 
  ungroup() %>%
  mutate(subid = factor(subid)) %>%
  complete(subid, shockCond, fill = list(count= 0)) %>% filter(count < 6)


summary(lmer(scale(DAN_sig_z) ~ (RT_z + reps) + shockCond +
               shockCond:RT_z +
              (-1 + reps|subid)+ 
              (-1 + RT_z|subid)+ 
               (-1 + shockCond|subid)+
               (-1 + shockCond:RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri %>% filter(group == 'stress',
                                                  subid != 'ap173'),
            control=lmerControl(optimizer="Nelder_Mead",
                         optCtrl=list(maxfun=2e5))))

dCleanStandardized_HC_allfmri %>% filter(group == 'stress',
                                 subid != 'ap173') %>%
  group_by(subid, group) %>% summarise(n()) %>%
  group_by(group) %>% summarise(n())

# is the RT * rep interaction significant?
dCleanStandardized_HC_allfmri %>% 
  group_by(subid, reps) %>% 
  summarise(count=n()) %>% 
  ungroup() %>%
  mutate(subid = factor(subid)) %>%
  complete(subid, reps, fill = list(count= 0)) %>% filter(count < 6)

summary(lmer(scale(DAN_sig_z) ~ group * (RT_z * reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (-1 + RT_z:reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri %>%
              filter(!subid %in% c('ap110', 'ap158', 'ap173'))))

fit = lmer(scale(DAN_sig_z) ~ group * (RT_z * reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (-1 + RT_z:reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC_allfmri %>%
              filter(!subid %in% c('ap110', 'ap158', 'ap173')))
coef(fit)
summary(fit)

dCleanStandardized_HC_allfmri %>% filter(!subid %in% c('ap110', 'ap158', 'ap173')) %>%
  group_by(subid, group) %>% summarise(n()) %>%
  group_by(group) %>% summarise(n())
```



## 2b (ii): Excluding 2 subjs w/poor vtc localizer (trial-wise criteria from above)
### Modulation by encoding strength (related to RT)
```{r}
# check out hipp first, out of curiosity
summary(lmer(scale(hipp_sig_z) ~ group * (reps) + shockCond +
              (1 |subid), 
            data=dCleanStandardized_HC,
            control=lmerControl(optimizer="bobyqa",
                                optCtrl=list(maxfun=2e5)))) # remove RE to converge

# first, lh only
summary(lmer(scale(CCN_lh_sig_z) ~ group * (reps)  + shockCond +
              (-1 + reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC))

summary(lmer(scale(DAN_lh_sig_z) ~ group * (reps)  + shockCond +
              (-1 + reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC))

# bilateral
summary(lmer(scale(CCN_sig_z) ~ group * (reps)  + shockCond +
              (-1 + reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC))

summary(lmer(scale(DAN_sig_z) ~ group * (reps)  + shockCond +
              (-1 + reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC))
```

### Is VTC reinstatement modulated?
```{r}
summary(lmer(ERActUnsigned ~ group * (RT_z * reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC))
```

### Modulation of HC recollection decisions by RT

#### LH CCN
```{r}
mean(dCleanStandardized_HC$RT_z)
sd(dCleanStandardized_HC$RT_z)
mean(dCleanStandardized_HC %>% filter(subid =='ap150') %>% pull(RT_z))
sd(dCleanStandardized_HC %>% filter(subid =='ap150') %>% pull(RT_z))

dCleanStandardized_HC %>% group_by(subid, group) %>% summarise(n()) %>%
  group_by(group) %>% summarise(n())
  

# first lh only
fit  = lmer(scale(CCN_lh_sig_z) ~ group * (RT_z + reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC)
summary(fit)

# make sure holds when removing rep effect
# summary(lmer(scale(CCN_lh_sig_z) ~ group * (RT_z + reps)  + shockCond +
#               (-1 + RT_z|subid)+
#               (1 |subid), 
#             data=dCleanStandardized_HC))

# explore interaction of group * rt
summary(lmer(scale(CCN_lh_sig_z) ~ RT_z + reps  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC%>% filter(group == 'control')))

summary(lmer(scale(CCN_lh_sig_z) ~ RT_z + reps + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC%>% filter(group == 'stress'),
            control=lmerControl(optimizer="Nelder_Mead",
                         optCtrl=list(maxfun=2e5))))

# check to make sure simple effects are same
# contrasts(dCleanStandardized_HC$group) = c(0,1)
# summary(lmer(scale(CCN_lh_sig_z) ~ group * (RT_z + reps)  + shockCond +
#               (-1 + reps|subid)+
#               (-1 + RT_z|subid)+
#               (1 |subid), 
#             data=dCleanStandardized_HC))
# 
# contrasts(dCleanStandardized_HC$group) = c(1,0)
# summary(lmer(scale(CCN_lh_sig_z) ~ group * (RT_z + reps)  + shockCond +
#               (-1 + reps|subid)+
#               (-1 + RT_z|subid)+
#               (1 |subid), 
#             data=dCleanStandardized_HC))
# contrasts(dCleanStandardized_HC$group) = c(1,-1)

# interaction between shockcond and RT on CCN? in stress group
# remove subjs w/trial counts/bin < 6
dCleanStandardized_HC %>% filter(group == 'stress') %>% 
  group_by(subid, shockCond) %>% 
  summarise(count=n()) %>% 
  ungroup() %>%
  mutate(subid = factor(subid)) %>%
  complete(subid, shockCond, fill = list(count= 0)) %>% filter(count < 6)

summary(lmer(scale(CCN_lh_sig_z) ~ (RT_z + reps) + shockCond +
               shockCond:RT_z +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
               (-1 + shockCond|subid)+
               (-1 + shockCond:RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC %>% filter(group == 'stress',
                                                  subid != 'ap173')))
dCleanStandardized_HC %>% filter(group == 'stress',
                                 subid != 'ap173') %>%
  group_by(subid, group) %>% summarise(n()) %>%
  group_by(group) %>% summarise(n())


# is the RT * rep interaction significant?
dCleanStandardized_HC %>% 
  group_by(subid, reps) %>% 
  summarise(count=n()) %>% 
  ungroup() %>%
  mutate(subid = factor(subid)) %>%
  complete(subid, reps, fill = list(count= 0)) %>% filter(count < 6)

summary(lmer(scale(CCN_lh_sig_z) ~ group * (RT_z * reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
               (-1 + RT_z:reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC %>%
              filter(!subid %in% c('ap110', 'ap158', 'ap173'))))

dCleanStandardized_HC %>% filter(!subid %in% c('ap110', 'ap158', 'ap173')) %>%
  group_by(subid, group) %>% summarise(n()) %>%
  group_by(group) %>% summarise(n())
```

##### Slopes for each subj
```{r}
datalist = list()
i = 1
for (subject in unique(dCleanStandardized_HC$subid)){
  print(subject)
  fit  = lm(CCN_lh_sig_z ~ RT_z + reps + shockCond,
            data=dCleanStandardized_HC %>% filter(subid == subject))
  print(fit$coefficients['RT_z'])
  dat = data.frame(subid=subject,
                   coef = fit$coefficients['RT_z'])
  datalist[[i]] <- dat 
  i = 1+i
}

slopes_ccn_rt <- dplyr::bind_rows(datalist)
slopes_ccn_rt
```


#### LH DAN
```{r}
### DAN
summary(lmer(scale(DAN_lh_sig_z) ~ group * (RT_z + reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC))

# explore interaction of group * rt
summary(lmer(scale(DAN_lh_sig_z) ~ RT_z + reps  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC%>% filter(group == 'control')))

summary(lmer(scale(DAN_lh_sig_z) ~ RT_z + reps + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC%>% filter(group == 'stress'),
            control=lmerControl(optimizer="Nelder_Mead",
                         optCtrl=list(maxfun=2e5))))

# double check simple effects
# contrasts(dCleanStandardized_HC$group) = c(0,1)
# summary(lmer(scale(DAN_lh_sig_z) ~ group * (RT_z + reps)  + shockCond +
#               (-1 + reps|subid)+
#               (-1 + RT_z|subid)+
#               (1 |subid), 
#             data=dCleanStandardized_HC))
# contrasts(dCleanStandardized_HC$group) = c(1,0)
# summary(lmer(scale(DAN_lh_sig_z) ~ group * (RT_z + reps)  + shockCond +
#               (-1 + reps|subid)+
#               (-1 + RT_z|subid)+
#               (1 |subid), 
#             data=dCleanStandardized_HC))
# contrasts(dCleanStandardized_HC$group) = c(1,-1)


# interaction between shockcond and RT on DAN? in stress group
# remove subjs w/trial counts/bin < 6
dCleanStandardized_HC %>% filter(group == 'stress') %>% 
  group_by(subid, shockCond) %>% 
  summarise(count=n()) %>% 
  ungroup() %>%
  mutate(subid = factor(subid)) %>%
  complete(subid, shockCond, fill = list(count= 0)) %>% filter(count < 6)

# remove slopes to converge
summary(lmer(scale(DAN_lh_sig_z) ~ (RT_z + reps) + shockCond +
               shockCond:RT_z +
              (-1 + RT_z|subid)+
               (-1 + shockCond|subid)+
              (1 |subid), 
              control=lmerControl(optimizer="Nelder_Mead",
                         optCtrl=list(maxfun=2e5)),
            data=dCleanStandardized_HC %>% filter(group == 'stress',
                                                  subid != 'ap173')))

# is the RT * rep interaction significant?
dCleanStandardized_HC %>% 
  group_by(subid, reps) %>% 
  summarise(count=n()) %>% 
  ungroup() %>%
  mutate(subid = factor(subid)) %>%
  complete(subid, reps, fill = list(count= 0)) %>% filter(count < 6)

summary(lmer(scale(DAN_lh_sig_z) ~ group * (RT_z * reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
               (-1 + RT_z:reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC %>%
              filter(!subid %in% c('ap110', 'ap158', 'ap173'))))
```

#### Plot combined lh networks
```{r}
## collapse
dm_avg = dm %>% filter(pcorr == 1) %>%
  group_by(subid) %>%
  mutate(rt_quintile = ntile(respRT, 5)) %>%
  group_by(subid, group, rt_quintile) %>%
  summarise(ccn = mean_(CCN_lh_sig), 
            dan = mean_(DAN_lh_sig), 
            count = n()) %>% 
  gather(key = 'network', value = 'signal', ccn:dan) %>%
  mutate(network = replace(network, network=='ccn', 'CCN'),
         network = replace(network, network=='dan', 'DAN'))
  
dfwc = summarySEwithin(dm_avg, measurevar="signal", 
                       withinvars=c("rt_quintile", "network"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

p2 = ggplot(dfwc, aes(x=rt_quintile, y=signal, group=group, color=group)) +
  facet_grid(.~network)+
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=signal-se, 
                               ymax=signal+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('Percent signal change')+
  xlab('RT (quintiles)')+
  ylim(-.015, .235)+
  scale_color_manual(values=palette, guide = guide_legend(title = NULL))


ggsave(p2,
       filename ='~/Experiments/AP/figs/respRTXfrontoparietalLH_quintile_HCrecollection.jpg',
       dpi=150, width = 9, height=4)

ggsave(p2,
       filename ='~/Dropbox/Stanford/Papers/Dissertation/Figures_defense/AP_respRTXfrontoparietalLH_quintile_HCrecollection.jpg',
       dpi=300, width = 9, height=4)


p1 = ggplot(dfwc %>% filter(group == 'control'), aes(x=rt_quintile, y=signal, group=group, color=group)) +
  facet_grid(.~network)+
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=signal-se, 
                               ymax=signal+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('Percent signal change')+
  xlab('RT (quintiles)')+
  ylim(-.015, .235)+
  scale_color_manual(values=palette, guide = guide_legend(title = NULL))
p1
ggsave(p1,
       filename ='~/Dropbox/Stanford/Papers/Dissertation/Figures_defense/AP_respRTXfrontoparietalLH_quintile_HCrecollection_controlonly.jpg',
       dpi=300, width = 9, height=4)

p2
```

```{r}
## plot stress by shockCond
dm_avg = dm %>% filter(pcorr == 1,
                       group == 'stress',
                       subid != 'ap173') %>%
  group_by(subid) %>%
  mutate(rt_quintile = ntile(respRT, 5)) %>%
  group_by(subid, shockCond, rt_quintile) %>%
  summarise(ccn = mean_(CCN_lh_sig), 
            dan = mean_(DAN_lh_sig), 
            count = n()) %>% 
  gather(key = 'network', value = 'signal', ccn:dan) %>%
  mutate(network = replace(network, network=='ccn', 'CCN'),
         network = replace(network, network=='dan', 'DAN'))
dm_avg
  
dfwc = summarySEwithin(dm_avg, measurevar="signal", 
                       withinvars=c("rt_quintile", "network", "shockCond"),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

p2 = ggplot(dfwc, aes(x=rt_quintile, y=signal, group=shockCond, color=shockCond)) +
  facet_grid(.~network)+
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=signal-se, 
                               ymax=signal+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('Percent signal change')+
  xlab('RT (quintiles)')+
  scale_color_manual(values=c('mediumpurple', 'darkorange'), 
                     guide = guide_legend(title = NULL)) 
p2

ggsave(p2,
       filename ='~/Experiments/AP/figs/stress_respRTXfrontoparietalLH_quintile_HCrecollection.jpg',
       dpi=150, width = 9, height=4)
p2
```


#### Look at lh CCN raw timecourse

Compare with misses first, just to make sure we're getting good signal for HC assoc hits
```{r}
ccn_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-frontoparietal.csv')

# first, compare with misses to make sure we're getting good signal for CCN:
# merge w/data (filter artifacts + get extra trial info)
ccn_lh = ccn_lh %>% filter(condition %in% c('sourcehit', 'M')) %>% 
  # inner join w/d, where have a new col indicating median of RT for that condition
  inner_join(d %>% group_by(subid, cond) %>% mutate(rt_bin = ntile(respRT, 3)) %>% ungroup(), 
             by=c('subid', 'run', 'onset')) %>%
  mutate(subid = factor(subid),
         cond = factor(cond))

with(ccn_lh, table(cond, condition.x))

ggplot(ccn_lh %>% group_by(subid, cond, time) %>% 
         summarise(ccn_sig = mean(mean_activity)) %>% 
         group_by(time, cond) %>% 
         summarise(mean(ccn_sig)), 
       aes(x=time, y=`mean(ccn_sig)`, color=cond, group=cond)) +
  geom_line()
```

##### Break down by RT
```{r}
ccn_lh = ccn_lh %>% filter(cond == 'sourcehit')

# double check that split of RT is good
ccn_lh %>% filter(time == 0) %>% group_by(subid, group, rt_bin) %>% 
  summarise(mean(respRT), max(respRT), min(respRT))

ccn_avg = ccn_lh %>% 
  group_by(subid, group, rt_bin, time) %>% 
  summarise(ccn_sig = mean(mean_activity)) %>%
  group_by(group, rt_bin, time) %>%
  summarise(mean = mean(ccn_sig), se = std.error(ccn_sig), n())
ccn_avg  

blues <- brewer.pal(4, "Blues")[2:4]
p2 = ggplot(ccn_avg, aes(x=factor(time), y=mean, group=factor(rt_bin), color=factor(rt_bin))) +
    facet_grid(.~group) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=mean-se, 
                               ymax=mean+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('CCN activity (% change)')+
  xlab('Time post-stimulus onset (s)') +
  guides(color=guide_legend(title="RT (tertile)")) +
  scale_color_manual(values=blues)
p2

ggsave(p2,
       filename ='~/Experiments/AP/figs/CCNlh_bytimeXrttertile_HCrecollection.jpg',
       dpi=150, width = 9, height=4)
p2
```

#### For comparison, take a look at posterior hippocampal ROI

Does this peak earlier, and CCN kicks in post-retrieval for evaluation? Or, is it extended (retrieving more memories)?

Compare with misses first, just to make sure we're getting good signal for HC assoc hits
```{r}
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-hippocampus-tail.csv')
roi_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-hippocampus-tail.csv')

# Collapse across hemispheres
ccn_lh = bind_rows("lh" = roi_lh, "rh" = roi_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcehit', 'M')) %>%
  group_by(subid, hemi, run, onset, time) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset, time) %>%
  summarise(mean_activity = mean_(mean_activity)) %>% ungroup()

ccn_lh
# first, compare with misses to make sure we're getting good signal
# merge w/data (filter artifacts + get extra trial info)
ccn_lh = ccn_lh %>% 
  # inner join w/d, where have a new col indicating median of RT for that condition
  inner_join(d %>% group_by(subid, cond) %>% mutate(rt_bin = ntile(respRT, 3)) %>% ungroup(), 
             by=c('subid', 'run', 'onset')) %>%
  mutate(subid = factor(subid),
         cond = factor(cond))

ggplot(ccn_lh %>% group_by(group, subid, cond, time) %>% 
         summarise(ccn_sig = mean(mean_activity)) %>% 
         group_by(group, time, cond) %>% 
         summarise(mean(ccn_sig)), 
       aes(x=time, y=`mean(ccn_sig)`, color=cond, group=cond)) +
  facet_grid(.~group)+
  geom_line()
```

```{r}
fit  = lmer(scale(hipp_tail_sig_z) ~ group * (RT_z + reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC)
summary(fit)

## collapse
dm_avg = dm %>% filter(pcorr == 1) %>%
  group_by(subid) %>%
  mutate(rt_quintile = ntile(respRT, 5)) %>%
  group_by(subid, group, rt_quintile) %>%
  summarise(ccn = mean_(hipp_tail_sig),
            count = n())

dfwc = summarySEwithin(dm_avg, measurevar="ccn", 
                       withinvars=c("rt_quintile"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

p2 = ggplot(dfwc, aes(x=rt_quintile, y=ccn, group=group, color=group)) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=ccn-se, 
                               ymax=ccn+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('Percent signal change')+
  xlab('RT (quintiles)')+
  scale_color_manual(values=palette, guide = guide_legend(title = NULL))
p2

ggsave(p2,
       filename ='~/Dropbox/Stanford/Papers/Dissertation/Figures_defense/AP_respRTXhippTail_quintile_HCrecollection.jpg',
       dpi=300, width = 6, height=4)
```


##### Break down by RT
```{r}
# subtract out baseline for each trial, as this is a little variable across people (potentially due to # of SHs across groups?)
ccn_avg = ccn_lh %>% mutate(time = paste0('T',time)) %>%
  spread(key = time, value=mean_activity) %>%
  mutate(T2 = T2-T0, 
         T4 = T4 - T0,
         T6 = T6 - T0,
         T8 = T8 - T0,
         T10 = T10 - T0,
         T12 = T12 - T0) %>%
  mutate(T0 = 0) %>%
  gather(time, mean_activity, T0:T8) %>%
  mutate(time = as.numeric(substr(time, 2,3))) %>%
  dplyr::select(subid, group, onset, cond, time, mean_activity, everything()) %>%
  mutate(rt_bin=replace(rt_bin, cond=='M', 1)) %>% 
  group_by(subid, group, cond, time, rt_bin) %>% 
  summarise(ccn_sig = mean(mean_activity)) %>%
  group_by(group, time, cond, rt_bin) %>%
  summarise(mean = mean(ccn_sig), se = std.error(ccn_sig), n()) %>%
  mutate(cond_rt = paste0(cond, '-', rt_bin),
         cond_rt = replace(cond_rt, cond_rt == 'M-1', 'M'))
ccn_avg

blues <- brewer.pal(4, "Blues")[2:4]
reds = brewer.pal(4, "Reds")[3]
colorpal = c(reds, blues)
p2 = ggplot(ccn_avg, aes(x=factor(time), y=mean, color=cond_rt, group=cond_rt)) + #group=factor(rt_bin),   color=factor(rt_bin))) +
    facet_grid(.~group) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=mean-se, 
                               ymax=mean+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('Hipp tail activity\n(% change rel onset)')+
  xlab('Time post-stimulus onset (s)') +
  guides(color=guide_legend(title="RT (tertile)")) +
  scale_color_manual(values=colorpal)
p2

ggsave(p2,
       filename ='~/Experiments/AP/figs/hippTail_bytimeXrttertile_HCrecollection_substractBL.jpg',
       dpi=150, width = 9, height=4)
p2
```

#### Bilateral networks
```{r}
# bilateral now
summary(lmer(scale(CCN_sig_z) ~ group * (RT_z + reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC))

# interaction
summary(lmer(scale(CCN_sig_z) ~ (RT_z + reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC %>% filter(group == 'control')))

summary(lmer(scale(CCN_sig_z) ~ (RT_z + reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC %>% filter(group == 'stress')))

# Now, double check out simple effects 
# contrasts(dCleanStandardized_HC$group) = c(0,1)
# summary(lmer(scale(CCN_sig_z) ~ group * (RT_z + reps)  + shockCond +
#               (-1 + reps|subid)+
#               (-1 + RT_z|subid)+
#               (1 |subid), 
#             data=dCleanStandardized_HC))
# 
# contrasts(dCleanStandardized_HC$group) = c(1,0)
# summary(lmer(scale(CCN_sig_z) ~ group * (RT_z + reps)  + shockCond +
#               (-1 + reps|subid)+
#               (-1 + RT_z|subid)+
#               (1 |subid), 
#             data=dCleanStandardized_HC))
# contrasts(dCleanStandardized_HC$group) = c(1,-1)


# is the RT * rep interaction significant?
summary(lmer(scale(CCN_sig_z) ~ group * (RT_z * reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (-1 + RT_z:reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC))

## DAN
summary(lmer(scale(DAN_sig_z) ~ group * (RT_z + reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC))

# is the RT * rep interaction significant?
summary(lmer(scale(DAN_sig_z) ~ group * (RT_z * reps)  + shockCond +
              (-1 + reps|subid)+
              (-1 + RT_z|subid)+
               (-1 + RT_z:reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC))
```

##### Plot bilateral
```{r}
## bilateral
dm_avg = dm %>% filter(pcorr == 1) %>%
  group_by(subid) %>%
  mutate(ccn_quintile = ntile(respRT, 5)) %>%
  group_by(subid, group, ccn_quintile, reps) %>%
  summarise(vtc_logit = mean_(CCN_sig), count = n()) %>%
  group_by(subid, group, ccn_quintile, reps) %>%
  summarise(vtc_logit = mean_(vtc_logit), count = n())%>%
  ungroup() %>%
  mutate(reps = revalue(reps, replace = c('2' = 'weak',
                                          '4' = 'strong')))

dfwc = summarySEwithin(dm_avg, measurevar="vtc_logit", 
                       withinvars=c("ccn_quintile", "reps"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

p2 = ggplot(dfwc, aes(x=ccn_quintile, y=vtc_logit, group=group, color=group)) +
    facet_grid(.~reps) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=vtc_logit-se, 
                               ymax=vtc_logit+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('CCN activity (% change)')+
  xlab('RT (quintiles)')+
  scale_color_manual(values=palette, guide = guide_legend(title = NULL))
p2

ggsave(p2,
       filename ='~/Experiments/AP/figs/respRTXccn_quintileXrep_HCrecollection.jpg',
       dpi=150, width = 9, height=4)
p2

## collapse
dm_avg = dm %>% filter(pcorr == 1) %>%
  group_by(subid) %>%
  mutate(ccn_quintile = ntile(respRT, 5)) %>%
  group_by(subid, group, ccn_quintile, reps) %>%
  summarise(vtc_logit = mean_(CCN_sig), count = n()) %>%
  group_by(subid, group, ccn_quintile) %>%
  summarise(vtc_logit = mean_(vtc_logit), count = n())

dfwc = summarySEwithin(dm_avg, measurevar="vtc_logit", 
                       withinvars=c("ccn_quintile"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

p2 = ggplot(dfwc, aes(x=ccn_quintile, y=vtc_logit, group=group, color=group)) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=vtc_logit-se, 
                               ymax=vtc_logit+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('CCN activity (% change)')+
  xlab('RT (quintiles)')+
  scale_color_manual(values=palette, guide = guide_legend(title = NULL))
p2

ggsave(p2,
       filename ='~/Experiments/AP/figs/respRTXccn_quintile_HCrecollection.jpg',
       dpi=150, width = 6, height=4)
p2
```

## 2b (iii): Explore: Is hipp/vtc greater for faster high confidence memories? Or for longer RT (potentially retrieval of more things to guide associate recall) memories?

### Hipp ~ RT:
```{r}
# look at trial counts/subj
with(dCleanStandardized_HC, table(subid))
data.frame(with(dCleanStandardized_HC, table(subid))) %>% summarise(mean(Freq), sd(Freq))
head(dCleanStandardized_HC)

deq.3b<-lmer(rGenHipp ~ group*(RT_z) + reps + shockCond +
              (-1 + RT_z|subid)+
              (-1 + reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC)
# uncorrelate random slopes and intercepts
summary(deq.3b)

# no interaction by rep * group?
summary(lmer(rGenHipp ~ group*(RT_z) * reps + shockCond +
              (-1 + RT_z|subid)+
              (-1 + reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC))
```
Relatively higher hippocampal signal within HC recollection decisions does not track with faster/slower RTs. However, stronger encoding strength does predict faster RTs.


#### Plot
```{r}
# look at mean trial count per bin
trial_counts = data.frame(with(dCleanStandardized_HC, 
                               table(subid, reps, hipp_quintile)))
trial_counts %>% group_by(reps, hipp_quintile) %>% summarise(mean(Freq), n())

## collapse
dm_avg = dm %>% filter(pcorr == 1) %>%
  group_by(subid) %>%
  mutate(hipp_quintile = ntile(hipp_sig, 5)) %>%
  group_by(subid, group, hipp_quintile, reps) %>%
  summarise(vtc_logit = mean_(respRT), count = n()) %>%
  group_by(subid, group, hipp_quintile, reps) %>%
  summarise(vtc_logit = mean_(vtc_logit), count = n())%>%
  ungroup() %>%
  mutate(reps = revalue(reps, replace = c('2' = 'weak',
                                          '4' = 'strong')))

dfwc = summarySEwithin(dm_avg, measurevar="vtc_logit", 
                       withinvars=c("hipp_quintile", "reps"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

p2 = ggplot(dfwc, aes(x=hipp_quintile, y=vtc_logit, group=group, color=group)) +
    facet_grid(.~reps) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=vtc_logit-se, 
                               ymax=vtc_logit+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('RT (s)')+
  xlab('Hippocampal activity (quintiles)')+
  scale_color_manual(values=palette, guide = guide_legend(title = NULL))
p2

ggsave(p2,
       filename ='~/Experiments/AP/figs/respRTXhipp_quintileXrep_HCrecollection_wholehipp.jpg',
       dpi=150, width = 9, height=4)
p2
```

### VTC ~ RT
```{r}
# look at trial counts/subj
with(dCleanStandardized_HC, table(subid))

deq.3b<-lmer(ERActUnsigned ~ group*(RT_z) + reps + shockCond +
              (-1 + RT_z|subid)+
              (-1 + reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC)
# uncorrelate random slopes and intercepts
summary(deq.3b)

summary(lmer(RT_z ~ (ERActUnsigned) + reps + shockCond +
              (-1 + ERActUnsigned|subid)+
              (-1 + reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC %>% filter(group == 'control')))

summary(lmer(RT_z ~ (ERActUnsigned) + reps + shockCond +
              (-1 + ERActUnsigned|subid)+
              (-1 + reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC %>% filter(group == 'stress')))

# interaction by rep * group?
fit1 = lmer(RT_z ~ group*(ERActUnsigned) * reps + shockCond +
              (-1 + ERActUnsigned|subid)+
              (-1 + reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_HC)
anova(deq.3b, fit1) 
summary(fit1)
```


#### Plot
```{r}
# look at mean trial count per bin
trial_counts = data.frame(with(dCleanStandardized_HC, 
                               table(subid, reps, vtc_quintile)))
trial_counts %>% group_by(reps, vtc_quintile) %>% summarise(mean(Freq), n())

## collapse
dm_avg = dm %>% filter(pcorr == 1) %>%
  group_by(subid) %>%
  mutate(hipp_quintile = ntile(vtc_logit, 5)) %>%
  group_by(subid, group, hipp_quintile, reps) %>%
  summarise(vtc_logit = mean_(respRT), count = n()) %>%
  group_by(subid, group, hipp_quintile, reps) %>%
  summarise(vtc_logit = mean_(vtc_logit), count = n())%>%
  ungroup() %>%
  mutate(reps = revalue(reps, replace = c('2' = 'weak',
                                          '4' = 'strong')))

dfwc = summarySEwithin(dm_avg, measurevar="vtc_logit", 
                       withinvars=c("hipp_quintile", "reps"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

p2 = ggplot(dfwc, aes(x=hipp_quintile, y=vtc_logit, group=group, color=group)) +
    facet_grid(.~reps) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=vtc_logit-se, 
                               ymax=vtc_logit+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('RT (s)')+
  xlab('Reinstatement strength (logits)')+
  scale_color_manual(values=palette, guide = guide_legend(title = NULL))
p2

ggsave(p2,
       filename ='~/Experiments/AP/figs/respRTXvtc_quintileXrep_HCrecollection.jpg',
       dpi=150, width = 9, height=4)
p2
```


## 2b (iv):  What about across *all* accurate (high AND low confidence) associative judgments (i.e., like Alan's study)

```{r}
# standardize continuous vars
dCleanStandardized_H = dm %>% filter(acc == 'H')
dCleanStandardized_H = dCleanStandardized_H %>% 
  group_by(subid) %>%
  mutate(ang_logit_z = zscore(ang_logit),
         vtc_logit_z = zscore(vtc_logit),
         hipp_logit_z = zscore(hipp_logit),
         CCN_sig_z = zscore(CCN_sig),
         DAN_sig_z = zscore(DAN_sig),
         hipp_sig_z = zscore(hipp_sig),
         hipp_tail_sig_z = zscore(hipp_tail_sig),
         hipp_quintile = ntile(hipp_sig, 5),
         CCN_quintile = ntile(CCN_sig, 5),
         DAN_quintile = ntile(DAN_sig, 5),
         hipp_tail_quintile = ntile(hipp_tail_sig, 5),
         vtc_quintile = ntile(vtc_logit, 5),
         hipp_logit_quintile = ntile(hipp_logit, 5),
         ang_quintile = ntile(ang_logit, 5),
         rt_z = zscore(respRT))

dCleanStandardized_H$rGenHipp<-scale(dCleanStandardized_H$hipp_sig_z)
dCleanStandardized_H$ERActUnsigned<-scale(dCleanStandardized_H$vtc_logit_z)
dCleanStandardized_H$ERActUnsigned_infpar<-scale(dCleanStandardized_H$ang_logit_z)
dCleanStandardized_H$RT_z<-scale(dCleanStandardized_H$rt_z)

# look at trial counts/subj
with(dCleanStandardized_H, table(subid))

deq.4b<-lmer(RT_z ~ group*(rGenHipp) + reps + shockCond +
              (-1 + rGenHipp|subid)+
              (-1 + reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_H)
# uncorrelate random slopes and intercepts
summary(deq.4b)

# interaction by rep * group?
summary(lmer(RT_z ~ group*(rGenHipp) * reps + shockCond +
              (-1 + rGenHipp|subid)+
              (-1 + reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_H))

# interaction:
summary(lmer(RT_z ~ (rGenHipp) + reps + shockCond +
              (-1 + rGenHipp|subid)+
              (-1 + reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_H %>% filter(group == 'control')))

summary(lmer(RT_z ~ (rGenHipp) + reps + shockCond +
              (-1 + rGenHipp|subid)+
              (-1 + reps|subid)+
              (1 |subid), 
            data=dCleanStandardized_H %>% filter(group == 'stress')))
```

### Plot
```{r}
# trial counts are pretty good:
dm %>% filter(acc == 'H') %>%
  group_by(subid) %>%
  summarise(n())

dm_avg = dm %>% filter(acc == 'H') %>%
  group_by(subid) %>%
  mutate(hipp_quintile = ntile(hipp_sig, 5)) %>%
  group_by(subid, group, hipp_quintile, reps) %>%
  summarise(vtc_logit = mean_(respRT), count = n()) %>%
  group_by(subid, group, hipp_quintile, reps) %>%
  summarise(vtc_logit = mean_(vtc_logit), count = n())%>%
  ungroup() %>%
  mutate(reps = revalue(reps, replace = c('2' = 'weak',
                                          '4' = 'strong')))

dfwc = summarySEwithin(dm_avg, measurevar="vtc_logit", 
                       withinvars=c("hipp_quintile", "reps"),
                       betweenvars = c('group'),
                       idvar="subid", na.rm=TRUE, conf.interval=.95)
dfwc

p2 = ggplot(dfwc, aes(x=hipp_quintile, y=vtc_logit, group=group, color=group)) +
    facet_grid(.~reps) +
    geom_line(position=pos_dodge, size=1.5) +
    geom_errorbar(width=0, aes(ymin=vtc_logit-se, 
                               ymax=vtc_logit+se), size=1.5, position=pos_dodge) +
    geom_point(size=5, position=pos_dodge) + 
  ylab('RT (s)')+
  xlab('Hippocampal activity (quintiles)')+
  scale_color_manual(values=palette, guide = guide_legend(title = NULL))
p2

ggsave(p2,
       filename ='~/Experiments/AP/figs/respRTXhipp_quintileXrep_Hhighlowconf_wholehipp.jpg',
       dpi=150, width = 9, height=4)
p2
```

# 3) Effects of group/encoding strength on VTC reinstatement

## Across old cues: pCorr ~ VTC reinstatement
Without controlling for hipp BOLD
```{r}
dCleanStandardized %>% group_by(group, subid) %>%
  summarise(n()) %>%
  group_by(group)%>% summarise(n())

summary(glmer(pcorr ~ group*(ERActUnsigned) + reps + shockCond +
               (-1 + ERActUnsigned|subid) + 
               (1|subid), 
             data=dCleanStandardized, family = "binomial"))
```

## HC assoc hits: VTC reinstatement ~ group
```{r}
subids_lowtrials = dm %>% 
  filter(cond == 'sourcehit') %>%
  group_by(group, subid) %>% 
  summarise(count = n()) %>% 
  ungroup() %>%
  complete(nesting(subid, group), fill = list(count= 0)) %>%
  filter(count < 6) %>% 
  pull(subid) %>% unique()
subids_lowtrials

d_avg = dm %>% filter(!subid %in% subids_lowtrials) %>%
  filter(cond == 'sourcehit') %>%
  group_by(group, subid) %>%
  summarise(mean=mean(vtc_logit))
with(d_avg, table(group))

# diff between groups?
bartlett.test(mean ~ group, data=d_avg)
t.test(mean ~ group, data=d_avg, var.equal=TRUE)
d_avg %>% group_by(group) %>% summarise(mean(mean), n())

t.test(d_avg %>% filter(group == 'control') %>% pull(mean), mu = 0)
t.test(d_avg %>% filter(group == 'stress') %>% pull(mean), mu = 0)
```

### Does this hold in VTC excluding parahipp?
```{r}
d_avg = dm %>% filter(!subid %in% subids_lowtrials) %>%
  filter(cond == 'sourcehit') %>%
  group_by(group, subid) %>%
  summarise(mean=mean(vtc_nophc_logit))
with(d_avg, table(group))

# diff between groups?
bartlett.test(mean ~ group, data=d_avg)
t.test(mean ~ group, data=d_avg, var.equal=TRUE)
d_avg %>% group_by(group) %>% summarise(mean(mean), n())

t.test(d_avg %>% filter(group == 'control') %>% pull(mean), mu = 0)
t.test(d_avg %>% filter(group == 'stress') %>% pull(mean), mu = 0)
```


### Distribution of HC assoc hit logits by subj
```{r}
trial_type = 'sourcehit'
subids_lowtrials = dm %>% 
  filter(cond == trial_type) %>%
  group_by(group, subid) %>% 
  summarise(count = n()) %>% 
  ungroup() %>%
  complete(nesting(subid, group), fill = list(count= 0)) %>%
  filter(count < 6) %>% 
  pull(subid) %>% unique()
subids_lowtrials

d_avg = dm %>% filter(!subid %in% subids_lowtrials) %>%
  filter(cond == trial_type) %>%
  mutate(subid = factor(subid))
with(d_avg, table(subid))
head(d_avg)

d_avg %>% group_by(subid, group, cond) %>% summarise(mean = mean(vtc_logit),
                                                     stdev = sd(vtc_logit)) %>%
  group_by(group, cond) %>% summarise(mean(mean), std.error(mean), n(),
                                      mean(stdev))
ggplot(d_avg, aes(x=vtc_logit, group=subid, color=subid)) + 
  geom_density() +
  facet_grid(group~.) +
  guides(colour=FALSE)

ggsave('/Volumes/group/awagner/sgagnon/AP/results/vtclogit_dist_sourcehit.png')
```

```{r}
trial_type = 'itemhit_lo'
subids_lowtrials = dm %>% 
  filter(cond == trial_type) %>%
  group_by(group, subid) %>% 
  summarise(count = n()) %>% 
  ungroup() %>%
  complete(nesting(subid, group), fill = list(count= 0)) %>%
  filter(count < 6) %>% 
  pull(subid) %>% unique()
subids_lowtrials

d_avg = dm %>% filter(!subid %in% subids_lowtrials) %>%
  filter(cond == trial_type) %>%
  mutate(subid = factor(subid))
with(d_avg, table(subid))
head(d_avg)

d_avg %>% group_by(subid, group, cond) %>% summarise(mean = mean(vtc_logit),
                                                     stdev = sd(vtc_logit)) %>%
  group_by(group, cond) %>% summarise(mean(mean), std.error(mean), n(),
                                      mean(stdev))

ggplot(d_avg, aes(x=vtc_logit, group=subid, color=subid)) + 
  geom_density() +
  facet_grid(group~.) +
  guides(colour=FALSE)

ggsave('/Volumes/group/awagner/sgagnon/AP/results/vtclogit_dist_itemhit.png')
```
```{r}
subids_lowtrials = dm %>% 
  filter(cond %in% c('sourcehit', 'itemhit_lo')) %>%
  mutate(cond = factor(cond)) %>%
  group_by(group, subid, cond) %>% 
  summarise(count = n()) %>% 
  ungroup() %>%
  complete(nesting(subid, group), cond, fill = list(count= 0)) %>%
  filter(count < 6) %>% 
  pull(subid) %>% unique()
subids_lowtrials

d_avg = dm %>% filter(!subid %in% subids_lowtrials) %>%
  filter(cond %in% c('sourcehit', 'itemhit_lo')) %>%
  mutate(subid = factor(subid),
         cond = factor(cond))
with(d_avg, table(subid, cond))
head(d_avg)

d_avg %>% group_by(subid, group, cond) %>% summarise(mean = mean(vtc_logit),
                                                     stdev = sd(vtc_logit)) %>%
  group_by(group, cond) %>% summarise(mean(mean), std.error(mean), n(),
                                      mean(stdev))

t.test(mean ~ cond, var.equal=TRUE, paired=TRUE, 
       d_avg %>% group_by(subid, group, cond) %>% summarise(mean = mean(vtc_logit),
                                                     stdev = sd(vtc_logit)))

contrasts(d_avg$cond) = c(1,-1); contrasts(d_avg$cond)
summary(lmer(mean ~ cond * group + (1|subid), 
             data=d_avg %>% group_by(subid, group, cond) %>% 
               summarise(mean = mean(vtc_logit),
                         stdev = sd(vtc_logit))))
```


### Does trial count influence reinstatement?
```{r}
d_avg = dm %>% 
  filter(cond == 'sourcehit') %>%
  filter(!subid %in% subids_lowtrials) %>%
  group_by(group, subid) %>%
  summarise(mean=mean(vtc_logit), n=n())

fit = lm(mean ~ n, data=d_avg)
summary(fit)
plot(fit)
with(d_avg, plot(n, mean))
boxplot(d_avg$mean)
hist(fit$residuals)

# robust regression: still n.s.
# summary(rr.huber <- rlm(mean ~ poly(n,2), data=d_avg))
#dd = data.frame(summary(rr.huber)$coefficients)
#dd$p.value =  2*pt(abs(dd$t.value), summary(rr.huber)$df[2], lower.tail=FALSE)
#dd
```

## HC assoc hits: VTC reinstatement ~ group * encoding strength
```{r}
subids_lowtrials = dm %>% 
  filter(cond == 'sourcehit') %>%
  group_by(group, subid, reps) %>% 
  summarise(count = n()) %>% 
  ungroup() %>%
  complete(nesting(subid, group), reps, fill = list(count= 0)) %>%
  filter(count < 6) %>% pull(subid) %>% unique()
subids_lowtrials

dm %>% filter(!subid %in% subids_lowtrials) %>%
  filter(cond == 'sourcehit') %>%
  group_by(group, subid, reps) %>%
  summarise(mean = mean(vtc_logit)) %>%
  group_by(group, reps) %>%
  summarise(mean(mean), n())

contrasts(dm$group)
contrasts(dm$reps)
dm %>% filter(!subid %in% subids_lowtrials) %>% 
  filter(cond == 'sourcehit') %>%
  group_by(group,subid) %>% summarise(n()) %>%
  group_by(group) %>% summarise(n())
# control=20, stress=19

dat = dm %>% filter(!subid %in% subids_lowtrials) %>%
             filter(cond == 'sourcehit')
dat

summary(lmer(vtc_logit ~ group * reps +
               (1 + reps|subid), 
             data=dat,
        control=lmerControl(optimizer="Nelder_Mead",
                         optCtrl=list(maxfun=2e5))))
```

## HC assoc hits: VTC reinstatement ~ group * run type (safe, threat)
```{r}
subids_lowtrials = dm %>% 
  filter(cond == 'sourcehit') %>%
  group_by(group, subid, shockCond) %>% 
  summarise(count = n()) %>% 
  ungroup() %>%
  complete(nesting(subid, group), shockCond, fill = list(count= 0)) %>%
  filter(count < 6) %>% pull(subid) %>% unique()
subids_lowtrials

dm %>% filter(!subid %in% subids_lowtrials) %>%
  filter(cond == 'sourcehit') %>%
  group_by(group, subid, shockCond) %>%
  summarise(mean = mean(vtc_logit)) %>%
  group_by(group, shockCond) %>%
  summarise(mean(mean), n())

contrasts(dm$group)
contrasts(dm$shockCond)
dm %>% filter(!subid %in% subids_lowtrials) %>% 
  filter(cond == 'sourcehit') %>%
  group_by(group,subid) %>% summarise(n()) %>%
  group_by(group) %>% summarise(n())
# control=21, stress=19

# just in stress group
summary(lmer(vtc_logit ~ shockCond + (1 + shockCond|subid), 
             data=dm %>% 
             filter(!subid %in% subids_lowtrials,
                    group == 'stress') %>%
             filter(cond == 'sourcehit')),
        control=lmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e5)))

# confirm holds with regular ttest -- report this, as straightforward here
dat = dm %>% 
             filter(!subid %in% subids_lowtrials,
                    group == 'stress') %>%
             filter(cond == 'sourcehit') %>%
group_by(group, subid, shockCond) %>%
  summarise(vtc_logit = mean(vtc_logit))
bartlett.test(vtc_logit ~ shockCond, data=dat)
t.test(vtc_logit ~ shockCond, data=dat, var.equal=TRUE, paired=TRUE)

# interaction by group
summary(lmer(vtc_logit ~ shockCond * group + (1 + shockCond|subid), 
             data=dm %>% 
             filter(!subid %in% subids_lowtrials) %>%
             filter(cond == 'sourcehit')),
        control=lmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e5))) 

```

## HC assoc hits: scene vs. face/object evidence:
```{r}
dcat = read.csv('/Users/sgagnon/Dropbox/Stanford/Presentations/AP/mvpa_logit_allcat_byreps_avg_46810_filtartloc_scalewithinrun.csv')
# dcat

dcat = dcat %>%
  filter(!subid %in% subids_rm,
         cond %in% c('sourcehit')) # rm subjs w/bad localizer

dim(dcat)
dcat = dt %>%
  mutate(onset=onset_adj, img_type=cond) %>% 
  dplyr::select(-group, -reps, -cond) %>%
  right_join(dcat, by=c('subid', 'run', 'onset')) %>% 
  filter(shock_and_post == 0)
dim(dcat)
# dcat 

str(dcat)
dcat = dcat %>% mutate(subid = factor(subid))

contrasts(dcat$group) = c(1,-1); contrasts(dcat$group)
contrasts(dcat$category) = cbind(sceneVobject=c(0, 1, 0),
                                 sceneVface = c(1, 0, 0)); contrasts(dcat$category)
fit = lmer(avg_logit ~ group * category + (1 + category|subid), data=dcat)
anova(fit, refit=FALSE)
summary(fit)
```


## HC assoc hits: PPA ~ group
```{r}
dat = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/pe_ppa_scene_graymid_limitvox.csv')
dat = dat %>% filter(cond %in% c('sourcehit', 'CR')) %>%
  mutate(cond = factor(cond))
dat

bartlett.test(value ~ group, data=dat %>% filter(cond == 'sourcehit'))
t.test(value ~ group, data=dat %>% filter(cond == 'sourcehit'), var.equal=TRUE)
t.test(value ~ group, data=dat %>% filter(cond == 'CR'), var.equal=TRUE)

# sig interaction? might be driven by decrease in CRs in ctrl, and directional increase in sh
contrasts(dat$group) = c(1,-1); contrasts(dat$group)
contrasts(dat$cond) = c(-1,1); contrasts(dat$cond)
summary(lmer(value ~ group * cond + (1|subid), data=dat)) # rand slope, not enough obs
```

## Visualize timecourse of reinstatement
### by group
```{r}
head(dm)

dm_time = dm %>%
  filter(cond %in% c('sourcehit')) %>%
  gather('time', 'logit_vtc', `X0`:`X12`) %>%
  mutate(time=gsub("X","",time)) %>%
  group_by(group, subid, cond, time) %>%
  summarise(mean_logit = mean_(logit_vtc)) %>%
  group_by(group, cond, time) %>%
  summarise(mean=mean_(mean_logit), sem=std.error(mean_logit), n=length(mean_logit)) %>%
  mutate(time = as.numeric(time))

p2 = ggplot(dm_time %>% filter(cond == 'sourcehit'),
            aes(x=factor(time), y=mean, group=group, color=group)) +
     geom_line(position=position_dodge(.2), size=1.5) +
    geom_point(position=position_dodge(.2), size=5) +
    geom_errorbar(width=0, aes(ymin=mean-sem, 
                               ymax=mean+sem), size=1.5,
                  position=position_dodge(.2)) +
    scale_color_manual(values = palette, 
                       guide = guide_legend(title = NULL)) +
  ylab('Reinstatement strength\n(logits)') +
  xlab('Time post-stimulus onset (s)') +
   theme(legend.title=element_blank(),
        legend.position = c(.9, .8))

ggsave('~/Experiments/AP/figs/AP_reinstatement_bygroup_SH_ts.jpeg',
       dpi=150, width=5.5, height=4)
p2


## no dodge
p2 = ggplot(dm_time %>% filter(cond == 'sourcehit'),
            aes(x=factor(time), y=mean, group=group, color=group)) +
     geom_line(size=1.5) +
    geom_point(size=5) +
    geom_errorbar(width=0, aes(ymin=mean-sem, 
                               ymax=mean+sem), size=1.5, alpha=.65) +
    scale_color_manual(values = palette, 
                       guide = guide_legend(title = NULL)) +
  ylab('Reinstatement strength') +
  xlab('Time post-stimulus onset (s)') +
   theme(legend.title=element_blank(),
        legend.position = c(.9, .8))
p2
ggsave('~/Experiments/AP/figs/AP_reinstatement_bygroup_SH_ts_nododge.jpeg',
       dpi=600, width=5, height=4)
p2
```

### HC recollection: by encoding strength * group
```{r}
subids_lowtrials = dm %>% 
  filter(cond == 'sourcehit') %>%
  group_by(group, subid, reps) %>% 
  summarise(count = n()) %>% 
  ungroup() %>%
  complete(nesting(subid, group), reps, fill = list(count= 0)) %>%
  filter(count < 6) %>% pull(subid) %>% unique()
subids_lowtrials

with(dm %>%
  filter(cond %in% c('sourcehit')), 
  table(subid, reps))
  
with(dm %>%
  filter(!subid %in% subids_lowtrials,
         cond %in% c('sourcehit')), 
  table(subid, reps))

dm_time = dm %>%
  filter(!subid %in% subids_lowtrials) %>%
  filter(cond %in% c('sourcehit')) %>%
  gather('time', 'logit_vtc', `X0`:`X12`) %>%
  mutate(time=gsub("X","",time)) %>%
  group_by(group, subid, reps, time) %>%
  summarise(mean_logit = mean_(logit_vtc)) %>%
  group_by(group, reps, time) %>%
  summarise(mean=mean_(mean_logit), sem=std.error(mean_logit), n=length(mean_logit)) %>%
  mutate(time = as.numeric(time)) %>%
  ungroup() %>%
  mutate(reps = revalue(reps, replace = c('2' = 'weak',
                                          '4' = 'strong'))) %>%
  mutate(group = revalue(group, replace = c('control' = 'Control',
                                            'stress' = 'Stress')))

dm_time

p2 = ggplot(dm_time,
            aes(x=factor(time), y=mean, group=reps, color=reps)) +
     geom_line(position=position_dodge(.2), size=1.5) +
    geom_point(position=position_dodge(.2), size=5) +
    facet_grid(.~group)+
    geom_errorbar(width=0, aes(ymin=mean-sem, 
                               ymax=mean+sem), size=1.5,
                  position=position_dodge(.2)) +
    scale_color_brewer(palette = 'Set1', 
                       guide = guide_legend(title = NULL)) +
  ylab('Reinstatement strength\n(logits)') +
  xlab('Time post-stimulus onset (s)') +
  theme_classic(base_size = 18)+
  theme(legend.position = c(.5, .8),
        legend.title=element_blank(), 
        strip.text = element_text(size=18),
        strip.background = element_rect(colour="white", fill="white"))
p2
ggsave('~/Experiments/AP/figs/AP_reinstatement_bygroupXrep_SH_ts.jpeg',
       dpi=300, width=8, height=4)
ggsave('~/Dropbox/Stanford/Papers/AP/Figures/AP_supp_figure6.tiff', 
       dpi=600, width=8, height=4)
ggsave('~/Dropbox/Stanford/Papers/AP/Figures/AP_supp_figure6_150dpi.tiff', 
       dpi=150, width=8, height=4)
p2
```

### All old conditions
```{r}
head(dm)
dm_time = dm %>%
  gather('time', 'logit_vtc', `X0`:`X12`) %>%
  mutate(time=gsub("X","",time)) %>%
  group_by(group, subid, cond, time) %>%
  summarise(mean_logit = mean_(logit_vtc)) %>%
  group_by(group, cond, time) %>%
  summarise(mean=mean_(mean_logit), 
            sem=std.error(mean_logit), 
            n=length(mean_logit)) %>%
  mutate(time = as.numeric(time))

# update names for plot
unique(dm_time$cond)
dm_time = dm_time %>% ungroup() %>%
  mutate(cond = as.character(cond),
         cond = revalue(cond, replace = c('sourcehit' = 'HC assoc hit',
                                          'sourcemiss_hi' = 'HC assoc FA',
                                          'itemhit_lo' = 'LC item hit',
                                           'M' = 'Miss')),
         cond = factor(cond, levels=c('HC assoc hit',
                                      'HC assoc FA',
                                      'LC item hit', 
                                      'Miss'))) 
dm_time
p2 = ggplot(dm_time,
            aes(x=factor(time), y=mean, group=cond, color=cond)) +
    facet_grid(.~group)+
   geom_errorbar(width=0, aes(ymin=mean-sem, 
                               ymax=mean+sem), size=1.5,
                  position=position_dodge(.5)) +
     geom_line(position=position_dodge(.5), size=1.5) +
    geom_point(position=position_dodge(.5), size=5) +
    scale_color_brewer(palette = 'RdYlBu', 
                       guide = guide_legend(title = NULL)) +
  ylab('Reinstatement strength\n(logits)') +
  xlab('Time post-stimulus onset (s)') +
   theme(legend.title=element_blank())
p2

ggsave('~/Experiments/AP/figs/AP_reinstatement_bygroup_allOLD_ts.jpeg',
       dpi=150, width=9, height=4)
p2
```
### All old conditions by hipp quintile
```{r}
head(dm)
dm_time = dm %>%
  gather('time', 'logit_vtc', `X0`:`X12`) %>%
  mutate(time=gsub("X","",time)) %>%
  group_by(group, subid, cond, time, hipp_quintile) %>%
  summarise(mean_logit = mean_(logit_vtc)) %>%
  group_by(group, cond, time, hipp_quintile) %>%
  summarise(mean=mean_(mean_logit), 
            sem=std.error(mean_logit), 
            n=length(mean_logit)) %>%
  ungroup() %>%
  mutate(time = as.numeric(time))

# update names for plot
unique(dm_time$cond)
dm_time = dm_time %>% ungroup() %>%
  mutate(cond = as.character(cond),
         cond = revalue(cond, replace = c('sourcehit' = 'HC assoc hit',
                                          'sourcemiss_hi' = 'HC assoc FA',
                                          'itemhit_lo' = 'LC item hit',
                                           'M' = 'Miss')),
         cond = factor(cond, levels=c('HC assoc hit',
                                      'HC assoc FA',
                                      'LC item hit', 
                                      'Miss'))) 
dm_time
p2 = ggplot(dm_time,
            aes(x=factor(time), y=mean, group=cond, color=cond)) +
    facet_grid(group~hipp_quintile)+
   geom_errorbar(width=0, aes(ymin=mean-sem, 
                               ymax=mean+sem), size=1.5,
                  position=position_dodge(.5)) +
     geom_line(position=position_dodge(.5), size=1.5) +
    geom_point(position=position_dodge(.5), size=5) +
    scale_color_brewer(palette = 'RdYlBu', 
                       guide = guide_legend(title = NULL)) +
  ylab('Reinstatement strength\n(logits)') +
  xlab('Time post-stimulus onset (s)') +
   theme(legend.title=element_blank())
p2

ggsave('~/Experiments/AP/figs/AP_reinstatement_bygroupXhippquintile_allOLD_ts.jpeg',
       dpi=150, width=20, height=9)
p2

p2 = ggplot(dm_time,
            aes(x=factor(time), y=mean, group=factor(hipp_quintile), color=factor(hipp_quintile))) +
    facet_grid(group~cond)+
      geom_hline(yintercept = 0, linetype=2)+

   geom_errorbar(width=0, aes(ymin=mean-sem, 
                               ymax=mean+sem), size=1.5,
                  position=position_dodge(.5)) +
     geom_line(position=position_dodge(.5), size=1.5) +
    geom_point(position=position_dodge(.5), size=5) +
    scale_color_brewer(palette = 'RdYlBu', 
                       guide = guide_legend(title = NULL)) +
  ylab('Reinstatement strength\n(logits)') +
  xlab('Time post-stimulus onset (s)') +
   theme(legend.title=element_blank())
ggsave('~/Experiments/AP/figs/AP_reinstatement_bygroupXhippquintile_allOLD_ts_v2.jpeg',
       dpi=150, width=20, height=9)
p2

p2 = ggplot(dm_time,
            aes(x=factor(time), y=mean, group=group, color=group)) +
    facet_grid(cond~hipp_quintile)+
  geom_hline(yintercept = 0, linetype=2)+
   geom_errorbar(width=0, aes(ymin=mean-sem, 
                               ymax=mean+sem), size=1.5,
                  position=position_dodge(.5)) +
     geom_line(position=position_dodge(.5), size=1.5) +
    geom_point(position=position_dodge(.5), size=5) +
    scale_color_manual(values=palette, 
                       guide = guide_legend(title = NULL)) +
  ylab('Reinstatement strength\n(logits)') +
  xlab('Time post-stimulus onset (s)') +
   theme(legend.title=element_blank()) 
p2

ggsave('~/Experiments/AP/figs/AP_reinstatement_bygroupXhippquintile_allOLD_ts_v3.jpeg',
       dpi=150, width=15, height=15)
p2
```
```{r}
head(dm)
dm_time = dm %>%
  group_by(group, subid, cond, hipp_quintile) %>%
  summarise(mean_logit = mean_(vtc_logit)) %>%
  group_by(group, cond, hipp_quintile) %>%
  summarise(mean=mean_(mean_logit), 
            sem=std.error(mean_logit), 
            n=length(mean_logit)) %>%
  ungroup()

# update names for plot
dm_time = dm_time %>% ungroup() %>%
  mutate(cond = as.character(cond),
         cond = revalue(cond, replace = c('sourcehit' = 'HC assoc hit',
                                          'sourcemiss_hi' = 'HC assoc FA',
                                          'itemhit_lo' = 'LC item hit',
                                           'M' = 'Miss')),
         cond = factor(cond, levels=c('HC assoc hit',
                                      'HC assoc FA',
                                      'LC item hit', 
                                      'Miss'))) 
dm_time

p2 = ggplot(dm_time,
            aes(x=factor(hipp_quintile), y=mean, group=group, color=group)) +
    facet_grid(.~cond)+
  geom_hline(yintercept = 0, linetype=2)+
   geom_errorbar(width=0, aes(ymin=mean-sem, 
                               ymax=mean+sem), size=1.5,
                  position=position_dodge(.5)) +
     geom_line(position=position_dodge(.5), size=1.5) +
    geom_point(position=position_dodge(.5), size=5) +
    scale_color_manual(values=palette, 
                       guide = guide_legend(title = NULL)) +
  ylab('Reinstatement strength\n(logits)') +
  xlab('Hipp quintile') +
   theme(legend.title=element_blank()) 
p2

ggsave('~/Experiments/AP/figs/AP_reinstatement_bygroupXhippquintile_allOLD_v4.jpeg',
       dpi=150, width=15, height=8)
p2
```


### All old conditions by hipp quintile (collapse across cond)
```{r}
head(dm)
dm_time = dm %>%
  gather('time', 'logit_vtc', `X0`:`X12`) %>%
  mutate(time=gsub("X","",time)) %>%
  group_by(group, subid, time, hipp_quintile) %>%
  summarise(mean_logit = mean_(logit_vtc)) %>%
  group_by(group, time, hipp_quintile) %>%
  summarise(mean=mean_(mean_logit), 
            sem=std.error(mean_logit), 
            n=length(mean_logit)) %>%
  ungroup() %>%
  mutate(time = as.numeric(time))

blues <- brewer.pal(6, "Blues")[2:6]
p2 = ggplot(dm_time,
            aes(x=factor(time), y=mean, group=hipp_quintile, color=factor(hipp_quintile))) +
    facet_grid(.~group)+
      geom_hline(yintercept = 0, linetype=2)+
   geom_errorbar(width=0, aes(ymin=mean-sem, 
                               ymax=mean+sem), size=1.5,
                  position=position_dodge(.5)) +
     geom_line(position=position_dodge(.5), size=1.5) +
    geom_point(position=position_dodge(.5), size=5) +
    scale_color_manual(values = blues,
                       guide = guide_legend(title = NULL)) +
  ylab('Reinstatement strength\n(logits)') +
  xlab('Time post-stimulus onset (s)') +
   theme(legend.title=element_blank())
p2

ggsave('~/Experiments/AP/figs/AP_reinstatement_bygroupXhippquintile_collapse_allOLD_ts.jpeg',
       dpi=150, width=9, height=5)
p2

p2 = ggplot(dm_time,
            aes(x=factor(time), y=mean, group=group, color=group)) +
    facet_grid(.~hipp_quintile)+
      geom_hline(yintercept = 0, linetype=2)+
   geom_errorbar(width=0, aes(ymin=mean-sem, 
                               ymax=mean+sem), size=1.5,
                  position=position_dodge(.5)) +
     geom_line(position=position_dodge(.5), size=1.5) +
    geom_point(position=position_dodge(.5), size=5) +
    scale_color_manual(values = palette,
                       guide = guide_legend(title = NULL)) +
  ylab('Reinstatement strength\n(logits)') +
  xlab('Time post-stimulus onset (s)') +
   theme(legend.title=element_blank())
p2

ggsave('~/Experiments/AP/figs/AP_reinstatement_bygroupXhippquintile_collapse_allOLD_ts_v2.jpeg',
       dpi=150, width=15, height=5)
p2
```

# 3b) Effects of group/encoding strength on inferior parietal reinstatement

Note that these analyses are using strict criterion that VTC reinstatement F1 score can't be an outlier (control = 22, stress = 20); see below for analyses allowing 1 participant with non-outlier inferior parietal F1 score to be included (control = 22, stress = 21).

## HC assoc hits: infparietal reinstatement ~ group
```{r}
subids_lowtrials = dm %>% 
  filter(cond == 'sourcehit') %>%
  group_by(group, subid) %>% 
  summarise(count = n()) %>% 
  ungroup() %>%
  complete(nesting(subid, group), fill = list(count= 0)) %>%
  filter(count < 6) %>% 
  pull(subid) %>% unique()
subids_lowtrials

d_avg = dm %>% filter(!subid %in% subids_lowtrials) %>%
  filter(cond == 'sourcehit') %>%
  group_by(group, subid) %>%
  summarise(mean=mean(ang_logit))
with(d_avg, table(group))

# diff between groups?
bartlett.test(mean ~ group, data=d_avg)
t.test(mean ~ group, data=d_avg, var.equal=TRUE)
d_avg %>% group_by(group) %>% summarise(mean(mean), n())

t.test(d_avg %>% filter(group == 'control') %>% pull(mean), mu = 0)
t.test(d_avg %>% filter(group == 'stress') %>% pull(mean), mu = 0)
```


# 4) Hipp peak from whole-brain analysis

## Sphere from control>stress, SH > CR
```{r echo=FALSE, cache=TRUE}
dat = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/pe_sourcehit-cr_zstat1_peak1_5mm_sphere_masked.nii.csv')
dat = dat %>% filter(cond %in% c('sourcehit', 'CR')) %>%
  mutate(cond = factor(cond))

# circular stats
contrasts(dat$group) = c(1,-1); contrasts(dat$group)
contrasts(dat$cond) = c(-1,1); contrasts(dat$cond)
summary(lmer(value ~ group * cond + (1|subid), data=dat))

t.test(value ~ group, data=dat %>% filter(cond == 'sourcehit'), var.equal=TRUE)
t.test(value ~ group, data=dat %>% filter(cond == 'CR'), var.equal=TRUE)

# Plot
dat_avg = dat %>%
  group_by(subid, group, cond) %>%
  summarise(mean=mean(value)) %>%
  group_by(group, cond) %>%
  summarise(value=mean(mean), sem=std.error(mean), n=length(mean)) %>%
  ungroup() %>%
  mutate(cond = factor(cond, levels=c('sourcehit', 'CR'))) %>%
  mutate(cond = revalue(cond, c('sourcehit' = 'HC\nassoc hit')))
dat_avg  

ggplot(data=dat_avg, aes(x=cond, y=value, 
                         fill=group, group=group)) +
  geom_bar(position=position_dodge(), stat="identity") +
  geom_errorbar(aes(ymin=value-sem, ymax=value+sem), 
                width=0, position=position_dodge(.9), size=1.5) +
  scale_fill_manual(values=palette) +
  scale_color_manual(values=palette) +
  xlab('') +
  ylab("Parameter estimate (a.u.)") +
  theme_classic(base_size = 16) +
  theme(legend.title=element_blank(),
        legend.position = c(.8, .8))

ggsave('~/Experiments/AP/figs/pe_sphere_sourcehit-CR_control-stress.png',  dpi=600, width=3, height=3.2)


dat_subs = dat %>%
  group_by(subid, group, cond) %>%
  summarise(mean=mean(value)) %>%
  ungroup() %>%
  mutate(cond = factor(cond, levels=c('sourcehit', 'CR'))) %>%
  mutate(cond = revalue(cond, c('sourcehit' = 'HC\nassoc hit')))
dat_subs  
  
p = ggplot(data=dat_subs, aes(x=cond, y=mean, 
                         color=group)) +
  geom_boxplot(position = position_dodge(width = .85),
                outlier.shape = NA) +
  geom_point(pch = 21, position = position_jitterdodge())+
  scale_color_manual(values=c('dodgerblue', 'orange')) +
  xlab('') +
  ylab("Parameter estimate (a.u.)") +
  theme_classic(base_size = 16) +
  theme(legend.title=element_blank(),
        legend.position = c(.8, .8))
p

p = ggplot(data=dat_avg, aes(x=cond, y=value, color=group, fill=group, group=group)) + 
  geom_point(pch = 19, alpha=1, size=3, position=position_dodge(.9)) +
  geom_errorbar(aes(y=value, ymin=value-sem, ymax=value+sem), 
                width=0, position=position_dodge(.9), size=1.5) +
  scale_fill_manual(values=c('dodgerblue', 'orange')) +
  scale_color_manual(values=c('dodgerblue', 'orange')) +
  xlab('') +
  ylab("Parameter estimate (a.u.)") +
  theme_classic(base_size = 16) +
  theme(legend.title=element_blank(),
        # legend.position = c(.8, .9),
        legend.background = element_rect(fill="transparent")) +
  geom_point(data=dat_subs, aes(y=mean), pch = 19, position = position_jitterdodge(), 
             alpha=.2, size=1.5)

ggsave('~/Experiments/AP/figs/pe_sphere_sourcehit-CR_control-stress_stripplot_se.jpg', dpi=600, width=3.8, height=3.2); p
```

# 5) Predictors of HC accuracy

## Calculate P(accurate|respond "high conf source" to old item)

```{r}
with(dtest %>% filter(reps > 0,
                      conf == 'Hi'), table(subj_status, acc))
dtest %>% 
  filter(subj_status == 'old',
         reps > 0, # old item
         conf == 'Hi') %>% dim()

dtest %>% 
  filter(subj_status == 'old',
         reps > 0, # old item
         conf == 'Hi',
         acc_num == 1) %>% dim() # 3025

dat = dtest %>% 
  filter(subj_status == 'old',
         reps > 0, # old item
         conf == 'Hi') %>%
  group_by(subid, group) %>%
  summarise(mean_acc = mean(acc_num), sum=sum(acc_num), count=n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), fill = list(mean_acc=0,
                                                    count=0))
dat
# filter out subjs who don't have more than 5 "old" responses to old cues
dim(dat) # all subjs included
dat %>% filter(count < 6) 
rm_subids = dat %>% filter(count < 6) %>% pull(subid) %>% unique(); rm_subids
rm_subids # ap151
dat = dat %>% filter(!subid %in% rm_subids)

# logit transform accuracy for stats (since upper bounded at 1)
dat %>% group_by(subid, group) %>% 
  summarise(mean_acc = mean(mean_acc), n()) %>% 
  group_by(group) %>% 
  summarise(mean(mean_acc), n())
hist(dat$mean_acc)
dat = dat %>% mutate(mean_acc_logit = car::logit(mean_acc))
hist(dat$mean_acc_logit)
boxplot(dat$mean_acc_logit)
```

### Across all subjs (regardless of scan-criteria) effect of group on acc?
```{r}
bartlett.test(mean_acc_logit ~ group, data=dat)
t.test(mean_acc_logit ~ group, data=dat, var.equal=TRUE)

dat_control = dat %>% filter(group == 'control')
t.test(x=dat_control$mean_acc_logit, mu = 0)

dat_control = dat %>% filter(group == 'stress')
t.test(x=dat_control$mean_acc_logit, mu = 0)
```

## Is group -> source accuracy mediated by hippocampal activity for SHs (>CRs)?

### Load in hippocampal ROI data
```{r}
roi = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/pe_sourcehit-cr_zstat1_peak1_5mm_sphere_masked.nii.csv')
roi = roi %>% filter(cond %in% c('sourcehit', 'CR')) %>%
  mutate(cond = factor(cond)) %>% 
  dplyr::select(subid, group, cond, value) %>%  # calc diff score
  spread(key = cond, value=value) %>%
  mutate(diff = sourcehit - CR) %>%
  left_join(dat, by = c('subid', 'group')) %>%
  mutate(diff_orig = diff,
         diff = as.numeric(scale(diff)),
         mean = mean_acc,
         mean_acc_logit = as.numeric(car::logit(mean_acc)),
         mean_acc = as.numeric(scale(car::logit(mean_acc))))
roi$subid= factor(roi$subid)
str(roi)

contrasts(roi$group) = c(1,-1)
with(roi, hist(mean_acc))
with(roi, hist(mean))

roi %>% group_by(group) %>% summarise(mean(mean), mean(mean_acc), n())
```

### Mediation of group -> assoc acc by posterior hipp BOLD
```{r}
model.t = lm(mean_acc ~ group, data=roi); summary(model.t) # total effect = 0.30
#              Estimate Std. Error t value Pr(>|t|)  
# (Intercept) 1.072e-16  1.455e-01   0.000   1.0000  
# group1      2.979e-01  1.455e-01   2.048   0.0468 *
model.m = lm(diff ~ group, data=roi); summary(model.m) # a = 0.35 
#               Estimate Std. Error t value Pr(>|t|)  
# (Intercept) -1.289e-16  1.427e-01   0.000   1.0000  
# group1       3.498e-01  1.427e-01   2.452   0.0185 *
model.y = lm(mean_acc ~ group + diff, data=roi); summary(model.y)
#              Estimate Std. Error t value Pr(>|t|)   
# (Intercept) 1.694e-16  1.297e-01   0.000  1.00000   
# group1      1.290e-01  1.386e-01   0.931  0.35745   
# diff        4.827e-01  1.402e-01   3.442  0.00134 **
model.other = lm(mean_acc ~ diff, data=roi); summary(model.other)
#              Estimate Std. Error t value Pr(>|t|)    
# (Intercept) 1.791e-16  1.295e-01   0.000 1.000000    
# diff        5.289e-01  1.310e-01   4.038 0.000224 ***
# Multiple R-squared:  0.2797,	Adjusted R-squared:  0.2626 

str(roi)
with(roi, plot(mean_acc ~ diff))
plot(model.other)

# does this hold for each group?
with(roi %>% filter(group == 'control'), plot(mean_acc ~ diff))
with(roi %>% filter(group == 'stress'), plot(mean_acc ~ diff))

summary(lm(mean_acc ~ diff, data=roi %>% filter(group == 'control')))
summary(lm(mean_acc ~ diff, data=roi %>% filter(group == 'stress')))

# robust regression since outliers/small sample sizes
library(MASS)
roi %>% filter(group == 'control') %>% summarise(n())
summary(rlm(mean_acc ~ diff, data=roi %>% filter(group == 'control')))
pt(q = 1.4697, df = 20, lower.tail = FALSE)
summary(rlm(mean_acc ~ diff, data=roi %>% filter(group == 'stress')))
pt(q = 3.0331, df = 20, lower.tail = FALSE)

# does variability in these measures vary across groups?
roi %>% filter(group == 'control') %>% pull(mean_acc) %>% sd()
roi %>% filter(group == 'stress') %>% pull(mean_acc) %>% sd()
roi %>% filter(group == 'control') %>% pull(diff) %>% sd()
roi %>% filter(group == 'stress') %>% pull(diff) %>% sd()

## Bootstrapping Confidence Interval (BCa and Percentile)
boot.med <- function(data, indices){
	data <-data[indices,]	#this does the random resampling of rows

	reg1 <- lm(diff ~ group, data=data)
	reg2 <- lm(mean_acc ~ group + diff, data=data)
	
	a <- coefficients(reg1)["group1"]	#the a path coefficient
	b <- coefficients(reg2)["diff"]	#the b path coefficient
	a*b							#returns the product of a*b
}

medboot<-boot(data=roi, statistic = boot.med, R=5000)	
mean(medboot$t)
quantile(medboot$t, c(0.025, 0.975))

# RESULTS:
# > mean(medboot$t)
# [1] 0.1645428
# > quantile(medboot$t, c(0.025, 0.975))
#      2.5%     97.5% 
# 0.0254956 0.3545451 
```

### Plot 
```{r}
p = ggplot(roi, aes(x=diff_orig, y=mean_acc_logit, color=group)) +
  geom_point() +   
  geom_smooth(method=lm, color='black') + 
  geom_point(aes(color=group), size=3, alpha=.8) +
  scale_color_manual(values=c('dodgerblue', 'orange')) +
  xlab('Hippocampal BOLD (a.u.)') +
  ylab('HC associative accuracy\n(logit transformed)') +
    theme(legend.title=element_blank(), legend.position = c(0.2, 0.9),
          plot.margin = unit(c(2, 2, 1, 1), "lines"))
ggsave('~/Experiments/AP/figs/AP_hippXacc.jpeg', dpi=150, width=5.5, height=4.3)

ggsave('~/Dropbox/Stanford/Papers/Dissertation/Figures_Defense/AP_hippXacc.png', dpi=300, width=5.5, height=4.3)

p
```

### Check that this still holds when removing 2 subs w/bad VTC:
```{r}
subids_rm = c('ap168', 'ap174')

roi = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/pe_sourcehit-cr_zstat1_peak1_5mm_sphere_masked.nii.csv')
roi = roi %>% filter(!subid %in% subids_rm,
                     cond %in% c('sourcehit', 'CR')) %>%
  mutate(cond = factor(cond)) %>% 
  dplyr::select(subid, group, cond, value) %>%  # calc diff score
  spread(key = cond, value=value) %>%
  mutate(diff = sourcehit - CR) %>%
  left_join(dat, by = c('subid', 'group')) %>%
  mutate(diff_orig = diff,
         diff = as.numeric(scale(diff)),
         mean = mean_acc,
         mean_acc = as.numeric(scale(car::logit(mean_acc))))
roi$subid= factor(roi$subid)
str(roi)

contrasts(roi$group) = c(1,-1)
roi %>% group_by(group) %>% summarise(mean(mean), mean(mean_acc), n())

model.t = lm(mean_acc ~ group, 
             data=roi); summary(model.t) 
#             Estimate Std. Error t value Pr(>|t|)  
# (Intercept) -0.01372    0.14961  -0.092   0.9274  
# group1       0.28815    0.14961   1.926   0.0612 .
model.m = lm(diff ~ group, 
             data=roi); summary(model.m) 
#             Estimate Std. Error t value Pr(>|t|)  
# (Intercept) -0.01504    0.14821  -0.102   0.9197  
# group1       0.31594    0.14821   2.132   0.0392 *
model.y = lm(mean_acc ~ group + diff, 
             data=roi); summary(model.y)
#              Estimate Std. Error t value Pr(>|t|)   
# (Intercept) -0.006673   0.134229  -0.050  0.96061   
# group1       0.140123   0.141631   0.989  0.32859   
# diff         0.468537   0.143185   3.272  0.00224 **
model.other = lm(mean_acc ~ diff, 
                 data=roi); summary(model.other)
#              Estimate Std. Error t value Pr(>|t|)    
# (Intercept) -2.593e-17  1.340e-01   0.000 1.000000    
# diff         5.138e-01  1.356e-01   3.788 0.000501 ***
# Multiple R-squared:  0.264,	Adjusted R-squared:  0.2456 
 
str(roi)
with(roi, plot(mean_acc ~ diff))

# does this hold for each group?
with(roi %>% filter(group == 'control'), plot(mean_acc ~ diff))
with(roi %>% filter(group == 'stress',
                    !subid %in% subids_rm), plot(mean_acc ~ diff))

summary(lm(mean_acc ~ diff, data=roi %>% filter(group == 'control')))
summary(lm(mean_acc ~ diff, data=roi %>% filter(group == 'stress')))

# robust regression since outliers/small sample sizes
library(MASS)
summary(rlm(mean_acc ~ diff, data=roi %>% filter(group == 'control')))
pt(q = 1.4697, df = 20, lower.tail = FALSE)
summary(rlm(mean_acc ~ diff, data=roi %>% filter(group == 'stress')))
pt(q = 3.2967, df = 20, lower.tail = FALSE)

## Bootstrapping Confidence Interval (BCa and Percentile)
boot.med <- function(data, indices){
	data <-data[indices,]	#this does the random resampling of rows

	reg1 <- lm(diff ~ group, data=data)
	reg2 <- lm(mean_acc ~ group + diff, data=data)
	
	a <- coefficients(reg1)["group1"]	#the a path coefficient
	b <- coefficients(reg2)["diff"]	#the b path coefficient
	a*b							#returns the product of a*b
}

medboot<-boot(data=roi, 
              statistic = boot.med, R=5000)
mean(medboot$t)
quantile(medboot$t, c(0.025, 0.975))

# RESULTS:
# > mean(medboot$t)
# [1] 0.1415879
# > quantile(medboot$t, c(0.025, 0.975))
#          2.5%         97.5% 
# -0.0001349303  0.3141738951
```


## Is hipp effect on source accuracy mediated by VTC reinstatement?
```{r}
vtc = read.csv('/Volumes/group/awagner/sgagnon/AP/results/sourcehit_avglogit_vtc.csv')
vtc = vtc %>% mutate(mean_logit = mean) %>% dplyr::select(-mean)

roi = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/pe_sourcehit-cr_zstat1_peak1_5mm_sphere_masked.nii.csv')
roi = roi %>% filter(cond %in% c('sourcehit', 'CR')) %>%
  mutate(cond = factor(cond)) %>% 
  dplyr::select(subid, group, cond, value) %>%  # calc diff score
  spread(key = cond, value=value) %>%
  mutate(diff = sourcehit - CR) %>%
  right_join(vtc, by = c('subid', 'group')) %>%
  left_join(dat, by = c('subid', 'group')) %>%
  mutate(diff_orig = diff,
         diff = as.numeric(scale(diff)),
         logit_orig = mean_logit,
         mean_logit = scale(mean_logit),
         mean_acc_logit = as.numeric(car::logit(mean_acc)),
         mean_acc = as.numeric(scale(car::logit(mean_acc))))
dim(roi)
str(roi)

roi %>% group_by(group) %>% summarise(n()) # n=22, 20

contrasts(roi$group) = c(1,-1)

model.t = lm(mean_acc ~ diff, data=roi); summary(model.t) 
#               Estimate Std. Error t value Pr(>|t|)    
# (Intercept) -2.593e-17  1.340e-01   0.000 1.000000    
# diff         5.138e-01  1.356e-01   3.788 0.000501 ***
model.m = lm(mean_logit ~ diff, data=roi); summary(model.m)
#              Estimate Std. Error t value Pr(>|t|)    
# (Intercept) 4.251e-17  1.336e-01   0.000 1.000000    
# diff        5.187e-01  1.352e-01   3.837 0.000433 ***
model.y = lm(mean_acc ~ mean_logit + diff, data=roi); summary(model.y)
#               Estimate Std. Error t value Pr(>|t|)   
# (Intercept) -2.756e-17  1.356e-01   0.000  1.00000   
# mean_logit   3.837e-02  1.606e-01   0.239  0.81240   
# diff         4.939e-01  1.606e-01   3.076  0.00383 **
model.other = lm(mean_acc ~ mean_logit, data=roi); summary(model.other) #marginal
# (Intercept) -3.227e-17  1.493e-01   0.000   1.0000  
# mean_logit   2.946e-01  1.511e-01   1.949   0.0583 .
# Multiple R-squared:  0.08676,	Adjusted R-squared:  0.06393 

# any effect of group on reinstatement, when controlling for hipp?
summary(lm(mean_logit ~ diff + group, data=roi))

## Bootstrapping Confidence Interval (BCa and Percentile)
boot.med <- function(data, indices){
	data <-data[indices,]	#this does the random resampling of rows

	reg1 <- lm(mean_logit ~ diff, data=data)
	reg2 <- lm(mean_acc ~ mean_logit + diff, data=data)
	
	a <- coefficients(reg1)["diff"]	#the a path coefficient
	b <- coefficients(reg2)["mean_logit"]	#the b path coefficient
	a*b							#returns the product of a*b
}

medboot<-boot(data=roi, statistic = boot.med, R=5000)	
mean(medboot$t)
quantile(medboot$t, c(0.025, 0.975))

# RESULTS:
# > mean(medboot$t)
# [1] 0.0239775
# > quantile(medboot$t, c(0.025, 0.975))
#       2.5%      97.5% 
# -0.1401416  0.1945644 
```

### Plots
```{r}
ggplot(roi, aes(x=logit_orig, y=mean_acc_logit, color=group)) +
  geom_point() +   
  geom_smooth(method=lm, color='black') + 
  geom_point(aes(color=group), size=3, alpha=.8) +
  scale_color_manual(values=c('dodgerblue', 'orange')) +
  xlab('Reinstatement strength (logits)') +
  ylab('HC associative accuracy\n(logit transformed)') +
    theme(legend.title=element_blank(), legend.position = c(0.2, 0.9),
          plot.margin = unit(c(2, 2, 1, 1), "lines"))
ggsave('~/Experiments/AP/figs/AP_logitXacc.jpeg', dpi=150, width=5.5, height=4.3)
ggsave('~/Dropbox/Stanford/Papers/Dissertation/Figures_Defense/AP_logitXacc.png', dpi=300, width=5.5, height=4.3)

ggplot(roi, aes(x=diff, y=logit_orig, color=group)) +
  geom_point() +   
  geom_smooth(method=lm, color='black') + 
  geom_point(aes(color=group), size=3, alpha=.8) +
  scale_color_manual(values=c('dodgerblue', 'orange')) +
  xlab('Hippocampal BOLD (a.u.)') +
  ylab('Reinstatement strength (logits)') +
    theme(legend.title=element_blank(), legend.position = c(0.2, 0.9),
          plot.margin = unit(c(2, 2, 1, 1), "lines"))
ggsave('~/Experiments/AP/figs/AP_logitXhipp.jpeg', dpi=150, width=5.5, height=4.3)
ggsave('~/Dropbox/Stanford/Papers/Dissertation/Figures_Defense/AP_logitXhipp.png', dpi=300, width=5.5, height=4.8)
```



```{r}
roi = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/pe_sourcehit-cr_zstat1_peak1_5mm_sphere_masked.nii.csv')
roi = roi %>% filter(cond %in% c('sourcehit', 'CR')) %>%
  mutate(cond = factor(cond)) %>% 
  dplyr::select(subid, group, cond, value) %>%  # calc diff score
  spread(key = cond, value=value) %>%
  mutate(diff = sourcehit - CR) %>%
  right_join(slopes_ccn_rt, by = c('subid')) %>%
  left_join(dat, by = c('subid', 'group')) %>%
  mutate(diff_orig = diff,
         diff = as.numeric(scale(diff)),
         slope_orig = coef,
         scaled_coef = as.numeric(scale(coef)),
         mean_acc = as.numeric(scale(car::logit(mean_acc))))
dim(roi)
str(roi)

contrasts(roi$group) = c(1,-1)

summary(lm(scaled_coef ~ group, data=roi))
summary(lm(mean_acc ~ scaled_coef + group, data=roi))
summary(lm(mean_acc ~ scaled_coef + group + diff, data=roi))
```

## Is hipp effect on source accuracy mediated by infparietal reinstatement?
Note that this analysis is excluding 2 subjs w/poor VTC localizer classification.

```{r}
vtc = read.csv('/Volumes/group/awagner/sgagnon/AP/results/sourcehit_avglogit_infparietal.csv')
vtc = vtc %>% mutate(mean_logit = mean) %>% dplyr::select(-mean)
dim(vtc)
vtc %>% group_by(subid, group) %>% summarise(n()) %>% group_by(group) %>% summarise(n())

roi = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/pe_sourcehit-cr_zstat1_peak1_5mm_sphere_masked.nii.csv')
roi = roi %>% filter(cond %in% c('sourcehit', 'CR')) %>%
  mutate(cond = factor(cond)) %>% 
  dplyr::select(subid, group, cond, value) %>%  # calc diff score
  spread(key = cond, value=value) %>%
  mutate(diff = sourcehit - CR) %>%
  right_join(vtc, by = c('subid', 'group')) %>%
  left_join(dat, by = c('subid', 'group')) %>%
  mutate(diff_orig = diff,
         diff = scale(diff),
         mean_logit = scale(mean_logit),
          mean_acc = as.numeric(scale(car::logit(mean_acc))))
dim(roi)
str(roi)

contrasts(roi$group) = c(1,-1)

model.t = lm(mean_acc ~ diff, data=roi); summary(model.t) 
model.m = lm(mean_logit ~ diff, data=roi); summary(model.m)
model.y = lm(mean_acc ~ mean_logit + diff, data=roi); summary(model.y)
model.other = lm(mean_acc ~ mean_logit, data=roi); summary(model.other)


## Bootstrapping Confidence Interval (BCa and Percentile)
boot.med <- function(data, indices){
	data <-data[indices,]	#this does the random resampling of rows

	reg1 <- lm(mean_logit ~ diff, data=data)
	reg2 <- lm(mean_acc ~ mean_logit + diff, data=data)
	
	a <- coefficients(reg1)["diff"]	#the a path coefficient
	b <- coefficients(reg2)["mean_logit"]	#the b path coefficient
	a*b							#returns the product of a*b
}

medboot<-boot(data=roi, statistic = boot.med, R=5000)	
mean(medboot$t)
quantile(medboot$t, c(0.025, 0.975))
```


## 5b) Predictors of LC accuracy

```{r}
dat = dtest %>% 
  filter(subj_status == 'old', 
         reps > 0,
         conf == 'Lo') %>%
  group_by(subid, group) %>%
  summarise(mean_acc = mean(acc_num), count=n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), fill = list(mean_acc=0,
                                              count=0))
dim(dat) # missing 104, with no LC responses
dat %>% filter(count < 6) 
rm_subids = dat %>% filter(count < 6) %>% pull(subid) %>% unique()
rm_subids
dat = dat %>% filter(!subid %in% rm_subids)

dat %>% group_by(subid, group) %>% summarise(n()) %>% group_by(group) %>% summarise(n())

hist(dat$mean_acc)
dat = dat%>% mutate(mean_acc_logit = car::logit(mean_acc))
hist(dat$mean_acc_logit)

bartlett.test(mean_acc_logit ~ group, data=dat)
t.test(mean_acc_logit ~ group, data=dat, var.equal=TRUE)

dat_control = dat %>% filter(group == 'control')
t.test(x=dat_control$mean_acc_logit, mu = 0)

dat_control = dat %>% filter(group == 'stress')
t.test(x=dat_control$mean_acc_logit, mu = 0)
dat
```

### Does hipp track LC accuracy?
```{r}
roi = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/pe_sourcehit-cr_zstat1_peak1_5mm_sphere_masked.nii.csv')
roi %>% group_by(subid, group) %>% summarise(n()) %>%  group_by(group) %>% summarise(n())

roi = roi %>% filter(cond %in% c('sourcehit', 'CR')) %>%
  mutate(cond = factor(cond)) %>% 
  dplyr::select(subid, group, cond, value) %>%  # calc diff score
  spread(key = cond, value=value) %>%
  mutate(diff = sourcehit - CR) %>%
  inner_join(dat, by = c('subid', 'group')) %>%
  mutate(diff_orig = diff,
         diff = scale(diff),
          mean_acc = as.numeric(scale(car::logit(mean_acc))))
dim(roi)
str(roi)

roi %>% group_by(group) %>% summarise(n())
contrasts(roi$group) = c(1,-1)
model.t = lm(mean_acc ~ diff, data=roi); summary(model.t) 

ggplot(roi, aes(x=diff_orig, y=mean_acc)) +
  geom_point() +   
  geom_smooth(method=lm) +
  xlab('Hippocampus SH > CR') +
  ylab('Low conf source accuracy (logit)')
```



# 6) Effects of stress on frontoparietal networks (and interactions by run type)

```{r}
basedir = '/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/'
# dt = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/mvpa/notebooks/ap_behav.csv') #already read in
# head(dt)
counts = dt %>%
  filter(mem_conditions %in% c('CR', 'sourcehit')) %>%
  group_by(subid, mem_conditions) %>%
  summarise(n=n()) %>%
  ungroup() %>%
  complete(subid, mem_conditions, fill = list(n=0)) 
  # filter(mem_conditions %in% c('sourcehit', 'CR'))
# length(unique(dt$mem_conditions)) * length(unique(dt$subid))

sub_remove = counts %>% 
  filter(mem_conditions %in% c('sourcehit', 'CR'), 
         n <= 5) %>% 
  pull(subid); sub_remove

sub_remove
```
```{r}
dt %>%
  filter(mem_conditions %in% c('CR', 'sourcehit')) %>%
  mutate(mem_conditions = factor(mem_conditions)) %>%
  group_by(subid, shockCond, mem_conditions) %>%
  summarise(n=n()) %>%
  ungroup() %>%
  complete(subid, shockCond, mem_conditions, fill = list(n=0)) %>%
  filter(n < 6)

dt %>%
  filter(mem_conditions %in% c('CR', 'sourcehit')) %>%
  mutate(mem_conditions = factor(mem_conditions)) %>%
  group_by(subid, group, shockCond, mem_conditions) %>%
  summarise(n=n()) %>%
  ungroup() %>%
  complete(nesting(subid, group),
           shockCond, mem_conditions, fill = list(n=0)) %>%
  group_by(subid, group) %>% summarise(min = min(n)) %>%
  filter(min > 5) %>%
  group_by(group) %>% summarise(n())
# and ap106 has too much motion, so n = 20 control
```



## 6a) CCN
```{r}
d2 = read.csv(paste(basedir,'pe_frontoparietal.csv', sep=''))
data = d2 %>%
  filter(cond %in% c('sourcehit', 'CR')) %>%
  mutate(cond = factor(cond)) %>% 
  filter(!(subid %in% sub_remove))

data %>% group_by(subid, group) %>% summarise(n()) %>% 
  group_by(group) %>% summarise(n())

contrasts(data$group) = c(1, -1); contrasts(data$group)
data$cond = factor(data$cond)
contrasts(data$cond) = c(-1,1); contrasts(data$cond)
contrasts(data$hemi) = c(1,-1); contrasts(data$hemi)

summary(lmer(value ~ group * cond + (1|subid), 
             data=data %>% filter(hemi == 'lh')))

summary(lmer(value ~ group * cond * hemi + (1 + cond + hemi|subid), data=data)) # including cond RE not enough obs
```

## 6b) DAN
```{r}
d2 = read.csv(paste(basedir,'pe_dorsalattn.csv', sep=''))
data = d2 %>%
  filter(cond %in% c('sourcehit', 'CR')) %>%
  mutate(cond = factor(cond)) %>% 
  filter(!(subid %in% sub_remove))

data %>% group_by(subid, group) %>% summarise(n()) %>% 
  group_by(group) %>% summarise(n())

contrasts(data$group) = c(1, -1); contrasts(data$group)
data$cond = factor(data$cond)
contrasts(data$cond) = c(-1,1); contrasts(data$cond)
contrasts(data$hemi) = c(1,-1); contrasts(data$hemi)

summary(lmer(value ~ group * cond + (1|subid), 
             data=data %>% filter(hemi == 'lh')))

summary(lmer(value ~ group * cond * hemi + (1 + cond + hemi|subid), data=data)) # including cond RE not enough obs
```

## 6c) Effect of shock condition -- CCN
```{r}
basedir = '/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw-byshockCond/group/roi/'
d2 = read.csv(paste(basedir,'pe_frontoparietal.csv', sep=''))
glimpse(d2)

data = d2 %>% 
  separate(cond, into = c('this', 'shockCond'), sep = ".*(_)", remove = FALSE) %>%
  separate(cond, into = c('cond', 'that'), sep = "_[^_]*$") %>%
  dplyr::select(-one_of('this', 'that')) %>%
  filter(cond %in% c('sourcehit', 'CR')) %>%
  mutate(cond=factor(cond),
         shockCond=factor(shockCond))
glimpse(data)

data %>% group_by(subid, shockCond, group) %>% 
  summarise(n()) %>%
  group_by(shockCond, group) %>% summarise(n())

contrasts(data$group) = c(1, -1); contrasts(data$group)
contrasts(data$cond) =c(-1,1); contrasts(data$cond)
contrasts(data$hemi) =c(1,-1); contrasts(data$hemi)
contrasts(data$shockCond) =c(1,-1); contrasts(data$shockCond)

# interaction within stress group?
dim(data %>% filter(group == 'stress', hemi == 'lh'))
summary(lmer(value ~ cond*shockCond + (1+cond+shockCond|subid), 
             data=data %>% filter(group == 'stress', hemi == 'lh'))) #interaction n.obs
# (Intercept)        313.78     137.51  19.00   2.282   0.0342 *  
# cond1              505.28      79.65  19.42   6.343 3.94e-06 ***
# shockCond1         -63.36      60.73  24.44  -1.043   0.3070    
# cond1:shockCond1   -60.28      51.96  38.13  -1.160   0.2532  

summary(lmer(value ~ cond*shockCond*hemi + (1+cond*shockCond+ hemi|subid), 
             data=data %>% filter(group == 'stress')))
```

## 6d) Effect of shock condition -- DAN
```{r}
basedir = '/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw-byshockCond/group/roi/'
d2 = read.csv(paste(basedir,'pe_dorsalattn.csv', sep=''))
glimpse(d2)

data = d2 %>% 
  separate(cond, into = c('this', 'shockCond'), sep = ".*(_)", remove = FALSE) %>%
  separate(cond, into = c('cond', 'that'), sep = "_[^_]*$") %>%
  dplyr::select(-one_of('this', 'that')) %>%
  filter(cond %in% c('sourcehit', 'CR')) %>%
  mutate(cond=factor(cond),
         shockCond=factor(shockCond))
glimpse(data)

data %>% group_by(subid, shockCond, group) %>% 
  summarise(n()) %>%
  group_by(shockCond, group) %>% summarise(n())

contrasts(data$group) = c(1, -1); contrasts(data$group)
contrasts(data$cond) =c(-1,1); contrasts(data$cond)
contrasts(data$hemi) =c(1,-1); contrasts(data$hemi)
contrasts(data$shockCond) =c(1,-1); contrasts(data$shockCond)

# interaction within stress group?
dim(data %>% filter(group == 'stress', hemi == 'lh'))
summary(lmer(value ~ cond*shockCond + (1+cond+shockCond|subid), 
             data=data %>% filter(group == 'stress', hemi == 'lh'))) #interaction n.obs

summary(lmer(value ~ cond*shockCond*hemi + (1+cond*shockCond+ hemi|subid), 
             data=data %>% filter(group == 'stress')))

# look at interaction
summary(lmer(value ~ cond + (1|subid), 
             data=data %>% filter(group == 'stress', hemi == 'lh', shockCond == 'safe'))) 

summary(lmer(value ~ cond + (1|subid), 
             data=data %>% filter(group == 'stress', hemi == 'lh', shockCond == 'threat'))) 

# interaction by group?
summary(lmer(value ~ cond*shockCond*group + (1+cond+shockCond|subid), 
             data=data %>% filter(hemi == 'lh')))
```

```{r}
dcomb = data %>%
  filter(hemi == 'lh') %>%
  group_by(group, subid, cond, shockCond) %>%
  summarise(mean = mean_(value), n()) %>%
  ungroup() %>%
  mutate(cond = as.character(cond),
         cond = revalue(cond, c("sourcehit" = "HC\nassoc hit")),
         cond = factor(cond, levels=c('HC\nassoc hit', 'CR')),
         shockCond = revalue(shockCond, c("safe" = "Safe")),
         shockCond = revalue(shockCond, c("threat" = "Threat")))
dcomb

dplot = data %>%
  filter(hemi == 'lh') %>%
  group_by(group, subid, cond, shockCond) %>%
  summarise(mean_pe = mean_(value)) %>%
  group_by(group, cond, shockCond) %>%
  summarise(mean=mean_(mean_pe), sem=std.error(mean_pe), n=length(mean_pe)) %>%
  ungroup() %>%
  mutate(cond = as.character(cond),
         cond = revalue(cond, c("sourcehit" = "HC\nassoc hit")),
         cond = factor(cond, levels=c('HC\nassoc hit', 'CR')),
         shockCond = revalue(shockCond, c("safe" = "Safe")),
         shockCond = revalue(shockCond, c("threat" = "Threat")))
dplot

p2 = ggplot(dplot, aes(x=cond, y=mean, group=group, fill=group)) +
    facet_grid(.~shockCond) +
    geom_bar(position = position_dodge(width=0.9), stat="identity") +
    geom_errorbar(width=0, aes(ymin=mean-sem, 
                               ymax=mean+sem), size=1.5, position=position_dodge(width=0.9)) +
    scale_fill_manual(values=palette, guide = guide_legend(title = NULL)) +
  ylab('Parameter estimate (a.u.)') +
  xlab('')
p2

ggsave('~/Experiments/AP/figs/AP_DAN_byruntype.jpeg', dpi=300, width=8, height=4)

p2

## plot individual subjs

p = ggplot(dcomb, 
       aes(x=cond, y=mean, color=group)) + 
   facet_grid(.~shockCond) +
  geom_point(pch = 19, position = position_jitterdodge(), 
             alpha=.2, size=1.5)+
  scale_x_discrete(name = "Encoding strength") +
  geom_point(data = dplot, aes(y=mean), position=position_dodge(.9), 
             alpha=1, size = 2.5, shape=19) +
  geom_errorbar(data = dplot, width=0,
                aes(y=mean, ymin=mean-sem, ymax=mean+sem),
                size=1.5, position=position_dodge(.9), alpha=1) +
  scale_color_manual(values=palette) +
  ylab('Parameter estimate (a.u.)') +
  xlab('')+
  theme_classic(base_size = 14)+
  theme(legend.title=element_blank(), 
        strip.text = element_text(size=14),
        strip.background = element_rect(colour="white", fill="white"))
p
ggsave('~/Dropbox/Stanford/Papers/AP/Figures/AP_supp_figure5.tiff', dpi=600, width=6.69, height=3)
```


# 7) Variability in neural patterns during retrieval

Does the control group have more variable responses across VTC when making SHs? Evidence for "categorical" responses in stress group?
```{r}
d_2dsd = read.csv('/Volumes/group/awagner/sgagnon/AP/results/retrieval_2dsd_SH_bilat-parahipp_fusi_inftemp_nohipp.csv')

str(d_2dsd)

d_2dsd %>% group_by(group) %>% summarise(n(), mean(sh_2dsd), std.error(sh_2dsd))

bartlett.test(sh_2dsd ~ group, data=d_2dsd)
t.test(sh_2dsd ~ group, data=d_2dsd, var.equal=TRUE)

summary(lm(sh_2dsd ~ sh_count, data=d_2dsd))
# num of SHs doesn't predict 2dsd

# does this hold when removing poor localizer subjs?
subids_rm = c('ap168', 'ap174') # bad VTC localizer classification
d_2dsd %>% filter(!subid %in% subids_rm) %>% group_by(group) %>% summarise(n(), mean(sh_2dsd), std.error(sh_2dsd))
bartlett.test(sh_2dsd ~ group, data=d_2dsd %>% filter(!subid %in% subids_rm))
t.test(sh_2dsd ~ group, data=d_2dsd %>% filter(!subid %in% subids_rm), var.equal=TRUE)
```

### 7a) Does VTC variability track HC assoc accuracy?

```{r}
dat = read.csv('/Volumes/group/awagner/sgagnon/AP/results/df_sourceAcc.csv')

dat %>% group_by(subid, group) %>% 
  summarise(mean_acc = mean(mean_acc), n()) %>% 
  group_by(group) %>% 
  summarise(mean(mean_acc), n())
dat
hist(dat$mean_acc)
dat = dat %>% mutate(mean_acc_logit = car::logit(mean_acc))
```


```{r}
d_2dsd = dat %>% right_join(d_2dsd, by = c('subid', 'group'))
d_2dsd %>% group_by(group) %>% summarise(n(), mean(sh_2dsd), std.error(sh_2dsd))
str(d_2dsd)
head(d_2dsd)

plot(mean_acc_logit ~ sh_2dsd, data=d_2dsd)
fit1 = lm(mean_acc_logit ~ sh_2dsd, data=d_2dsd)
fit2 = lm(mean_acc_logit ~ poly(sh_2dsd,2), data=d_2dsd)
anova(fit1, fit2) # quad is better, but looks like driven by 2 outliers
summary(fit1)
plot(fit1)

# holds when controlling for group?
contrasts(d_2dsd$group) = c(-1,1)
summary(lm(mean_acc_logit ~ sh_2dsd + group, data=d_2dsd))

# what about removing VTC outliers?
plot(mean_acc_logit ~ sh_2dsd, data=d_2dsd %>% filter(!subid %in% subids_rm))
summary(lm(mean_acc_logit ~ sh_2dsd, data=d_2dsd %>% filter(!subid %in% subids_rm)))
```


#### Does 2dsd explain variance in hipp -> sourceAcc not explained by VTC?
```{r}
vtc = read.csv('/Volumes/group/awagner/sgagnon/AP/results/sourcehit_avglogit_vtc.csv')
vtc = vtc %>% mutate(mean_logit = mean) %>% dplyr::select(-mean)

d_2dsd = read.csv('/Volumes/group/awagner/sgagnon/AP/results/retrieval_2dsd_SH_bilat-parahipp_fusi_inftemp_nohipp.csv')

roi = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/pe_sourcehit-cr_zstat1_peak1_5mm_sphere_masked.nii.csv')
roi = roi %>% filter(cond %in% c('sourcehit', 'CR')) %>%
  mutate(cond = factor(cond)) %>% 
  dplyr::select(subid, group, cond, value) %>%  # calc diff score
  spread(key = cond, value=value) %>%
  mutate(diff = sourcehit - CR) %>%
  right_join(d_2dsd, by = c('subid', 'group')) %>%
  right_join(vtc, by = c('subid', 'group')) %>%
  left_join(dat, by = c('subid', 'group')) %>%
  mutate(diff_orig = diff,
         diff = as.numeric(scale(diff)),
         mean_logit = as.numeric(scale(mean_logit)),
         mean_acc = as.numeric(scale(car::logit(mean_acc))),
         sh_2dsd = as.numeric(scale(sh_2dsd)))
dim(roi)
str(roi)

contrasts(roi$group) = c(1,-1)

summary(lm(mean_acc ~ mean_logit + diff + sh_2dsd, data=roi))
summary(lm(mean_logit ~ sh_2dsd, data=roi))

# Is hipp effect on source acc mediated by 2dsd?
contrasts(roi$group) = c(1,-1)

model.t = lm(mean_acc ~ diff, data=roi); summary(model.t) 
#               Estimate Std. Error t value Pr(>|t|)    
# (Intercept) -2.593e-17  1.340e-01   0.000 1.000000    
# diff         5.138e-01  1.356e-01   3.788 0.000501 ***
model.m = lm(sh_2dsd ~ diff, data=roi); summary(model.m)
#              Estimate Std. Error t value Pr(>|t|)    
# (Intercept) 8.713e-16  1.547e-01   0.000    1.000
# diff        1.403e-01  1.565e-01   0.896    0.375
model.y = lm(mean_acc ~ sh_2dsd + diff, data=roi); summary(model.y)
#               Estimate Std. Error t value Pr(>|t|)   
# (Intercept) -2.764e-16  1.280e-01   0.000 1.000000    
# sh_2dsd      2.874e-01  1.309e-01   2.196 0.034119 *  
# diff         4.735e-01  1.309e-01   3.617 0.000844 ***
model.other = lm(mean_acc ~ sh_2dsd, data=roi); summary(model.other)
# (Intercept) -3.263e-16  1.461e-01   0.000   1.0000  
# sh_2dsd      3.539e-01  1.479e-01   2.393   0.0215 *

ggplot(roi, aes(x=sh_2dsd, y=mean_acc)) +
  geom_point() +   
  geom_smooth(method=lm) +
  xlab('SH 2dsd') +
  ylab('Source accuracy (logit)')

roi %>% group_by(group) %>% summarise(n())

## Bootstrapping Confidence Interval (BCa and Percentile)
boot.med <- function(data, indices){
	data <-data[indices,]	#this does the random resampling of rows

	reg1 <- lm(sh_2dsd ~ diff, data=data)
	reg2 <- lm(mean_acc ~ sh_2dsd + diff, data=data)
	
	a <- coefficients(reg1)["diff"]	#the a path coefficient
	b <- coefficients(reg2)["sh_2dsd"]	#the b path coefficient
	a*b							#returns the product of a*b
}

medboot<-boot(data=roi, statistic = boot.med, R=5000)	
mean(medboot$t)
quantile(medboot$t, c(0.025, 0.975))

# > mean(medboot$t)
# [1] 0.05026415
# > quantile(medboot$t, c(0.025, 0.975))
#        2.5%       97.5% 
# -0.08661536  0.23665193 
```


# Supplemental stats

## S1) Encoding performance

### Encoding: P(respond related)
```{r echo=FALSE, cache=TRUE}
ds = read.csv('/Volumes/group/awagner/sgagnon/AP/data/behav/df_study.csv')
str(ds)

ds = ds %>% mutate(repType = factor(repType))
# Set up some contrasts for stats
contrasts(ds$cond) = c(-1,1); contrasts(ds$cond)
contrasts(ds$group) = c(-1,1); contrasts(ds$group)
contrasts(ds$repType) = c(-1, 1); contrasts(ds$repType)

d = ds %>%
  mutate(related = ifelse(resp == "related", 1, 0))

# does group interact with cond or repetition?
summary(glmer(related ~ (cond + scale(repCount) * repType)* group + 
               (1 + cond + scale(repCount) * repType|subid), data=d, family=binomial,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5))))

# Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [
# glmerMod]
#  Family: binomial  ( logit )
# Formula: related ~ (cond + scale(repCount) * repType) * group + (1 + cond +  
#     scale(repCount) * repType | subid)
#    Data: d
# Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e+05))
# 
#      AIC      BIC   logLik deviance df.resid 
#  25266.0  25467.6 -12608.0  25216.0    23477 
# 
# Scaled residuals: 
#      Min       1Q   Median       3Q      Max 
# -17.4263  -0.6963   0.1380   0.6961   4.9863 
# 
# Random effects:
#  Groups Name                     Variance Std.Dev. Corr                   
#  subid  (Intercept)              2.66066  1.6312                          
#         cond1                    0.02785  0.1669    0.09                  
#         scale(repCount)          0.39866  0.6314    0.68  0.25            
#         repType1                 0.05033  0.2244   -0.25 -0.11 -0.65      
#         scale(repCount):repType1 0.02937  0.1714   -0.48 -0.14 -0.92  0.89
# Number of obs: 23502, groups:  subid, 47
# 
# Fixed effects:
#                                  Estimate Std. Error z value Pr(>|z|)    
# (Intercept)                      0.387405   0.239490   1.618 0.105743    
# cond1                            0.008194   0.029941   0.274 0.784343    
# scale(repCount)                  0.345822   0.098338   3.517 0.000437 ***
# repType1                         0.033983   0.042839   0.793 0.427616    
# group1                          -0.037016   0.239443  -0.155 0.877142    
# scale(repCount):repType1        -0.014395   0.040085  -0.359 0.719510    
# cond1:group1                     0.044631   0.029759   1.500 0.133686    
# scale(repCount):group1          -0.044596   0.098204  -0.454 0.649747    
# repType1:group1                  0.011226   0.042252   0.266 0.790472    
# scale(repCount):repType1:group1 -0.019030   0.039522  -0.482 0.630146    
# ---
# Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1
# 
# Correlation of Fixed Effects:
#             (Intr) cond1  scl(C) rpTyp1 group1 sc(C):T1 cnd1:1 s(C):1 rpT1:1
# cond1        0.074                                                          
# scal(rpCnt)  0.659  0.192                                                   
# repType1    -0.237 -0.065 -0.615                                            
# group1      -0.025 -0.002 -0.023  0.015                                     
# scl(rpC):T1 -0.360 -0.072 -0.735  0.782  0.018                              
# cond1:grop1 -0.002 -0.085 -0.006  0.001  0.075  0.000                       
# scl(rpCn):1 -0.023 -0.007 -0.052  0.043  0.659  0.046    0.194              
# rpTyp1:grp1  0.015  0.001  0.043 -0.105 -0.239 -0.085   -0.067 -0.620       
# scl(C):T1:1  0.018  0.000  0.046 -0.085 -0.364 -0.100   -0.073 -0.744  0.777
```

### Encoding: RT
```{r}
d = ds %>% 
  filter(resp != 'no response') %>%
  mutate(resp = factor(resp)) %>%
  group_by(group, subid, repCount, repType, cond) %>%
  summarise(rt = median_(respRT)) %>%
  ungroup()

res = lmer(rt ~ (cond + scale(repCount) * repType) * group +
             (1 + cond + scale(repCount) * repType|subid), data=d,
           control=lmerControl(optCtrl=list(maxfun=1e5)), REML=TRUE)
summary(res)

summary(lmer(rt ~ (cond + scale(repCount)) * group +
             (1 + scale(repCount)|subid), # remove cond to converge
             data=d %>% filter(repType == '2'),
           control=lmerControl(optCtrl=list(maxfun=1e5))))

summary(lmer(rt ~ (cond + scale(repCount)) * group +
             (1 + scale(repCount)|subid), # remove cond to converge
             data=d %>% filter(repType == '4'),
           control=lmerControl(optCtrl=list(maxfun=1e5))))
```

## S2) Compare item vs. assoc dprime (Wixted approach)

```{r}
item_d = read.csv('/Volumes/group/awagner/sgagnon/AP/results/behav_item_dprime.csv')
assoc_d = read.csv('/Volumes/group/awagner/sgagnon/AP/results/behav_assoc_dprime.csv')

# merge these 2 measures:
item_d = item_d %>% 
  dplyr::select(subid, group, dprime) %>%
  group_by(subid, group) %>%
  summarise(item_d = mean(dprime))

assoc_d = assoc_d %>% 
  dplyr::select(subid, group, dprime) %>%
  group_by(subid, group) %>%
  summarise(assoc_d = mean(dprime))

combined_d = item_d %>% left_join(assoc_d)
combined_d

## Wixted 2004 standardized measure:

# make sure no major outliers biasing sd!
boxplot(combined_d %>% filter(group == 'control') %>% 
  dplyr::select(item_d, assoc_d))
stripchart(combined_d %>% filter(group == 'control') %>% 
  dplyr::select(item_d, assoc_d), vertical = TRUE, method = "jitter", add=TRUE)

# get control group stats for standardizing
sum_stats = combined_d %>% filter(group == 'control') %>% 
  ungroup() %>%
  dplyr::select(item_d, assoc_d) %>%
  summarise_each(funs(mean, sd, n()))
sum_stats

# get stress standardized by control stats
rel_control = combined_d %>% 
  ungroup() %>%
  mutate(item_z = (item_d - sum_stats$item_d_mean)/sum_stats$item_d_sd,
         assoc_z = (assoc_d - sum_stats$assoc_d_mean)/sum_stats$assoc_d_sd) %>% 
  filter(group == 'stress') %>%
  dplyr::select(subid, group, item_z, assoc_z) %>%
  gather(key='dprimetype', value='zscore', item_z:assoc_z)

rel_control %>%
  group_by(dprimetype) %>%
  summarise_each(funs(mean))

# stats:
bartlett.test(zscore ~ dprimetype, data=rel_control)
t.test(zscore ~ dprimetype, data=rel_control, var.equal=TRUE, paired=TRUE)
```

## S3) Associative accuracy (behavioral inclusion criteria) by encoding strength and run type (safe, threat)

### High confidence assoc accuracy
```{r}
dat = dtest %>% 
  filter(subj_status == 'old', 
         reps > 0,
         conf == 'Hi') %>%
  group_by(subid, group) %>%
  summarise(mean_acc = mean(acc_num), sum=sum(acc_num), count=n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), fill = list(mean_acc=0,
                                                    count=0))

dim(dat) # all subjs included

dat %>% filter(count < 6) 
# ap151

rm_subids = dat %>% filter(count < 6) %>% pull(subid) %>% unique(); rm_subids
rm_subids # ap151
dat = dat %>% filter(!subid %in% rm_subids)

dat %>% group_by(subid, group) %>% 
  summarise(mean_acc = mean(mean_acc), n()) %>% 
  group_by(group) %>% 
  summarise(mean(mean_acc), n())
```

```{r}
hist(dat$mean_acc) # skewed negatively

# logit transform
dat = dat %>% mutate(mean_acc_logit = car::logit(mean_acc))
hist(dat$mean_acc_logit)
boxplot(dat$mean_acc_logit)

# stats:
dat %>% group_by(group) %>% summarise(n())
bartlett.test(mean_acc_logit ~ group, data=dat)
t.test(mean_acc_logit ~ group, data=dat, var.equal=TRUE)

dat_control = dat %>% filter(group == 'control')
t.test(x=dat_control$mean_acc_logit, mu = 0)

dat_control = dat %>% filter(group == 'stress')
t.test(x=dat_control$mean_acc_logit, mu = 0)

# logit(.5) = 0 # when acc=50%, logit = 0
```

#### P(correct | "high conf old" to old item), broken down by study reps
```{r}
with(dtest %>% 
  filter(subj_status == 'old', 
         reps > 0,
         conf == 'Hi'), table(acc, acc_num))

# just split by study reps
dat = dtest %>% 
  filter(subj_status == 'old', 
         reps > 0,
         conf == 'Hi') %>%
  group_by(subid, group, reps) %>%
  summarise(mean_acc = mean(acc_num), count=n()) %>%
  ungroup() %>%
  mutate(reps = factor(reps)) %>%
  complete(nesting(subid, group), reps, fill = list(mean_acc=0,
                                                    count=0))

dim(dat) # all subjs included
dat %>% filter(count < 6) 
dat

rm_subids = dat %>% filter(count < 6) %>% pull(subid) %>% unique(); rm_subids
# 2 control, 1 stress
dat = dat %>% filter(!subid %in% rm_subids)
dat

dat %>% group_by(subid, group) %>% summarise(n()) %>% group_by(group) %>% summarise(n())
dat = dat%>% mutate(mean_logit = car::logit(mean_acc))

contrasts(dat$reps) = c(-1,1); contrasts(dat$reps)
contrasts(dat$group) = c(1,-1); contrasts(dat$group)
summary(lmer(mean_logit ~ group*reps + 
               (1|subid), data=dat)) # not enough obs for the RE
```

#### P(correct | "high conf old" to old item), broken down by shock condition
```{r}
# just split by study reps
dat = dtest %>% 
  filter(subj_status == 'old', 
         reps > 0,
         conf == 'Hi') %>%
  group_by(subid, group, shockCond) %>%
  summarise(mean_acc = mean(acc_num), count=n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), shockCond, fill = list(mean_acc=0,
                                                         count=0))

dim(dat) # all subjs included
dat %>% filter(count < 6) 
# many low trial counts/bin!

rm_subids = dat %>% filter(count < 6) %>% pull(subid) %>% unique()
dat = dat %>% filter(!subid %in% rm_subids)

dat %>% group_by(subid, group) %>% summarise(n()) %>% group_by(group) %>% summarise(n())

dat = dat%>% mutate(mean_logit = car::logit(mean_acc))

contrasts(dat$shockCond) = c(1,-1); contrasts(dat$shockCond)
contrasts(dat$group) = c(1,-1); contrasts(dat$group)
summary(lmer(mean_logit ~ group*shockCond + 
               (1|subid), data=dat)) # not enough obs for the RE

# what about just within stress
summary(lmer(mean_logit ~ shockCond + 
               (1|subid), data=dat %>% filter(group == 'stress'))) # not enough obs for the RE
```

### Low confidence assoc accuracy
```{r}
dat = dtest %>% 
  filter(subj_status == 'old', 
         reps > 0,
         conf == 'Lo') %>%
  group_by(subid, group) %>%
  summarise(mean_acc = mean(acc_num), count=n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), fill = list(mean_acc=0,
                                                    count=0))

dim(dat) # all subjs included
dat %>% filter(count < 6) 
# dat %>% filter(subid == 'ap156')
# many low trial counts/bin!

rm_subids = dat %>% filter(count < 6) %>% pull(subid) %>% unique(); rm_subids
dat = dat %>% filter(!subid %in% rm_subids)

dat %>% group_by(subid, group) %>% summarise(n(), mean_acc = mean(mean_acc)) %>% group_by(group) %>% summarise(n(), mean(mean_acc))

hist(dat$mean_acc)
dat = dat%>% mutate(mean_acc_logit = car::logit(mean_acc))
hist(dat$mean_acc_logit)

bartlett.test(mean_acc_logit ~ group, data=dat)
t.test(mean_acc_logit ~ group, data=dat, var.equal=TRUE)

dat_control = dat %>% filter(group == 'control')
t.test(x=dat_control$mean_acc_logit, mu = 0)

dat_control = dat %>% filter(group == 'stress')
t.test(x=dat_control$mean_acc_logit, mu = 0)
dat
```
#### P(correct | "low conf old" to old item), broken down by study reps
```{r}
# just split by study reps
dat = dtest %>% 
  filter(subj_status == 'old', 
         reps > 0,
         conf == 'Lo') %>%
  group_by(subid, group, reps) %>%
  summarise(mean_acc = mean(acc_num), count=n()) %>%
  ungroup() %>%
  mutate(reps = factor(reps)) %>%
  complete(nesting(subid, group), reps, fill = list(mean_acc=0,
                                                    count=0))

47*2
dim(dat)

dat %>% filter(count < 6) 
# many low trial counts/bin!

rm_subids = dat %>% filter(count < 6) %>% pull(subid) %>% unique()
dat = dat %>% filter(!subid %in% rm_subids)

dat %>% group_by(subid, group) %>%summarise(n()) %>% group_by(group) %>% summarise(n())

dat = dat%>% mutate(mean_logit = car::logit(mean_acc))

contrasts(dat$reps) = c(-1,1); contrasts(dat$reps)
contrasts(dat$group) = c(1,-1); contrasts(dat$group)
summary(lmer(mean_logit ~ group*reps + 
               (1|subid), data=dat)) # not enough obs for the RE
```

#### P(correct | "low conf old" to old item), broken down by shock condition
```{r}
# just split by study reps
dat = dtest %>% 
  filter(subj_status == 'old', 
         reps > 0,
         conf == 'Lo') %>%
  group_by(subid, group, shockCond) %>%
  summarise(mean_acc = mean(acc_num), count=n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), shockCond, fill = list(mean_acc=0,
                                                         count=0))

dim(dat)
dat %>% filter(count < 6) 
# many low trial counts/bin!

rm_subids = dat %>% filter(count < 6) %>% pull(subid) %>% unique()
dat = dat %>% filter(!subid %in% rm_subids)

dat %>% group_by(subid, group) %>%summarise(n()) %>% group_by(group) %>% summarise(n())

dat = dat%>% mutate(mean_logit = car::logit(mean_acc))

contrasts(dat$shockCond) = c(1,-1); contrasts(dat$shockCond)
contrasts(dat$group) = c(1,-1); contrasts(dat$group)
summary(lmer(mean_acc ~ group*shockCond + 
               (1|subid), data=dat)) # not enough obs for the RE

# what about just within stress
summary(lmer(mean_logit ~ shockCond + 
               (1|subid), data=dat %>% filter(group == 'stress'))) # not enough obs for the RE
```

## S4) Localizer behavioral performance

#### P(correct)
```{r echo=FALSE, cache=TRUE}
dl_acc = read.csv('/Volumes/group/awagner/sgagnon/AP/behav/localizer_acc.csv')
head(dl_acc)
contrasts(dl_acc$group) = c(1,-1); contrasts(dl_acc$group)
contrasts(dl_acc$cond) = cbind(c(-1, .5, .5),
                               c(0, -.5, .5))
contrasts(dl_acc$cond)
res = glmer(acc ~ group*cond + (1 + cond|subid), 
            data=dl_acc, family=binomial)
anova(res)
summary(res)
```

### Median RT for correct responses
```{r echo=FALSE, cache=TRUE}
dl_med = read.csv('/Volumes/group/awagner/sgagnon/AP/behav/localizer_medRT.csv')

dl_med %>% group_by(subid, group) %>% summarise(n()) %>% 
  group_by(group) %>% summarise(n()) 

contrasts(dl_med$group) = c(1,-1); contrasts(dl_med$group)
contrasts(dl_med$cond) = cbind(c(-1, .5, .5),
                               c(0, -.5, .5)); contrasts(dl_med$cond)

res = lmer(respRT ~ group*cond + (1|subid), data=dl_med, REML=TRUE) # not enough data to add cond
anova(res)
summary(res)
```


## S5) Motion

### Motion @retrieval (when stressor present)
```{r}
dmot = read.csv('/Volumes/group/awagner/sgagnon/AP/results/group_motion.csv')
str(dmot)

# Retrieval TRs:
d = dmot %>% filter(!subid %in% c('ap151', 'ap156'),
                  run %in% c(1,2,3,4,5,6)) %>%
  group_by(subid, group) %>%
  summarise(max_displ = max(displace_rel), 
            med_displ = median(displace_rel), 
            n=n())

d %>% group_by(group) %>% summarise(n(), mean(max_displ), sd(max_displ), 
                                    mean(med_displ), sd(med_displ))

bartlett.test(max_displ ~ group, data=d)
t.test(max_displ ~ group, data=d, var.equal=TRUE)
with(d, boxplot(max_displ ~ group))
with(d, boxplot(max_displ))

bartlett.test(med_displ ~ group, data=d)
t.test(med_displ ~ group, data=d, var.equal=TRUE)
with(d, boxplot(med_displ ~ group))
with(d, boxplot(med_displ))

dmot %>% filter(displace_rel > 2)
```

### Motion @localizer
```{r}
d = dmot %>% filter(!subid %in% c('ap151', 'ap156'),
                  run %in% c(7,8)) %>%
  group_by(subid, group) %>%
  summarise(max_displ = max(displace_rel), 
            med_displ = median(displace_rel), n=n())

d %>% group_by(group) %>% summarise(n(), mean(max_displ), mean(med_displ),
                                    sd(max_displ), sd(med_displ))

bartlett.test(max_displ ~ group, data=d)
t.test(max_displ ~ group, data=d, var.equal=TRUE)

bartlett.test(med_displ ~ group, data=d)
t.test(med_displ ~ group, data=d, var.equal=TRUE)
```


### What if we collapse across all runs (retrieval + localizer)
```{r}
# Retrieval TRs:
d = dmot %>% filter(!subid %in% c('ap151', 'ap156'),
                  run %in% c(1,2,3,4,5,6,7,8)) %>%
  group_by(subid, group) %>%
  summarise(max_displ = max(displace_rel), 
            med_displ = median(displace_rel), 
            n=n())

d %>% group_by(group) %>% summarise(n(), 
                                    mean(max_displ), 
                                    sd(max_displ), 
                                    mean(med_displ), 
                                    sd(med_displ))

bartlett.test(max_displ ~ group, data=d)
t.test(max_displ ~ group, data=d, var.equal=TRUE)
# marginal, but not sig

bartlett.test(med_displ ~ group, data=d)
t.test(med_displ ~ group, data=d, var.equal=TRUE)
# not sig
```


## S6) Other ROI Analyses

```{r}
basedir = '/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/'

dt = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/mvpa/notebooks/ap_behav.csv')
head(dt)
counts = dt %>%
  group_by(subid, mem_conditions) %>%
  summarise(n=n()) %>%
  ungroup() %>%
  complete(subid, mem_conditions, fill = list(n=0)) %>%
  filter(!mem_conditions %in% c('nuisance', 'FA', 'M'))
# length(unique(dt$mem_conditions)) * length(unique(dt$subid))

counts %>% filter(n <= 5)
```

### Hippocampus

```{r echo=FALSE, cache=TRUE}
basedir = '/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/'

d2 = read.csv(paste(basedir,'pe_hippocampus-head.csv', sep=''))
d3 = read.csv(paste(basedir,'pe_hippocampus-tail.csv', sep=''))
d4 = read.csv(paste(basedir,'pe_hippocampus-body.csv', sep=''))
 
dht = bind_rows(d2,d3,d4)
str(dht)
data = dht %>%
  filter(cond %in% c('sourcehit', 'CR')) %>%
  mutate(cond = factor(cond),
         roi = factor(roi)) %>%
  group_by(subid, group, cond, roi) %>%
  summarise(value = mean(value)) %>%
  ungroup() %>%
  mutate(roi_num = ifelse(roi == 'hippocampus-head', -1, 
                          ifelse(roi == 'hippocampus-tail', 1, 0)))
head(data)
# roi is coded as numeric, along the long axis

contrasts(data$group) = c(1, -1); contrasts(data$group)
data$cond = factor(data$cond)
contrasts(data$cond) = c(-1, 1); contrasts(data$cond)

fit = lmer(value ~ group * cond * poly(roi_num, degree = 2) +
            (1 + cond + poly(roi_num, degree=2)|subid), data=data,
           control=lmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e5)))
fit_lin = lmer(value ~ group * cond * scale(roi_num) +
            (1 + cond + scale(roi_num)|subid), data=data,
           control=lmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e5)))
anova(fit_lin, fit)
summary(fit) # # not enough terms to fit RE interaction


summary(lmer(value ~ group * cond + (1|subid), 
            data=data %>% filter(roi == 'hippocampus-tail'))) # not enough obs for RE cond

summary(lmer(value ~ group * cond + (1|subid), 
            data=data %>% filter(roi == 'hippocampus-body'))) # not enough obs for RE cond
summary(lmer(value ~ group * cond + (1|subid), 
            data=data %>% filter(roi == 'hippocampus-head'))) # not enough obs for RE cond

bartlett.test(mean ~ group, data=data %>%
         filter(cond == 'sourcehit', roi == 'hippocampus-tail') %>%
         group_by(subid, group) %>%
         summarise(mean=mean_(value)))
t.test(mean ~ group, var.equal=TRUE, data=data %>%
         filter(cond == 'sourcehit', roi == 'hippocampus-tail') %>%
         group_by(subid, group) %>%
         summarise(mean=mean_(value)))

bartlett.test(mean ~ group, data=data %>%
         filter(cond == 'sourcehit', roi == 'hippocampus-body') %>%
         group_by(subid, group) %>%
         summarise(mean=mean_(value)))
t.test(mean ~ group, var.equal=TRUE, data=data %>%
         filter(cond == 'sourcehit', roi == 'hippocampus-body') %>%
         group_by(subid, group) %>%
         summarise(mean=mean_(value)))

bartlett.test(mean ~ group, data=data %>%
         filter(cond == 'sourcehit', roi == 'hippocampus-head') %>%
         group_by(subid, group) %>%
         summarise(mean=mean_(value)))
t.test(mean ~ group, var.equal=TRUE, data=data %>%
         filter(cond == 'sourcehit', roi == 'hippocampus-head') %>%
         group_by(subid, group) %>%
         summarise(mean=mean_(value)))
```

```{r echo=FALSE, cache=TRUE, fig.width=12, fig.height=4}
dm = data %>%
  separate(roi, c('region', 'roi')) %>% 
  mutate(roi = factor(roi, levels=c('head', 'body', 'tail'))) %>%
  group_by(group, subid, roi, cond) %>%
  summarise(mean_pe = mean_(value)) %>%
  group_by(group, roi, cond) %>%
  summarise(mean=mean_(mean_pe), sem=std.error(mean_pe), n=length(mean_pe))

p2 = ggplot(dm, aes(x=cond, y=mean, group=group, fill=group)) +
    geom_bar(position = position_dodge(width=0.9), stat="identity") +
    geom_errorbar(width=0, aes(ymin=mean-sem, 
                               ymax=mean+sem), size=1.5, position=position_dodge(width=0.9)) +
  facet_grid(. ~ roi) +
    scale_fill_manual(values=palette, guide = guide_legend(title = NULL)) +
  ylab('Parameter estimate (a.u.)') +
  xlab('')
p2

ggsave('/Volumes/group/awagner/sgagnon/AP/results/retrieval_pe_hipp_HBT_SHvCR.png', dpi=400,
       width=12, height=4)
```

### Angular
```{r}
sub_remove = counts %>% 
  filter(mem_conditions %in% c('sourcehit', 'CR'), 
         n <= 5) %>% 
  pull(subid); sub_remove

basedir = '/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/'
d2 = read.csv(paste(basedir,'pe_DefaultA_IPL.csv', sep=''))
data = d2 %>%
  filter(cond %in% c('sourcehit', 'CR'))
# dim(data)
data = data %>% filter(!(subid %in% sub_remove))
# dim(data)

contrasts(data$group) = c(1, -1); contrasts(data$group)
data$cond = factor(data$cond)
contrasts(data$cond) = c(-1,1); contrasts(data$cond)

summary(lmer(value ~ group * cond + (1|subid), data=data)) # including cond RE not enough obs
```

```{r echo=FALSE, cache=TRUE, fig.width=12, fig.height=4}
dm = data %>%
  group_by(group, subid, roi, cond) %>%
  summarise(mean_pe = mean_(value)) %>%
  group_by(group, roi, cond) %>%
  summarise(mean=mean_(mean_pe), sem=std.error(mean_pe), n=length(mean_pe))

p2 = ggplot(dm, aes(x=cond, y=mean, group=group, fill=group)) +
    geom_bar(position = position_dodge(width=0.9), stat="identity") +
    geom_errorbar(width=0, aes(ymin=mean-sem, 
                               ymax=mean+sem), size=1.5, position=position_dodge(width=0.9)) +
    scale_fill_manual(values=palette, guide = guide_legend(title = NULL)) +
  ylab('Parameter estimate (a.u.)') +
  xlab('')
p2

ggsave('/Volumes/group/awagner/sgagnon/AP/results/retrieval_pe_DefaultA_IPL_SHvCR.png', dpi=400,
       width=5, height=4.2)
```

### Retrosplenial

```{r}
basedir = '/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/'
d2 = read.csv(paste(basedir,'pe_DefaultC_Rsp.csv', sep=''))
data = d2 %>%
  filter(cond %in% c('sourcehit', 'CR')) %>%
  group_by(subid, group, cond) %>%
  summarise(value = mean(value))
# dim(data)
data = data %>% filter(!(subid %in% sub_remove))
# dim(data)

contrasts(data$group) = c(1, -1); contrasts(data$group)
data$cond = factor(data$cond)
contrasts(data$cond) = c(-1,1); contrasts(data$cond)

summary(lmer(value ~ group * cond + (1|subid), data=data)) # including cond RE not enough obs
```

```{r echo=FALSE, cache=TRUE, fig.width=12, fig.height=4}
dm = data %>%
  group_by(group, subid, cond) %>%
  summarise(mean_pe = mean_(value)) %>%
  group_by(group, cond) %>%
  summarise(mean=mean_(mean_pe), sem=std.error(mean_pe), n=length(mean_pe))

p2 = ggplot(dm, aes(x=cond, y=mean, group=group, fill=group)) +
    geom_bar(position = position_dodge(width=0.9), stat="identity") +
    geom_errorbar(width=0, aes(ymin=mean-sem, 
                               ymax=mean+sem), size=1.5, position=position_dodge(width=0.9)) +
    scale_fill_manual(values=palette, guide = guide_legend(title = NULL)) +
  ylab('Parameter estimate (a.u.)') +
  xlab('')
p2

ggsave('/Volumes/group/awagner/sgagnon/AP/results/retrieval_pe_DefaultC_Rsp_SHvCR.png', dpi=400,
       width=5, height=4.2)
```


## S7) Reinstatement

### VTC equalize trial counts
```{r}
d = read.csv('/Users/sgagnon/Dropbox/Stanford/Presentations/AP/mvpa_logit_bilat-parahipp_fusi_inftemp_allcat_byreps_avg_46810_filtartloc_equalizetrials.csv')
dt = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/mvpa/notebooks/ap_behav.csv')

subids_rm = c('ap168', 'ap174')
with(d %>% filter(category == 'place'), table(subid, condition))

d = d %>%
  filter(!subid %in% subids_rm,
         category == 'place', 
         condition == 'sourcehit')
dim(d)
head(d)


dj = dt %>%
  mutate(onset=onset_adj, img_type=cond) %>% 
  dplyr::select(-group, -reps, -cond) %>%
  right_join(d, by=c('subid', 'run', 'onset')) %>%
  mutate(subid = factor(subid), imgType = factor(img_type))
# str(dj)

dim(dj)
dt %>% filter(shock_and_post != 0)
with(dt %>% filter(shock_and_post != 0), table(cond, mem_conditions))
dj %>% filter(shock_and_post != 0)
dj = dj %>% filter(shock_and_post == 0)
dim(dj)
```

```{r}
subids_lowtrials = dj %>% 
  group_by(group, subid) %>% 
  summarise(count = n()) %>% 
  ungroup() %>%
  complete(nesting(subid, group), fill = list(count= 0)) %>%
  filter(count < 6) %>% 
  pull(subid) %>% unique()
subids_lowtrials

contrasts(dj$group) = c(1,-1); contrasts(dj$group)

with(dj, table(subid))
subids_rm

d_avg = dj %>% filter(!subid %in% subids_lowtrials) %>%
  group_by(group, subid) %>%
  summarise(mean=mean(avg_logit))

bartlett.test(mean ~ group, data=d_avg)
t.test(mean ~ group, data=d_avg, var.equal=TRUE)
d_avg %>% group_by(group) %>% summarise(mean(mean), n())

boxplot(mean ~ group, data=d_avg)
ggplot(d_avg, aes(x=group, y=mean, color=group)) +
  geom_boxplot() + geom_jitter() +
  scale_color_manual(values = palette) +
  xlab('') + ylab('Logit')

t.test(d_avg %>% filter(group == 'control') %>% pull(mean), mu = 0)
t.test(d_avg %>% filter(group == 'stress') %>% pull(mean), mu = 0)
```

## S8) Inferior parietal reinstatement

## Load in data
```{r}
d = read.csv('/Users/sgagnon/Dropbox/Stanford/Presentations/AP/mvpa_logit_place_byreps_avg_46810_filtartloc_scalewithinrun.csv')

subids_rm = c('ap168') # bad localizer classification

# filter d to just good subjs, and only OLD items
d = d %>%
  filter(!subid %in% subids_rm) %>%
  filter(cond %in% c('sourcemiss_hi', 'sourcehit', 'M', 'itemhit_lo')) %>%
  mutate(pcorr = factor(ifelse(cond == "sourcehit", 1, 0)),
         vtc_logit = avg_logit)

dt %>% filter(shock_and_post == 2) # one subj w/consecutive shocks - trial needs to be removed (though mem_condition == 'nuisance')

# Merge w/other behavioral info
d = dt %>%
  mutate(onset=onset_adj, img_type=cond) %>% 
  dplyr::select(-group, -reps, -cond) %>%
  right_join(d, by=c('subid', 'run', 'onset')) %>%
  mutate(subid = factor(subid), imgType = factor(img_type))
dim(d)
d = d %>% filter(shock_and_post == 0)
dim(d)

# Read in hipp BOLD
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-hippocampus.csv')
roi_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-hippocampus.csv')
# dim(roi_lh); dim(roi_rh)

# Take timepoints of interest for old trials, and collapse across hemispheres
roi_f = bind_rows("lh" = roi_lh, "rh" = roi_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, hemi, run, onset) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset) %>%
  summarise(hipp_sig = mean_(mean_activity)) %>% ungroup()

# Read in hipp tail BOLD
roi_tail_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-hippocampus-tail.csv')
roi_tail_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-hippocampus-tail.csv')

# Take timepoints of interest for old trials, and collapse across hemispheres
roi_tail_f = bind_rows("lh" = roi_tail_lh, "rh" = roi_tail_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, hemi, run, onset) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset) %>%
  summarise(hipp_tail_sig = mean_(mean_activity)) %>% ungroup()

# Read in angular BOLD
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-DefaultA_IPL.csv')
angular_lh_f = roi_lh %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, run, onset) %>%
  summarise(angular_lh_sig = mean_(mean_activity)) %>% ungroup()

# Read in RSP BOLD
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-DefaultC_Rsp.csv')
roi_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-DefaultC_Rsp.csv')

# Take timepoints of interest for old trials, and collapse across hemispheres
rsp_f = bind_rows("lh" = roi_lh, "rh" = roi_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, hemi, run, onset) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset) %>%
  summarise(rsp_sig = mean_(mean_activity)) %>% ungroup()

# Read in CCN BOLD
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-frontoparietal.csv')
roi_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-frontoparietal.csv')
# dim(roi_lh); dim(roi_rh)

# Take timepoints of interest for old trials, and collapse across hemispheres
CCN_f = bind_rows("lh" = roi_lh, "rh" = roi_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, hemi, run, onset) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset) %>%
  summarise(CCN_sig = mean_(mean_activity)) %>% ungroup()

# also, just for LH
CCN_lh_f = roi_lh %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, run, onset) %>%
  summarise(CCN_lh_sig = mean_(mean_activity)) %>% ungroup()

# Read in DAN BOLD
roi_lh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_lh-dorsalattn.csv')
roi_rh = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/extractraw_AP_mvpa_raw_rh-dorsalattn.csv')
# dim(roi_lh); dim(roi_rh)

# Take timepoints of interest for old trials, and collapse across hemispheres
DAN_f = bind_rows("lh" = roi_lh, "rh" = roi_rh, .id = "hemi") %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, hemi, run, onset) %>%
  summarise(mean_activity = mean_(mean_activity)) %>%
  group_by(subid, run, onset) %>%
  summarise(DAN_sig = mean_(mean_activity)) %>% ungroup()

# also, just for LH
DAN_lh_f = roi_lh %>%
  filter(condition %in% c('sourcemiss_hi', 'sourcehit', 'itemhit_lo', 'M'),
    time %in% c(4,6,8,10)) %>%
  group_by(subid, run, onset) %>%
  summarise(DAN_lh_sig = mean_(mean_activity)) %>% ungroup()

# Other reinstatement
d_infpar = read.csv('/Users/sgagnon/Dropbox/Stanford/Presentations/AP/mvpa_logit_inferiorparietal_place_byreps_avg_46810_filtartloc_scalewithinrun.csv') %>%
  filter(!subid %in% subids_rm) %>%
  filter(cond %in% c('sourcemiss_hi', 'sourcehit', 'M', 'itemhit_lo')) %>%
  mutate(ang_logit = avg_logit) %>%
  dplyr::select(subid, run, onset, ang_logit)

d_hipp = read.csv('/Users/sgagnon/Dropbox/Stanford/Presentations/AP/mvpa_logit_bilat-hippocampus_place_byreps_avg_46810_filtartloc_scalewithinrun.csv') %>%
  filter(!subid %in% subids_rm) %>%
  filter(cond %in% c('sourcemiss_hi', 'sourcehit', 'M', 'itemhit_lo')) %>%
  mutate(pcorr = factor(ifelse(cond == "sourcehit", 1, 0)),
         hipp_logit = avg_logit) %>%
  dplyr::select(subid, run, onset, hipp_logit)

# Merge w/VTC classifier evidence
dm_ip = d %>%
  left_join(roi_f, by=c('subid', 'run', 'onset')) %>%
  left_join(roi_tail_f, by=c('subid', 'run', 'onset')) %>%
  left_join(DAN_f, by=c('subid', 'run', 'onset')) %>%
  left_join(CCN_f, by=c('subid', 'run', 'onset')) %>%
  left_join(rsp_f, by=c('subid', 'run', 'onset')) %>%
  left_join(angular_lh_f, by=c('subid', 'run', 'onset')) %>%
  left_join(DAN_lh_f, by=c('subid', 'run', 'onset')) %>%
  left_join(CCN_lh_f, by=c('subid', 'run', 'onset')) %>%
  left_join(d_infpar, by=c('subid', 'run', 'onset')) %>%
  left_join(d_hipp, by=c('subid', 'run', 'onset')) %>%
  group_by(subid) %>%
  mutate(ang_logit_z = zscore(ang_logit),
         vtc_logit_z = zscore(vtc_logit),
         hipp_logit_z = zscore(hipp_logit),
         CCN_sig_z = zscore(CCN_sig),
         rsp_sig_z = zscore(rsp_sig),
         DAN_sig_z = zscore(DAN_sig),
         angular_lh_sig_z = zscore(angular_lh_sig),
         CCN_lh_sig_z = zscore(CCN_lh_sig),
         DAN_lh_sig_z = zscore(DAN_lh_sig),
         hipp_sig_z = zscore(hipp_sig),
         hipp_tail_sig_z = zscore(hipp_tail_sig),
         reps = factor(reps),
         hipp_quintile = ntile(hipp_sig, 5),
         rsp_quintile = ntile(rsp_sig, 5),
         CCN_quintile = ntile(CCN_sig, 5),
         DAN_quintile = ntile(DAN_sig, 5),
         angular_lh_sig_quintile = ntile(angular_lh_sig, 5),
         CCN_lh_quintile = ntile(CCN_lh_sig, 5),
         DAN_lh_quintile = ntile(DAN_lh_sig, 5),
         hipp_tail_quintile = ntile(hipp_tail_sig, 5),
         vtc_quintile = ntile(vtc_logit, 5),
         hipp_logit_quintile = ntile(hipp_logit, 5),
         ang_quintile = ntile(ang_logit, 5)) %>%
  ungroup() %>%
  mutate(subid = factor(subid),
         cond = factor(cond),
         condition = factor(condition))
dim(dm_ip) #just hipp: 6623  
with(dm_ip, table(subid, reps))

str(dm_ip)

# set up contrasts
contrasts(dm_ip$pcorr) = c(-1,1); contrasts(dm_ip$pcorr)
contrasts(dm_ip$reps) = c(-1,1); contrasts(dm_ip$reps)
contrasts(dm_ip$group) = c(1,-1); contrasts(dm_ip$group)
contrasts(dm_ip$shockCond) = c(1,-1); contrasts(dm_ip$shockCond)
```

Trial-wise analysis counts/group:
```{r}
dm_ip %>% group_by(subid, group) %>% summarise(n()) %>% group_by(group) %>% summarise(n())
```

### HC assoc hits: infparietal reinstatement ~ group
```{r}
subids_lowtrials = dm_ip %>% 
  filter(cond == 'sourcehit') %>%
  group_by(group, subid) %>% 
  summarise(count = n()) %>% 
  ungroup() %>%
  complete(nesting(subid, group), fill = list(count= 0)) %>%
  filter(count < 6) %>% 
  pull(subid) %>% unique()
subids_lowtrials

d_avg = dm_ip %>% filter(!subid %in% subids_lowtrials) %>%
  filter(cond == 'sourcehit') %>%
  group_by(group, subid) %>%
  summarise(mean=mean(ang_logit))
with(d_avg, table(group))

# diff between groups?
bartlett.test(mean ~ group, data=d_avg)
t.test(mean ~ group, data=d_avg, var.equal=TRUE)
d_avg %>% group_by(group) %>% summarise(mean(mean), n())

t.test(d_avg %>% filter(group == 'control') %>% pull(mean), mu = 0)
t.test(d_avg %>% filter(group == 'stress') %>% pull(mean), mu = 0)
```

### HC accuracy mediation

```{r}
dat = dtest %>% 
  filter(subj_status == 'old',
         reps > 0, # old item
         conf == 'Hi') %>%
  group_by(subid, group) %>%
  summarise(mean_acc = mean(acc_num), sum=sum(acc_num), count=n()) %>%
  ungroup() %>%
  complete(nesting(subid, group), fill = list(mean_acc=0,
                                                    count=0))
dat
# filter out subjs who don't have more than 5 "old" responses to old cues
dim(dat) # all subjs included
dat %>% filter(count < 6) 
rm_subids = dat %>% filter(count < 6) %>% pull(subid) %>% unique(); rm_subids
rm_subids # ap151
dat = dat %>% filter(!subid %in% rm_subids)
```


```{r}
subids_lowtrials = dm_ip %>% 
  filter(cond == 'sourcehit') %>%
  group_by(group, subid) %>% 
  summarise(count = n()) %>% 
  ungroup() %>%
  complete(nesting(subid, group), fill = list(count= 0)) %>%
  filter(count < 6) %>% 
  pull(subid) %>% unique()
subids_lowtrials

with(dm_ip %>% filter(cond == 'sourcehit'), table(subid))

d_avg =  dm_ip %>% 
  filter(cond == 'sourcehit') %>%
  filter(!subid %in% subids_lowtrials) %>%
  group_by(group, subid) %>%
  summarise(mean=mean(ang_logit))
dim(d_avg)
d_avg
```

```{r}
vtc = d_avg %>% mutate(mean_logit = mean) %>% dplyr::select(-mean)
dim(vtc)
vtc %>% group_by(subid, group) %>% summarise(n()) %>% group_by(group) %>% summarise(n())

roi = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/pe_sourcehit-cr_zstat1_peak1_5mm_sphere_masked.nii.csv')
roi = roi %>% filter(cond %in% c('sourcehit', 'CR')) %>%
  mutate(cond = factor(cond)) %>% 
  dplyr::select(subid, group, cond, value) %>%  # calc diff score
  spread(key = cond, value=value) %>%
  mutate(diff = sourcehit - CR) %>%
  right_join(vtc, by = c('subid', 'group')) %>%
  left_join(dat, by = c('subid', 'group')) %>%
  mutate(diff_orig = diff,
         diff = scale(diff),
         mean_logit = scale(mean_logit),
          mean_acc = as.numeric(scale(car::logit(mean_acc))))
dim(roi)
str(roi)

contrasts(roi$group) = c(1,-1)

model.t = lm(mean_acc ~ diff, data=roi); summary(model.t) 
model.m = lm(mean_logit ~ diff, data=roi); summary(model.m)
model.y = lm(mean_acc ~ mean_logit + diff, data=roi); summary(model.y)
model.other = lm(mean_acc ~ mean_logit, data=roi); summary(model.other)


## Bootstrapping Confidence Interval (BCa and Percentile)
boot.med <- function(data, indices){
	data <-data[indices,]	#this does the random resampling of rows

	reg1 <- lm(mean_logit ~ diff, data=data)
	reg2 <- lm(mean_acc ~ mean_logit + diff, data=data)
	
	a <- coefficients(reg1)["diff"]	#the a path coefficient
	b <- coefficients(reg2)["mean_logit"]	#the b path coefficient
	a*b							#returns the product of a*b
}

medboot<-boot(data=roi, statistic = boot.med, R=5000)	
mean(medboot$t)
quantile(medboot$t, c(0.025, 0.975))

# [1] 0.001264906
#        2.5%       97.5%
# -0.11376327  0.09313285
```


# Other analyses

## Is PPA activity reduced for item hits relative to source hits?
```{r}
# dat = read.csv('/Volumes/group/awagner/sgagnon/AP/analysis/ap_memory_raw/group/roi/pe_ppa_scene_limitvox.csv')
# dat = dat %>% filter(cond %in% c('sourcehit', 
#                                  'itemhit_lo')) %>%
#   mutate(cond = factor(cond))
# str(dat)
# 
# subids_lowtrials = dm %>% 
#   filter(cond %in% c('itemhit_lo', 'sourcehit')) %>%
#   mutate(cond = factor(cond)) %>%
#   group_by(group, cond, subid) %>% 
#   summarise(count = n()) %>% 
#   ungroup() %>%
#   complete(nesting(subid, group), cond, 
#            fill = list(count= 0)) %>%
#   filter(count < 6) %>% 
#   pull(subid) %>% unique()
# print(subids_lowtrials)
# 
# dat = dat %>% filter(!subid %in% subids_lowtrials) %>%
#   mutate(subid = factor(subid))
# with(dat, table(subid))
# head(dat)
# 
# contrasts(dat$group) = c(1,-1); contrasts(dat$group)
# contrasts(dat$cond) = c(-1,1); contrasts(dat$cond)
# summary(lmer(value ~ group * cond + (1|subid), data=dat)) # rand slope, not enough obs
# 
# bartlett.test(value ~ group, data=dat %>% filter(cond == 'sourcehit'))
# t.test(value ~ group, data=dat %>% filter(cond == 'sourcehit'), var.equal=TRUE)
# t.test(value ~ group, data=dat %>% filter(cond == 'itemhit_lo'), var.equal=TRUE)
# 
# dat %>% filter(cond == 'itemhit_lo') %>% pull(value)
# t.test(dat %>% filter(cond == 'itemhit_lo') %>% pull(value), mu=0)
# 
# dat %>% group_by(group, cond) %>% summarise(mean = mean(value), 
#                                             se = std.error(value), n())
```

